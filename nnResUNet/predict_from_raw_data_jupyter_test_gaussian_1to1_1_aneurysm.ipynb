{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e76c6a8",
   "metadata": {},
   "source": [
    "## 測試nnUNet Inference code  \n",
    "因為sliding_window用林君彥的pipeline要1個case inference 9000多pitch 要30分鐘，所以要改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a0ff1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import multiprocessing\n",
    "import os\n",
    "import shutil\n",
    "import traceback\n",
    "from asyncio import sleep\n",
    "from copy import deepcopy\n",
    "from typing import Tuple, Union, List\n",
    "\n",
    "import nnunetv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from batchgenerators.dataloading.data_loader import DataLoader\n",
    "from batchgenerators.dataloading.multi_threaded_augmenter import MultiThreadedAugmenter\n",
    "from batchgenerators.transforms.utility_transforms import NumpyToTensor\n",
    "from batchgenerators.utilities.file_and_folder_operations import load_json, join, isfile, maybe_mkdir_p, isdir, subdirs, \\\n",
    "    save_json\n",
    "from nnunetv2.configuration import default_num_processes\n",
    "from nnunetv2.inference.export_prediction import export_prediction_from_softmax\n",
    "#from nnunetv2.inference.sliding_window_prediction import predict_sliding_window_return_logits, compute_gaussian\n",
    "from nnunetv2.preprocessing.preprocessors.default_preprocessor import DefaultPreprocessor\n",
    "from nnunetv2.utilities.file_path_utilities import get_output_folder, should_i_save_to_file, check_workers_busy\n",
    "from nnunetv2.utilities.find_class_by_name import recursive_find_python_class\n",
    "from nnunetv2.utilities.json_export import recursive_fix_for_json_export\n",
    "from nnunetv2.utilities.label_handling.label_handling import determine_num_input_channels, convert_labelmap_to_one_hot\n",
    "from nnunetv2.utilities.plans_handling.plans_handler import PlansManager, ConfigurationManager\n",
    "from nnunetv2.utilities.utils import create_lists_from_splitted_dataset_folder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.filters import threshold_multiotsu, gaussian, threshold_otsu, frangi\n",
    "from skimage.measure import label, regionprops, regionprops_table\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e14f979",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessAdapter(DataLoader):\n",
    "    def __init__(self, list_of_lists: List[List[str]], list_of_segs_from_prev_stage_files: Union[List[None], List[str]],\n",
    "                 preprocessor: DefaultPreprocessor, output_filenames_truncated: List[str],\n",
    "                 plans_manager: PlansManager, dataset_json: dict, configuration_manager: ConfigurationManager,\n",
    "                 num_threads_in_multithreaded: int = 1):\n",
    "        self.preprocessor, self.plans_manager, self.configuration_manager, self.dataset_json = \\\n",
    "            preprocessor, plans_manager, configuration_manager, dataset_json\n",
    "\n",
    "        self.label_manager = plans_manager.get_label_manager(dataset_json)\n",
    "\n",
    "        super().__init__(list(zip(list_of_lists, list_of_segs_from_prev_stage_files, output_filenames_truncated)),\n",
    "                         1, num_threads_in_multithreaded,\n",
    "                         seed_for_shuffle=1, return_incomplete=True,\n",
    "                         shuffle=False, infinite=False, sampling_probabilities=None)\n",
    "\n",
    "        self.indices = list(range(len(list_of_lists)))\n",
    "\n",
    "    def generate_train_batch(self):\n",
    "        idx = self.get_indices()[0]\n",
    "        files = self._data[idx][0]\n",
    "        seg_prev_stage = self._data[idx][1]\n",
    "        ofile = self._data[idx][2]\n",
    "        # if we have a segmentation from the previous stage we have to process it together with the images so that we\n",
    "        # can crop it appropriately (if needed). Otherwise it would just be resized to the shape of the data after\n",
    "        # preprocessing and then there might be misalignments\n",
    "        data, seg, data_properites = self.preprocessor.run_case(files, seg_prev_stage, self.plans_manager,\n",
    "                                                                self.configuration_manager,\n",
    "                                                                self.dataset_json)\n",
    "        #if seg_prev_stage is not None:\n",
    "        #    seg_onehot = convert_labelmap_to_one_hot(seg[0], self.label_manager.foreground_labels, data.dtype)\n",
    "        #    data = np.vstack((data, seg_onehot))\n",
    "\n",
    "        if np.prod(data.shape) > (2e9 / 4 * 0.85):\n",
    "            # we need to temporarily save the preprocessed image due to process-process communication restrictions\n",
    "            np.save(ofile + '.npy', data)\n",
    "            data = ofile + '.npy'\n",
    "\n",
    "        return {'data': data, 'seg': seg, 'data_properites': data_properites, 'ofile': ofile}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e02b59dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_what_we_need(model_training_output_dir, use_folds, checkpoint_name):\n",
    "    # we could also load plans and dataset_json from the init arguments in the checkpoint. Not quite sure what is the\n",
    "    # best method so we leave things as they are for the moment.\n",
    "    dataset_json = load_json(join(model_training_output_dir, 'dataset.json'))\n",
    "    plans = load_json(join(model_training_output_dir, 'nnUNetPlans_64x-5L-b110.json'))\n",
    "    \n",
    "    plans_manager = PlansManager(plans)\n",
    "\n",
    "    if isinstance(use_folds, str):\n",
    "        use_folds = [use_folds]\n",
    "\n",
    "    parameters = []\n",
    "    for i, f in enumerate(use_folds):\n",
    "        f = int(f) if f != 'all' else f\n",
    "        checkpoint = torch.load(join(model_training_output_dir, f'fold_{f}', checkpoint_name),\n",
    "                                map_location=torch.device('cpu'), weights_only=False)\n",
    "        if i == 0:\n",
    "            trainer_name = checkpoint['trainer_name']\n",
    "            configuration_name = checkpoint['init_args']['configuration']\n",
    "            inference_allowed_mirroring_axes = checkpoint['inference_allowed_mirroring_axes'] if \\\n",
    "                'inference_allowed_mirroring_axes' in checkpoint.keys() else None\n",
    "\n",
    "        parameters.append(checkpoint['network_weights'])\n",
    "\n",
    "    configuration_manager = plans_manager.get_configuration(configuration_name)\n",
    "    # restore network\n",
    "    num_input_channels = determine_num_input_channels(plans_manager, configuration_manager, dataset_json)\n",
    "    trainer_class = recursive_find_python_class(join(nnunetv2.__path__[0], \"training\", \"nnUNetTrainer\"),\n",
    "                                                trainer_name, 'nnunetv2.training.nnUNetTrainer')\n",
    "    network = trainer_class.build_network_architecture(plans_manager, dataset_json, configuration_manager,\n",
    "                                                       num_input_channels, enable_deep_supervision=False)\n",
    "    return parameters, configuration_manager, inference_allowed_mirroring_axes, plans_manager, dataset_json, network, trainer_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5b7e209",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_detect_available_folds(model_training_output_dir, checkpoint_name):\n",
    "    print('use_folds is None, attempting to auto detect available folds')\n",
    "    fold_folders = subdirs(model_training_output_dir, prefix='fold_', join=False)\n",
    "    fold_folders = [i for i in fold_folders if i != 'fold_all']\n",
    "    fold_folders = [i for i in fold_folders if isfile(join(model_training_output_dir, i, checkpoint_name))]\n",
    "    use_folds = [int(i.split('_')[-1]) for i in fold_folders]\n",
    "    print(f'found the following folds: {use_folds}')\n",
    "    return use_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "490ceb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from typing import Union, Tuple, List\n",
    "from acvl_utils.cropping_and_padding.padding import pad_nd_image\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from torch import nn\n",
    "\n",
    "from nnunetv2.utilities.helpers import empty_cache, dummy_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd2193e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gaussian(tile_size: Tuple[int, ...], sigma_scale: float = 1. / 8, dtype=np.float16) \\\n",
    "        -> np.ndarray:\n",
    "    tmp = np.zeros(tile_size)\n",
    "    center_coords = [i // 2 for i in tile_size]\n",
    "    sigmas = [i * sigma_scale for i in tile_size]\n",
    "    tmp[tuple(center_coords)] = 1\n",
    "    gaussian_importance_map = gaussian_filter(tmp, sigmas, 0, mode='constant', cval=0)\n",
    "    gaussian_importance_map = gaussian_importance_map / np.max(gaussian_importance_map) * 1\n",
    "    gaussian_importance_map = gaussian_importance_map.astype(dtype)\n",
    "\n",
    "    # gaussian_importance_map cannot be 0, otherwise we may end up with nans!\n",
    "    gaussian_importance_map[gaussian_importance_map == 0] = np.min(\n",
    "        gaussian_importance_map[gaussian_importance_map != 0])\n",
    "\n",
    "    return gaussian_importance_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29a940ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_steps_for_sliding_window(image_size: Tuple[int, ...], tile_size: Tuple[int, ...], tile_step_size: float) -> \\\n",
    "        List[List[int]]:\n",
    "    assert [i >= j for i, j in zip(image_size, tile_size)], \"image size must be as large or larger than patch_size\"\n",
    "    assert 0 < tile_step_size <= 1, 'step_size must be larger than 0 and smaller or equal to 1'\n",
    "\n",
    "    # our step width is patch_size*step_size at most, but can be narrower. For example if we have image size of\n",
    "    # 110, patch size of 64 and step_size of 0.5, then we want to make 3 steps starting at coordinate 0, 23, 46\n",
    "    target_step_sizes_in_voxels = [i * tile_step_size for i in tile_size]\n",
    "\n",
    "    num_steps = [int(np.ceil((i - k) / j)) + 1 for i, j, k in zip(image_size, target_step_sizes_in_voxels, tile_size)]\n",
    "\n",
    "    steps = []\n",
    "    for dim in range(len(tile_size)):\n",
    "        # the highest step value for this dimension is\n",
    "        max_step_value = image_size[dim] - tile_size[dim]\n",
    "        if num_steps[dim] > 1:\n",
    "            actual_step_size = max_step_value / (num_steps[dim] - 1)\n",
    "        else:\n",
    "            actual_step_size = 99999999999  # does not matter because there is only one step at 0\n",
    "\n",
    "        steps_here = [int(np.round(actual_step_size * i)) for i in range(num_steps[dim])]\n",
    "\n",
    "        steps.append(steps_here)\n",
    "\n",
    "    return steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0330cea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sliding_window_generator(image_size: Tuple[int, ...], tile_size: Tuple[int, ...], tile_step_size: float,\n",
    "                                 verbose: bool = False):\n",
    "    if len(tile_size) < len(image_size):\n",
    "        assert len(tile_size) == len(image_size) - 1, 'if tile_size has less entries than image_size, len(tile_size) ' \\\n",
    "                                                      'must be one shorter than len(image_size) (only dimension ' \\\n",
    "                                                      'discrepancy of 1 allowed).'\n",
    "        steps = compute_steps_for_sliding_window(image_size[1:], tile_size, tile_step_size)\n",
    "        if verbose: print(f'n_steps {image_size[0] * len(steps[0]) * len(steps[1])}, image size is {image_size}, tile_size {tile_size}, '\n",
    "                          f'tile_step_size {tile_step_size}\\nsteps:\\n{steps}')\n",
    "        for d in range(image_size[0]):\n",
    "            for sx in steps[0]:\n",
    "                for sy in steps[1]:\n",
    "                    slicer = tuple([slice(None), d, *[slice(si, si + ti) for si, ti in zip((sx, sy), tile_size)]])\n",
    "                    yield slicer\n",
    "    else:\n",
    "        steps = compute_steps_for_sliding_window(image_size, tile_size, tile_step_size)\n",
    "        if verbose: print(f'n_steps {np.prod([len(i) for i in steps])}, image size is {image_size}, tile_size {tile_size}, '\n",
    "                          f'tile_step_size {tile_step_size}\\nsteps:\\n{steps}')\n",
    "        for sx in steps[0]:\n",
    "            for sy in steps[1]:\n",
    "                for sz in steps[2]:\n",
    "                    slicer = tuple([slice(None), *[slice(si, si + ti) for si, ti in zip((sx, sy, sz), tile_size)]])\n",
    "                    yield slicer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4401e5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maybe_mirror_and_predict(network: nn.Module, x: torch.Tensor, mirror_axes: Tuple[int, ...] = None) \\\n",
    "        -> torch.Tensor:\n",
    "    prediction = network(x)\n",
    "\n",
    "    if mirror_axes is not None:\n",
    "        # check for invalid numbers in mirror_axes\n",
    "        # x should be 5d for 3d images and 4d for 2d. so the max value of mirror_axes cannot exceed len(x.shape) - 3\n",
    "        assert max(mirror_axes) <= len(x.shape) - 3, 'mirror_axes does not match the dimension of the input!'\n",
    "\n",
    "        num_predictons = 2 ** len(mirror_axes)\n",
    "        if 0 in mirror_axes:\n",
    "            prediction += torch.flip(network(torch.flip(x, (2,))), (2,))\n",
    "        if 1 in mirror_axes:\n",
    "            prediction += torch.flip(network(torch.flip(x, (3,))), (3,))\n",
    "        if 2 in mirror_axes:\n",
    "            prediction += torch.flip(network(torch.flip(x, (4,))), (4,))\n",
    "        if 0 in mirror_axes and 1 in mirror_axes:\n",
    "            prediction += torch.flip(network(torch.flip(x, (2, 3))), (2, 3))\n",
    "        if 0 in mirror_axes and 2 in mirror_axes:\n",
    "            prediction += torch.flip(network(torch.flip(x, (2, 4))), (2, 4))\n",
    "        if 1 in mirror_axes and 2 in mirror_axes:\n",
    "            prediction += torch.flip(network(torch.flip(x, (3, 4))), (3, 4))\n",
    "        if 0 in mirror_axes and 1 in mirror_axes and 2 in mirror_axes:\n",
    "            prediction += torch.flip(network(torch.flip(x, (2, 3, 4))), (2, 3, 4))\n",
    "        prediction /= num_predictons\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c5e76f",
   "metadata": {},
   "source": [
    "## 最需要改的地方"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e85cd469",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def predict_sliding_window_return_logits(network: nn.Module,\n",
    "                                         input_image: Union[np.ndarray, torch.Tensor],\n",
    "                                         vessel_image: Union[np.ndarray, torch.Tensor],\n",
    "                                         num_segmentation_heads: int,\n",
    "                                         tile_size: Tuple[int, ...],\n",
    "                                         mirror_axes: Tuple[int, ...] = None,\n",
    "                                         tile_step_size: float = 0.5,\n",
    "                                         use_gaussian: bool = True,\n",
    "                                         precomputed_gaussian: torch.Tensor = None,\n",
    "                                         perform_everything_on_gpu: bool = True,\n",
    "                                         verbose: bool = True,\n",
    "                                         device: torch.device = torch.device('cuda'),\n",
    "                                         batch_size: int = 1) -> Union[np.ndarray, torch.Tensor]:\n",
    "    if perform_everything_on_gpu:\n",
    "        assert device.type == 'cuda', 'Can use perform_everything_on_gpu=True only when device=\"cuda\"'\n",
    "\n",
    "    network = network.to(device)\n",
    "    network.eval()\n",
    "\n",
    "    empty_cache(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Autocast is a little bitch.\n",
    "        # If the device_type is 'cpu' then it's slow as heck and needs to be disabled.\n",
    "        # If the device_type is 'mps' then it will complain that mps is not implemented, even if enabled=False is set. Whyyyyyyy. (this is why we don't make use of enabled=False)\n",
    "        # So autocast will only be active if we have a cuda device.\n",
    "        with torch.autocast(device.type, enabled=True) if device.type == 'cuda' else dummy_context():\n",
    "            assert len(input_image.shape) == 4, 'input_image must be a 4D np.ndarray or torch.Tensor (c, x, y, z)'\n",
    "\n",
    "            if not torch.cuda.is_available():\n",
    "                if perform_everything_on_gpu:\n",
    "                    print('WARNING! \"perform_everything_on_gpu\" was True but cuda is not available! Set it to False...')\n",
    "                perform_everything_on_gpu = False\n",
    "\n",
    "            results_device = device if perform_everything_on_gpu else torch.device('cpu')\n",
    "\n",
    "            if verbose: print(\"step_size:\", tile_step_size)\n",
    "            if verbose: print(\"mirror_axes:\", mirror_axes)\n",
    "\n",
    "            if not isinstance(input_image, torch.Tensor):\n",
    "                # pytorch will warn about the numpy array not being writable. This doesnt matter though because we\n",
    "                # just want to read it. Suppress the warning in order to not confuse users...\n",
    "                with warnings.catch_warnings():\n",
    "                    warnings.simplefilter(\"ignore\")\n",
    "                    input_image = torch.from_numpy(input_image)\n",
    "\n",
    "            # if input_image is smaller than tile_size we need to pad it to tile_size.\n",
    "            data, slicer_revert_padding = pad_nd_image(input_image, tile_size, 'constant', {'value': 0}, True, None)\n",
    "            #data_vessel, slicer_revert_padding = pad_nd_image(vessel_image, data.shape, 'constant', {'value': 0}, True, None)\n",
    "            \n",
    "            # 計算需要補齊的大小:tensorA = torch.randn(1, 127, 512, 512)  # 假設是 tensorA\n",
    "            pad_height = (data.shape[2] - vessel_image.shape[2])  # 需要補齊的高度 (上和下)\n",
    "            pad_width = (data.shape[3] - vessel_image.shape[3])  # 需要補齊的寬度 (左和右)\n",
    "            pad_depth = (data.shape[1] - vessel_image.shape[1])  # 需要補齊的深度 (前和後)\n",
    "\n",
    "            # 計算每一維的補齊值\n",
    "            # pad順序為 (左, 右, 上, 下, 前, 後)\n",
    "            padding = (pad_width // 2, pad_width - pad_width // 2,  # 深度（前後）\n",
    "                       pad_height // 2, pad_height - pad_height // 2,  # 高度（上下）\n",
    "                       pad_depth, 0)  # 寬度（左右）\n",
    "            \n",
    "            # 使用 F.pad 進行補齊\n",
    "            data_vessel = F.pad(vessel_image, padding, mode='constant', value=0)\n",
    "                        \n",
    "            print(\"step_size:\", tile_step_size) #0.5 => 步距重疊率\n",
    "            print(\"mirror_axes:\", mirror_axes) #還是0\n",
    "            print('data pad後的大小:', data.shape) #這邊還是512\n",
    "            print('data_vessel pad後的大小:', data_vessel.shape) #這邊還是512\n",
    "\n",
    "            if use_gaussian:\n",
    "                gaussian = torch.from_numpy(\n",
    "                    compute_gaussian(tile_size, sigma_scale=1. / 8)) if precomputed_gaussian is None else precomputed_gaussian\n",
    "                gaussian = gaussian.half()\n",
    "                # make sure nothing is rounded to zero or we get division by zero :-(\n",
    "                mn = gaussian.min()\n",
    "                if mn == 0:\n",
    "                    gaussian.clip_(min=mn)\n",
    "            else:\n",
    "                # 不使用 gaussian 時，設置為 None 以節省記憶體\n",
    "                gaussian = None\n",
    "                    \n",
    "            slicers = get_sliding_window_generator(data.shape[1:], tile_size, tile_step_size, verbose=verbose)\n",
    "\n",
    "            # preallocate results and num_predictions. Move everything to the correct device\n",
    "            try:\n",
    "                predicted_logits = torch.zeros((num_segmentation_heads, *data.shape[1:]), dtype=torch.half,\n",
    "                                               device=results_device)\n",
    "                n_predictions = torch.zeros(data.shape[1:], dtype=torch.half,\n",
    "                                            device=results_device)\n",
    "                if use_gaussian and gaussian is not None:\n",
    "                    gaussian = gaussian.to(results_device)\n",
    "            except RuntimeError:\n",
    "                # sometimes the stuff is too large for GPUs. In that case fall back to CPU\n",
    "                results_device = torch.device('cpu')\n",
    "                predicted_logits = torch.zeros((num_segmentation_heads, *data.shape[1:]), dtype=torch.half,\n",
    "                                               device=results_device)\n",
    "                n_predictions = torch.zeros(data.shape[1:], dtype=torch.half,\n",
    "                                            device=results_device)\n",
    "                if use_gaussian and gaussian is not None:\n",
    "                    gaussian = gaussian.to(results_device)\n",
    "            finally:\n",
    "                empty_cache(device)\n",
    "\n",
    "            if use_gaussian:\n",
    "                # 使用 gaussian 權重的情況：需要處理所有 patches\n",
    "                # 收集所有需要處理的 patches 和對應的 slicers\n",
    "                patches_to_process = []\n",
    "                slicers_to_process = []\n",
    "                \n",
    "                for sl in slicers:\n",
    "                    #只預測有血管的地方\n",
    "                    if torch.sum(data_vessel[sl]) > 0:\n",
    "                        workon = data[sl][None]\n",
    "                        patches_to_process.append(workon)\n",
    "                        slicers_to_process.append(sl)\n",
    "                    else:\n",
    "                        # 對於沒有血管的地方，直接設置為零\n",
    "                        prediction = torch.zeros((num_segmentation_heads, *tile_size)).to(results_device)\n",
    "                        predicted_logits[sl] += prediction * gaussian\n",
    "                        n_predictions[sl[1:]] += gaussian\n",
    "                \n",
    "                # 批次處理有血管的 patches\n",
    "                if len(patches_to_process) > 0:\n",
    "                    if verbose:\n",
    "                        print(f\"[Gaussian模式] 處理 {len(patches_to_process)} 個有血管的 patches，使用 batch_size={batch_size}\")\n",
    "                    \n",
    "                    for i in range(0, len(patches_to_process), batch_size):\n",
    "                        batch_end = min(i + batch_size, len(patches_to_process))\n",
    "                        batch_patches = patches_to_process[i:batch_end]\n",
    "                        batch_slicers = slicers_to_process[i:batch_end]\n",
    "                        \n",
    "                        # 將 batch 中的 patches 組合成一個 tensor\n",
    "                        batch_tensor = torch.cat(batch_patches, dim=0).to(device, non_blocking=False)\n",
    "                        \n",
    "                        # 批次預測\n",
    "                        #start_time_batch = time.time()\n",
    "                        batch_predictions = maybe_mirror_and_predict(network, batch_tensor, mirror_axes).to(results_device)\n",
    "                        #print(f\"[Done] maybe_mirror_and_predict no. {i} spend {time.time() - start_time_batch:.3f} sec\")\n",
    "                        \n",
    "                        \n",
    "                        # 處理每個預測結果\n",
    "                        for j, (prediction, sl) in enumerate(zip(batch_predictions, batch_slicers)):\n",
    "                            # prediction 這邊直接套用 softmax 去正規化輸出\n",
    "                            prediction = torch.softmax(prediction, 0)\n",
    "                            \n",
    "                            # 使用高斯權重\n",
    "                            predicted_logits[sl] += prediction * gaussian\n",
    "                            n_predictions[sl[1:]] += gaussian\n",
    "            else:\n",
    "                # 不使用 gaussian 權重的情況：可以完全跳過沒有血管的區域，大幅加速\n",
    "                patches_to_process = []\n",
    "                slicers_to_process = []\n",
    "                all_slicers = list(slicers)  # 先轉換成 list 以便重複使用\n",
    "                \n",
    "                # 只收集有血管的 patches，完全跳過空白區域\n",
    "                for sl in all_slicers:\n",
    "                    if torch.sum(data_vessel[sl]) > 0:\n",
    "                        workon = data[sl][None]\n",
    "                        patches_to_process.append(workon)\n",
    "                        slicers_to_process.append(sl)\n",
    "                \n",
    "                if len(patches_to_process) > 0:\n",
    "                    if verbose:\n",
    "                        total_patches = len(all_slicers)\n",
    "                        print(f\"[非Gaussian模式] 跳過 {total_patches - len(patches_to_process)} 個空白 patches，只處理 {len(patches_to_process)} 個有血管的 patches，使用 batch_size={batch_size}\")\n",
    "                    \n",
    "                    for i in range(0, len(patches_to_process), batch_size):\n",
    "                        batch_end = min(i + batch_size, len(patches_to_process))\n",
    "                        batch_patches = patches_to_process[i:batch_end]\n",
    "                        batch_slicers = slicers_to_process[i:batch_end]\n",
    "                        \n",
    "                        # 將 batch 中的 patches 組合成一個 tensor\n",
    "                        batch_tensor = torch.cat(batch_patches, dim=0).to(device, non_blocking=False)\n",
    "                        \n",
    "                        # 批次預測\n",
    "                        start_time_batch = time.time()\n",
    "                        batch_predictions = maybe_mirror_and_predict(network, batch_tensor, mirror_axes).to(results_device)\n",
    "                        print(f\"[Done] maybe_mirror_and_predict no. {i} spend {time.time() - start_time_batch:.3f} sec\")\n",
    "                        \n",
    "                        # 處理每個預測結果\n",
    "                        for j, (prediction, sl) in enumerate(zip(batch_predictions, batch_slicers)):\n",
    "                            # prediction 這邊直接套用 softmax 去正規化輸出\n",
    "                            prediction = torch.softmax(prediction, 0)\n",
    "                            \n",
    "                            # 不使用高斯權重，直接累加\n",
    "                            predicted_logits[sl] += prediction\n",
    "                            n_predictions[sl[1:]] += 1\n",
    "                \n",
    "                # 對於完全沒有血管的區域，設置一個預設的背景預測\n",
    "                # 這樣可以避免這些區域保持未初始化狀態\n",
    "                if len(patches_to_process) < len(all_slicers):\n",
    "                    # 創建背景預測：[1.0, 0.0] 表示背景類別的機率為 1\n",
    "                    background_prediction = torch.zeros((num_segmentation_heads, *tile_size), device=results_device)\n",
    "                    background_prediction[0] = 1.0  # 背景類別設為 1\n",
    "                    \n",
    "                    for sl in all_slicers:\n",
    "                        if torch.sum(data_vessel[sl]) == 0:  # 沒有血管的區域\n",
    "                            predicted_logits[sl] += background_prediction\n",
    "                            n_predictions[sl[1:]] += 1\n",
    "\n",
    "            # 安全除法，避免除以零產生 NaN\n",
    "            # 對於 n_predictions 為 0 的位置，保持 predicted_logits 為 0\n",
    "            mask = n_predictions > 0\n",
    "            predicted_logits = torch.where(mask.unsqueeze(0), \n",
    "                                         predicted_logits / n_predictions.unsqueeze(0), \n",
    "                                         predicted_logits)\n",
    "            \n",
    "            if verbose:\n",
    "                zero_predictions = torch.sum(n_predictions == 0).item()\n",
    "                total_voxels = torch.numel(n_predictions)\n",
    "                if zero_predictions > 0:\n",
    "                    print(f\"警告：有 {zero_predictions}/{total_voxels} 個體素沒有被任何 patch 覆蓋到\")\n",
    "                    print(f\"這些位置將保持為零值（通常是影像邊緣或完全沒有血管的區域）\")\n",
    "            #print('predicted_logits.shape:', predicted_logits.shape, ' data_vessel.shape:', data_vessel.shape)\n",
    "            #predicted_logits.shape: torch.Size([2, 127, 512, 512])  data_vessel.shape: torch.Size([1, 127, 512, 512])\n",
    "            \n",
    "            #只與vessel相乘\n",
    "            #print('predicted_logits.shape:', predicted_logits.shape, ' data_vessel.shape:', data_vessel.shape)\n",
    "            #predicted_logits = predicted_logits[1, :, :, :] * data_vessel.to(results_device)\n",
    "            #print('predicted_logits.shape:', predicted_logits.shape)\n",
    "            # 使用 unsqueeze 增加一個維度，放在最前面\n",
    "            #predicted_logits = predicted_logits[0, :, :, :].unsqueeze(0)\n",
    "            #predicted_logits = data_vessel.to(results_device)\n",
    "                        \n",
    "            #與vessel相乘\n",
    "            repeat_vessel = data_vessel.repeat(2, 1, 1, 1)\n",
    "            predicted_logits = predicted_logits * repeat_vessel.to(results_device)\n",
    "            #predicted_logits = repeat_vessel.to(results_device)            \n",
    "\n",
    "    empty_cache(device)\n",
    "    return predicted_logits[tuple([slice(None), *slicer_revert_padding[1:]])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15aafe06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Union, List\n",
    "import numpy as np\n",
    "#from nibabel import io_orientation\n",
    "\n",
    "from nnunetv2.imageio.base_reader_writer import BaseReaderWriter\n",
    "import nibabel as nib\n",
    "\n",
    "def write_probabilities(seg, output_fname, img_nii):\n",
    "    # revert transpose\n",
    "    seg = seg.transpose((2, 1, 0)).astype(np.float32)\n",
    "    \n",
    "    affine = img_nii.affine\n",
    "    header = img_nii.header.copy()\n",
    "    new_nii = nib.nifti1.Nifti1Image(seg, affine, header=header)\n",
    "    \n",
    "    nib.save(new_nii, output_fname) \n",
    "    #nibabel.save(seg_nib, output_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c222b42",
   "metadata": {},
   "source": [
    "## 最需要改的地方2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af4b7a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from copy import deepcopy\n",
    "from typing import Union, List\n",
    "\n",
    "import numpy as np\n",
    "from acvl_utils.cropping_and_padding.bounding_boxes import bounding_box_to_slice\n",
    "from batchgenerators.utilities.file_and_folder_operations import load_json, isfile, save_pickle\n",
    "from nnunetv2.utilities.plans_handling.plans_handler import PlansManager, ConfigurationManager\n",
    "\n",
    "def export_prediction_probabilities(predicted_array_or_file: Union[np.ndarray, str], properties_dict: dict,\n",
    "                                    vessel_image, img_nii,\n",
    "                                    configuration_manager: ConfigurationManager,\n",
    "                                    plans_manager: PlansManager,\n",
    "                                    dataset_json_dict_or_file: Union[dict, str], output_file_truncated: str,\n",
    "                                    save_probabilities: bool = False):\n",
    "    \n",
    "    if isinstance(predicted_array_or_file, str):\n",
    "        tmp = deepcopy(predicted_array_or_file)\n",
    "        if predicted_array_or_file.endswith('.npy'):\n",
    "            predicted_array_or_file = np.load(predicted_array_or_file)\n",
    "        elif predicted_array_or_file.endswith('.npz'):\n",
    "            predicted_array_or_file = np.load(predicted_array_or_file)['softmax']\n",
    "        os.remove(tmp)\n",
    "\n",
    "    predicted_array_or_file = predicted_array_or_file.astype(np.float32)\n",
    "    print('before')\n",
    "    print('predicted_array_or_file.shape:', predicted_array_or_file.shape)\n",
    "    print('np.max(predicted_array_or_file):', np.max(predicted_array_or_file))\n",
    "    print('np.median(predicted_array_or_file):', np.median(predicted_array_or_file))\n",
    "\n",
    "    if isinstance(dataset_json_dict_or_file, str):\n",
    "        dataset_json_dict_or_file = load_json(dataset_json_dict_or_file)\n",
    "\n",
    "    # resample to original shape\n",
    "    current_spacing = configuration_manager.spacing if \\\n",
    "        len(configuration_manager.spacing) == \\\n",
    "        len(properties_dict['shape_after_cropping_and_before_resampling']) else \\\n",
    "        [properties_dict['spacing'][0], *configuration_manager.spacing]\n",
    "    \n",
    "    print('properties_dict[shape_after_cropping_and_before_resampling]:', properties_dict['shape_after_cropping_and_before_resampling'])\n",
    "    print('current_spacing:', current_spacing)\n",
    "    print('properties_dict[spacing]:', properties_dict['spacing'])\n",
    "    \n",
    "    predicted_array_or_file = configuration_manager.resampling_fn_probabilities(predicted_array_or_file,\n",
    "                                            properties_dict['shape_after_cropping_and_before_resampling'],\n",
    "                                            current_spacing,\n",
    "                                            properties_dict['spacing'])\n",
    "    \n",
    "    print('after')\n",
    "    print('predicted_array_or_file.shape:', predicted_array_or_file.shape)\n",
    "    print('np.max(predicted_array_or_file):', np.max(predicted_array_or_file))\n",
    "    print('np.median(predicted_array_or_file):', np.median(predicted_array_or_file))    \n",
    "    \n",
    "    \n",
    "    label_manager = plans_manager.get_label_manager(dataset_json_dict_or_file)\n",
    "    \n",
    "    \"\"\"\n",
    "    segmentation = label_manager.convert_logits_to_segmentation(predicted_array_or_file)\n",
    "\n",
    "    # put result in bbox (revert cropping)\n",
    "    segmentation_reverted_cropping = np.zeros(properties_dict['shape_before_cropping'], dtype=np.uint8)\n",
    "    slicer = bounding_box_to_slice(properties_dict['bbox_used_for_cropping'])\n",
    "    segmentation_reverted_cropping[slicer] = segmentation\n",
    "    del segmentation\n",
    "    print('segmentation_reverted_cropping.shape:', segmentation_reverted_cropping.shape)\n",
    "\n",
    "    # revert transpose\n",
    "    segmentation_reverted_cropping = segmentation_reverted_cropping.transpose(plans_manager.transpose_backward)\n",
    "    \"\"\"\n",
    "    \n",
    "    # save\n",
    "    # probabilities are already resampled\n",
    "\n",
    "    # apply nonlinearity\n",
    "#     predicted_array_or_file = label_manager.apply_inference_nonlin(predicted_array_or_file)\n",
    "\n",
    "#     print('apply nonlinearity')\n",
    "#     print('predicted_array_or_file.shape:', predicted_array_or_file.shape)\n",
    "#     print('np.max(predicted_array_or_file):', np.max(predicted_array_or_file))\n",
    "#     print('np.median(predicted_array_or_file):', np.median(predicted_array_or_file))\n",
    "    \n",
    "    # revert cropping\n",
    "    probs_reverted_cropping = label_manager.revert_cropping(predicted_array_or_file,\n",
    "                                                            properties_dict['bbox_used_for_cropping'],\n",
    "                                                            properties_dict['shape_before_cropping'])\n",
    "    \n",
    "    print('revert cropping')\n",
    "    print('probs_reverted_cropping.shape:', probs_reverted_cropping.shape)\n",
    "    print('np.max(probs_reverted_cropping):', np.max(probs_reverted_cropping))\n",
    "    print('np.median(probs_reverted_cropping):', np.median(probs_reverted_cropping))\n",
    "    \n",
    "    probs_reverted_cropping = np.expand_dims(probs_reverted_cropping[1,:,:,:], axis=0)\n",
    "    \n",
    "    if probs_reverted_cropping is None:\n",
    "        raise ValueError(\"Reverting cropping failed, 'probs_reverted_cropping' is None.\")\n",
    "        \n",
    "    # $revert transpose\n",
    "    probs_reverted_cropping = probs_reverted_cropping.transpose([0] + [i + 1 for i in\n",
    "                                                                plans_manager.transpose_backward])\n",
    "    \n",
    "#     print('revert transpose')\n",
    "#     print('probs_reverted_cropping.shape:', probs_reverted_cropping.shape)\n",
    "#     print('np.max(probs_reverted_cropping):', np.max(probs_reverted_cropping))\n",
    "#     print('np.median(probs_reverted_cropping):', np.median(probs_reverted_cropping))\n",
    "    #np.savez_compressed(output_file_truncated + '.npz', probabilities=probs_reverted_cropping)\n",
    "    #save_pickle(properties_dict, output_file_truncated + '.pkl')\n",
    "    #del probs_reverted_cropping\n",
    "    #del predicted_array_or_file\n",
    "\n",
    "#     rw = plans_manager.image_reader_writer_class()\n",
    "#     rw.write_seg(probs_reverted_cropping[0,:,:,:], output_file_truncated + dataset_json_dict_or_file['file_ending'],\n",
    "#                            properties_dict)\n",
    "    \n",
    "    #print('properties_dict:', properties_dict)\n",
    "    #這邊用額外的自寫輸出成nifti方式好惹\n",
    "    write_probabilities(probs_reverted_cropping[0,:,:,:], output_file_truncated + dataset_json_dict_or_file['file_ending'], img_nii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62a505fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_from_raw_data(list_of_lists_or_source_folder: Union[str, List[List[str]]],\n",
    "                          Mask_list_of_lists_or_Mask_folder: Union[str, List[List[str]]],\n",
    "                          output_folder: str,\n",
    "                          model_training_output_dir: str,\n",
    "                          use_folds: Union[Tuple[int, ...], str] = None,\n",
    "                          tile_step_size: float = 0.5,\n",
    "                          use_gaussian: bool = True,\n",
    "                          use_mirroring: bool = True,\n",
    "                          perform_everything_on_gpu: bool = True,\n",
    "                          verbose: bool = True,\n",
    "                          save_probabilities: bool = False,\n",
    "                          overwrite: bool = True,\n",
    "                          checkpoint_name: str = 'checkpoint_final.pth',\n",
    "                          num_processes_preprocessing: int = default_num_processes,\n",
    "                          num_processes_segmentation_export: int = default_num_processes,\n",
    "                          folder_with_segs_from_prev_stage: str = None,\n",
    "                          num_parts: int = 1,\n",
    "                          part_id: int = 0,\n",
    "                          desired_gpu_index : int = 0,\n",
    "                          device: torch.device = torch.device('cuda'),\n",
    "                          batch_size: int = 1):\n",
    "    print(\"\\n#######################################################################\\nPlease cite the following paper \"\n",
    "          \"when using nnU-Net:\\n\"\n",
    "          \"Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). \"\n",
    "          \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. \"\n",
    "          \"Nature methods, 18(2), 203-211.\\n#######################################################################\\n\")\n",
    "\n",
    "    # 假設你想要在某個特定 GPU 上執行（例如GPU 1，編號從0開始）\n",
    "    #desired_gpu_index = 0  # 修改此處來指定你希望使用的 GPU 編號\n",
    "\n",
    "    # 檢查是否為 CUDA 設備，並指定 GPU 編號\n",
    "    if device.type == 'cuda':\n",
    "        device = torch.device(type='cuda', index=desired_gpu_index)  # 根據 desired_gpu_index 設定具體的 GPU\n",
    "\n",
    "    if device.type != 'cuda':\n",
    "        perform_everything_on_gpu = False\n",
    "\n",
    "    # let's store the input arguments so that its clear what was used to generate the prediction\n",
    "    my_init_kwargs = {}\n",
    "    for k in inspect.signature(predict_from_raw_data).parameters.keys():\n",
    "        my_init_kwargs[k] = locals()[k]\n",
    "    my_init_kwargs = deepcopy(my_init_kwargs)  # let's not unintentionally change anything in-place. Take this as a\n",
    "    # safety precaution.\n",
    "    recursive_fix_for_json_export(my_init_kwargs)\n",
    "    maybe_mkdir_p(output_folder)\n",
    "    save_json(my_init_kwargs, join(output_folder, 'predict_from_raw_data_args.json'))\n",
    "\n",
    "    if use_folds is None:\n",
    "        use_folds = auto_detect_available_folds(model_training_output_dir, checkpoint_name)\n",
    "\n",
    "    # load all the stuff we need from the model_training_output_dir\n",
    "    # 這邊獲得都是模型的參數\n",
    "    parameters, configuration_manager, inference_allowed_mirroring_axes, \\\n",
    "    plans_manager, dataset_json, network, trainer_name = \\\n",
    "        load_what_we_need(model_training_output_dir, use_folds, checkpoint_name)\n",
    "    \n",
    "    print('總共有幾個網路parameters(同時拿幾個網路預測):', len(parameters)) #用來得知網路參數有幾個\n",
    "    \n",
    "    #這邊先不用到\n",
    "    \"\"\"\n",
    "    # check if we need a prediction from the previous stage\n",
    "    if configuration_manager.previous_stage_name is not None:\n",
    "        if folder_with_segs_from_prev_stage is None:\n",
    "            print(f'WARNING: The requested configuration is a cascaded model and requires predctions from the '\n",
    "                  f'previous stage! folder_with_segs_from_prev_stage was not provided. Trying to run the '\n",
    "                  f'inference of the previous stage...')\n",
    "            folder_with_segs_from_prev_stage = join(output_folder,\n",
    "                                                    f'prediction_{configuration_manager.previous_stage_name}')\n",
    "            predict_from_raw_data(list_of_lists_or_source_folder,\n",
    "                                  folder_with_segs_from_prev_stage,\n",
    "                                  get_output_folder(plans_manager.dataset_name,\n",
    "                                                    trainer_name,\n",
    "                                                    plans_manager.plans_name,\n",
    "                                                    configuration_manager.previous_stage_name),\n",
    "                                  use_folds, tile_step_size, use_gaussian, use_mirroring, perform_everything_on_gpu,\n",
    "                                  verbose, False, overwrite, checkpoint_name,\n",
    "                                  num_processes_preprocessing, num_processes_segmentation_export, None,\n",
    "                                  num_parts=num_parts, part_id=part_id, device=device)\n",
    "    \"\"\"\n",
    "\n",
    "    # sort out input and output filenames\n",
    "    if isinstance(list_of_lists_or_source_folder, str):\n",
    "        list_of_lists_or_source_folder = create_lists_from_splitted_dataset_folder(list_of_lists_or_source_folder,\n",
    "                                                                                   dataset_json['file_ending'])\n",
    "        Mask_list_of_lists_or_Mask_folder = create_lists_from_splitted_dataset_folder(Mask_list_of_lists_or_Mask_folder,\n",
    "                                                                                   dataset_json['file_ending'])\n",
    "    print(f'There are {len(list_of_lists_or_source_folder)} cases in the source folder')\n",
    "    list_of_lists_or_source_folder = list_of_lists_or_source_folder[part_id::num_parts]\n",
    "    caseids = [os.path.basename(i[0])[:-(len(dataset_json['file_ending']) + 5)] for i in list_of_lists_or_source_folder]\n",
    "    print(f'I am process {part_id} out of {num_parts} (max process ID is {num_parts - 1}, we start counting with 0!)')\n",
    "    print(f'There are {len(caseids)} cases that I would like to predict')\n",
    "    print('list_of_lists_or_source_folder example:', list_of_lists_or_source_folder[0])\n",
    "    print('Mask_list_of_lists_or_Mask_folder:', Mask_list_of_lists_or_Mask_folder[0])\n",
    "\n",
    "    output_filename_truncated = [join(output_folder, i) for i in caseids]\n",
    "    seg_from_prev_stage_files = [join(folder_with_segs_from_prev_stage, i + dataset_json['file_ending']) if\n",
    "                                 folder_with_segs_from_prev_stage is not None else None for i in caseids]\n",
    "    # remove already predicted files form the lists\n",
    "    if not overwrite:\n",
    "        tmp = [isfile(i + dataset_json['file_ending']) for i in output_filename_truncated]\n",
    "        not_existing_indices = [i for i, j in enumerate(tmp) if not j]\n",
    "\n",
    "        output_filename_truncated = [output_filename_truncated[i] for i in not_existing_indices]\n",
    "        list_of_lists_or_source_folder = [list_of_lists_or_source_folder[i] for i in not_existing_indices]\n",
    "        seg_from_prev_stage_files = [seg_from_prev_stage_files[i] for i in not_existing_indices]\n",
    "        print(f'overwrite was set to {overwrite}, so I am only working on cases that haven\\'t been predicted yet. '\n",
    "              f'That\\'s {len(not_existing_indices)} cases.')\n",
    "        # caseids = [caseids[i] for i in not_existing_indices]\n",
    "\n",
    "    # placing this into a separate function doesnt make sense because it needs so many input variables...\n",
    "    preprocessor = configuration_manager.preprocessor_class(verbose=verbose)\n",
    "    # hijack batchgenerators, yo\n",
    "    # we use the multiprocessing of the batchgenerators dataloader to handle all the background worker stuff. This\n",
    "    # way we don't have to reinvent the wheel here.\n",
    "    num_processes = max(1, min(num_processes_preprocessing, len(list_of_lists_or_source_folder)))\n",
    "    #print('seg_from_prev_stage_files:', seg_from_prev_stage_files) #這邊原本都是None\n",
    "    \n",
    "    ppa = PreprocessAdapter(list_of_lists_or_source_folder, Mask_list_of_lists_or_Mask_folder, preprocessor,\n",
    "                            output_filename_truncated, plans_manager, dataset_json,\n",
    "                            configuration_manager, num_processes)\n",
    "    mta = MultiThreadedAugmenter(ppa, NumpyToTensor(), num_processes, 1, None, pin_memory=device.type == 'cuda')\n",
    "    \n",
    "    # precompute gaussian\n",
    "    inference_gaussian = torch.from_numpy(\n",
    "        compute_gaussian(configuration_manager.patch_size)).half()\n",
    "    if perform_everything_on_gpu:\n",
    "        inference_gaussian = inference_gaussian.to(device)\n",
    "    print('inference_gaussian.shape:', inference_gaussian.shape)\n",
    "\n",
    "    # num seg heads is needed because we need to preallocate the results in predict_sliding_window_return_logits\n",
    "    label_manager = plans_manager.get_label_manager(dataset_json)\n",
    "    num_seg_heads = label_manager.num_segmentation_heads\n",
    "    #num_seg_heads 這邊為 0背景 1.動脈瘤，所以為2\n",
    "    #print('num_seg_heads:', num_seg_heads)\n",
    "\n",
    "    # go go go\n",
    "    # spawn allows the use of GPU in the background process in case somebody wants to do this. Not recommended. Trust me.\n",
    "    # export_pool = multiprocessing.get_context('spawn').Pool(num_processes_segmentation_export)\n",
    "    # export_pool = multiprocessing.Pool(num_processes_segmentation_export)\n",
    "    with multiprocessing.get_context(\"spawn\").Pool(num_processes_segmentation_export) as export_pool:\n",
    "        network = network.to(device)\n",
    "\n",
    "        r = []\n",
    "        with torch.no_grad():\n",
    "            for preprocessed, nii_path in zip(mta, list_of_lists_or_source_folder):\n",
    "                start_time = time.time()\n",
    "                data = preprocessed['data']\n",
    "                data_vessel = preprocessed['seg']\n",
    "                #print('data:', data.shape, 'data_vessel:', data_vessel.shape)\n",
    "                #讀取nifti只是為了affine\n",
    "                img_nii = nib.load(str(nii_path[0]))\n",
    "                if isinstance(data, str):\n",
    "                    delfile = data\n",
    "                    data = torch.from_numpy(np.load(data))\n",
    "                    os.remove(delfile)\n",
    "                \n",
    "                if isinstance(data_vessel, str):\n",
    "                    data_vessel = torch.from_numpy(np.load(data_vessel))\n",
    "\n",
    "                ofile = preprocessed['ofile']\n",
    "                print(f'\\nPredicting {os.path.basename(ofile)}:')\n",
    "                print(f'perform_everything_on_gpu: {perform_everything_on_gpu}')\n",
    "                print('configuration_manager.patch_size:', configuration_manager.patch_size)\n",
    "                \n",
    "                properties = preprocessed['data_properites'] #組回nifti的參數\n",
    "\n",
    "                # let's not get into a runaway situation where the GPU predicts so fast that the disk has to b swamped with\n",
    "                # npy files\n",
    "                proceed = not check_workers_busy(export_pool, r, allowed_num_queued=len(export_pool._pool))\n",
    "                while not proceed:\n",
    "                    sleep(1)\n",
    "                    proceed = not check_workers_busy(export_pool, r, allowed_num_queued=len(export_pool._pool))\n",
    "\n",
    "                # we have some code duplication here but this allows us to run with perform_everything_on_gpu=True as\n",
    "                # default and not have the entire program crash in case of GPU out of memory. Neat. That should make\n",
    "                # things a lot faster for some datasets.\n",
    "                prediction = None\n",
    "                overwrite_perform_everything_on_gpu = perform_everything_on_gpu\n",
    "                #目前是走perform_everything_on_gpu = 1\n",
    "                if perform_everything_on_gpu:\n",
    "                    try:\n",
    "                        for params in parameters:\n",
    "                            network.load_state_dict(params)\n",
    "                            if prediction is None:\n",
    "                                prediction = predict_sliding_window_return_logits(\n",
    "                            network, data, data_vessel, num_seg_heads,\n",
    "                            configuration_manager.patch_size,\n",
    "                            mirror_axes=inference_allowed_mirroring_axes if use_mirroring else None,\n",
    "                            tile_step_size=tile_step_size,\n",
    "                            use_gaussian=use_gaussian,\n",
    "                            precomputed_gaussian=inference_gaussian,\n",
    "                            perform_everything_on_gpu=perform_everything_on_gpu,\n",
    "                            verbose=verbose,\n",
    "                            device=device,\n",
    "                            batch_size=batch_size)\n",
    "                            else:\n",
    "                                prediction += predict_sliding_window_return_logits(\n",
    "                                    network, data, data_vessel, num_seg_heads,\n",
    "                                    configuration_manager.patch_size,\n",
    "                                    mirror_axes=inference_allowed_mirroring_axes if use_mirroring else None,\n",
    "                                    tile_step_size=tile_step_size,\n",
    "                                    use_gaussian=use_gaussian,\n",
    "                                    precomputed_gaussian=inference_gaussian,\n",
    "                                    perform_everything_on_gpu=perform_everything_on_gpu,\n",
    "                                    verbose=verbose,\n",
    "                                    device=device,\n",
    "                                    batch_size=batch_size)\n",
    "                            if len(parameters) > 1:\n",
    "                                prediction /= len(parameters)\n",
    "\n",
    "                    except RuntimeError:\n",
    "                        print('Prediction with perform_everything_on_gpu=True failed due to insufficient GPU memory. '\n",
    "                              'Falling back to perform_everything_on_gpu=False. Not a big deal, just slower...')\n",
    "                        print('Error:')\n",
    "                        traceback.print_exc()\n",
    "                        prediction = None\n",
    "                        overwrite_perform_everything_on_gpu = False\n",
    "\n",
    "                #如果gpu失敗，走以下\n",
    "                if prediction is None:\n",
    "                    for params in parameters:\n",
    "                        network.load_state_dict(params)\n",
    "                        if prediction is None:\n",
    "                            prediction = predict_sliding_window_return_logits(\n",
    "                                network, data, data_vessel, num_seg_heads,\n",
    "                                configuration_manager.patch_size,\n",
    "                                mirror_axes=inference_allowed_mirroring_axes if use_mirroring else None,\n",
    "                                tile_step_size=tile_step_size,\n",
    "                                use_gaussian=use_gaussian,\n",
    "                                precomputed_gaussian=inference_gaussian,\n",
    "                                perform_everything_on_gpu=perform_everything_on_gpu,\n",
    "                                verbose=verbose,\n",
    "                                device=device,\n",
    "                                batch_size=batch_size)\n",
    "                        else:\n",
    "                            prediction += predict_sliding_window_return_logits(\n",
    "                                network, data, data_vessel, num_seg_heads,\n",
    "                                configuration_manager.patch_size,\n",
    "                                mirror_axes=inference_allowed_mirroring_axes if use_mirroring else None,\n",
    "                                tile_step_size=tile_step_size,\n",
    "                                use_gaussian=use_gaussian,\n",
    "                                precomputed_gaussian=inference_gaussian,\n",
    "                                perform_everything_on_gpu=perform_everything_on_gpu,\n",
    "                                verbose=verbose,\n",
    "                                device=device,\n",
    "                                batch_size=batch_size)\n",
    "                        if len(parameters) > 1:\n",
    "                            prediction /= len(parameters)\n",
    "\n",
    "                print('Prediction done, transferring to CPU if needed')\n",
    "                prediction = prediction.to('cpu').numpy()\n",
    "                \n",
    "                #print('final prediction.shape:', prediction.shape)\n",
    "                if should_i_save_to_file(prediction, r, export_pool):\n",
    "                    print(\n",
    "                        'output is either too large for python process-process communication or all export workers are '\n",
    "                        'busy. Saving temporarily to file...')\n",
    "                    np.save(ofile + '.npy', prediction)\n",
    "                    prediction = ofile + '.npy'\n",
    "\n",
    "                \"\"\"\n",
    "                # this needs to go into background processes\n",
    "                # export_prediction(prediction, properties, configuration_name, plans, dataset_json, ofile,\n",
    "                #                   save_probabilities)\n",
    "                print('sending off prediction to background worker for resampling and export')\n",
    "                r.append(\n",
    "                    export_pool.starmap_async(\n",
    "                        export_prediction_probabilities, ((prediction, properties, configuration_manager, plans_manager,\n",
    "                                                          dataset_json, ofile, save_probabilities),)\n",
    "                    )\n",
    "                )\n",
    "                print(f'done with {os.path.basename(ofile)}')\n",
    "                \"\"\"\n",
    "                print(f\"[Done] spend {time.time() - start_time:.2f} sec\")\n",
    "                export_prediction_probabilities(prediction, properties, data_vessel, img_nii, configuration_manager, plans_manager,\n",
    "                                                dataset_json, ofile, save_probabilities)\n",
    "                \n",
    "                print(f\"[Done] spend {time.time() - start_time:.2f} sec\")\n",
    "        #[i.get() for i in r]\n",
    "\n",
    "    # we need these two if we want to do things with the predictions like for example apply postprocessing\n",
    "    shutil.copy(join(model_training_output_dir, 'dataset.json'), join(output_folder, 'dataset.json'))\n",
    "    shutil.copy(join(model_training_output_dir, 'plans.json'), join(output_folder, 'plans.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92513a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_entry_point():\n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser(description='Use this to run inference with nnU-Net. This function is used when '\n",
    "                                                 'you want to manually specify a folder containing a trained nnU-Net '\n",
    "                                                 'model. This is useful when the nnunet environment variables '\n",
    "                                                 '(nnUNet_results) are not set.')\n",
    "    parser.add_argument('-i', type=str, required=True,\n",
    "                        help='input folder. Remember to use the correct channel numberings for your files (_0000 etc). '\n",
    "                             'File endings must be the same as the training dataset!')\n",
    "    parser.add_argument('-v', type=str, required=True,\n",
    "                        help='input vessel folder. Remember to use the correct channel numberings for your files (_0000 etc). '\n",
    "                             'File endings must be the same as the training dataset!')\n",
    "    parser.add_argument('-o', type=str, required=True,\n",
    "                        help='Output folder. If it does not exist it will be created. Predicted segmentations will '\n",
    "                             'have the same name as their source images.')\n",
    "    parser.add_argument('-d', type=str, required=True,\n",
    "                        help='Dataset with which you would like to predict. You can specify either dataset name or id')\n",
    "    parser.add_argument('-p', type=str, required=False, default='nnUNetPlans',\n",
    "                        help='Plans identifier. Specify the plans in which the desired configuration is located. '\n",
    "                             'Default: nnUNetPlans')\n",
    "    parser.add_argument('-tr', type=str, required=False, default='nnUNetTrainer',\n",
    "                        help='What nnU-Net trainer class was used for training? Default: nnUNetTrainer')\n",
    "    parser.add_argument('-c', type=str, required=True,\n",
    "                        help='nnU-Net configuration that should be used for prediction. Config must be located '\n",
    "                             'in the plans specified with -p')\n",
    "    parser.add_argument('-f', nargs='+', type=str, required=False, default=(0, 1, 2, 3, 4),\n",
    "                        help='Specify the folds of the trained model that should be used for prediction. '\n",
    "                             'Default: (0, 1, 2, 3, 4)')\n",
    "    parser.add_argument('-step_size', type=float, required=False, default=0.5,\n",
    "                        help='Step size for sliding window prediction. The larger it is the faster but less accurate '\n",
    "                             'the prediction. Default: 0.5. Cannot be larger than 1. We recommend the default.')\n",
    "    parser.add_argument('--disable_tta', action='store_true', required=False, default=False,\n",
    "                        help='Set this flag to disable test time data augmentation in the form of mirroring. Faster, '\n",
    "                             'but less accurate inference. Not recommended.')\n",
    "    parser.add_argument('--verbose', action='store_true', help=\"Set this if you like being talked to. You will have \"\n",
    "                                                               \"to be a good listener/reader.\")\n",
    "    parser.add_argument('--save_probabilities', action='store_true',\n",
    "                        help='Set this to export predicted class \"probabilities\". Required if you want to ensemble '\n",
    "                             'multiple configurations.')\n",
    "    parser.add_argument('--continue_prediction', action='store_true',\n",
    "                        help='Continue an aborted previous prediction (will not overwrite existing files)')\n",
    "    parser.add_argument('-chk', type=str, required=False, default='checkpoint_final.pth',\n",
    "                        help='Name of the checkpoint you want to use. Default: checkpoint_final.pth')\n",
    "    parser.add_argument('-npp', type=int, required=False, default=3,\n",
    "                        help='Number of processes used for preprocessing. More is not always better. Beware of '\n",
    "                             'out-of-RAM issues. Default: 3')\n",
    "    parser.add_argument('-nps', type=int, required=False, default=3,\n",
    "                        help='Number of processes used for segmentation export. More is not always better. Beware of '\n",
    "                             'out-of-RAM issues. Default: 3')\n",
    "    parser.add_argument('-prev_stage_predictions', type=str, required=False, default=None,\n",
    "                        help='Folder containing the predictions of the previous stage. Required for cascaded models.')\n",
    "    parser.add_argument('-num_parts', type=int, required=False, default=1,\n",
    "                        help='Number of separate nnUNetv2_predict call that you will be making. Default: 1 (= this one '\n",
    "                             'call predicts everything)')\n",
    "    parser.add_argument('-part_id', type=int, required=False, default=0,\n",
    "                        help='If multiple nnUNetv2_predict exist, which one is this? IDs start with 0 can end with '\n",
    "                             'num_parts - 1. So when you submit 5 nnUNetv2_predict calls you need to set -num_parts '\n",
    "                             '5 and use -part_id 0, 1, 2, 3 and 4. Simple, right? Note: You are yourself responsible '\n",
    "                             'to make these run on separate GPUs! Use CUDA_VISIBLE_DEVICES (google, yo!)')\n",
    "    parser.add_argument('-desired_gpu_index', type=int, default=0, required=False, \n",
    "                        help=\"This to set which GPU ID!\")\n",
    "    parser.add_argument('-device', type=str, default='cuda', required=False,\n",
    "                        help=\"Use this to set the device the inference should run with. Available options are 'cuda' \"\n",
    "                             \"(GPU), 'cpu' (CPU) and 'mps' (Apple M1/M2). Do NOT use this to set which GPU ID! \"\n",
    "                             \"Use CUDA_VISIBLE_DEVICES=X nnUNetv2_predict [...] instead!\")\n",
    "    parser.add_argument('-batch_size', type=int, default=1, required=False,\n",
    "                        help=\"Batch size for sliding window prediction. Larger batch sizes can speed up inference \"\n",
    "                             \"but require more GPU memory. Default: 1\")    \n",
    "\n",
    "    args = parser.parse_args()\n",
    "    args.f = [i if i == 'all' else int(i) for i in args.f]\n",
    "\n",
    "    model_folder = get_output_folder(args.d, args.tr, args.p, args.c)\n",
    "\n",
    "    if not isdir(args.o):\n",
    "        maybe_mkdir_p(args.o)\n",
    "\n",
    "    # slightly passive agressive haha\n",
    "    assert args.part_id < args.num_parts, 'Do you even read the documentation? See nnUNetv2_predict -h.'\n",
    "\n",
    "    assert args.device in ['cpu', 'cuda',\n",
    "                           'mps'], f'-device must be either cpu, mps or cuda. Other devices are not tested/supported. Got: {args.device}.'\n",
    "    if args.device == 'cpu':\n",
    "        # let's allow torch to use hella threads\n",
    "        import multiprocessing\n",
    "        torch.set_num_threads(multiprocessing.cpu_count())\n",
    "        device = torch.device('cpu')\n",
    "    elif args.device == 'cuda':\n",
    "        # multithreading in torch doesn't help nnU-Net if run on GPU\n",
    "        torch.set_num_threads(1)\n",
    "        torch.set_num_interop_threads(1)\n",
    "        device = torch.device('cuda')\n",
    "    else:\n",
    "        device = torch.device('mps')\n",
    "\n",
    "    predict_from_raw_data(args.i,\n",
    "                          args.v,\n",
    "                          args.o,\n",
    "                          model_folder,\n",
    "                          args.f,\n",
    "                          args.step_size,\n",
    "                          use_gaussian=True,\n",
    "                          use_mirroring=not args.disable_tta,\n",
    "                          perform_everything_on_gpu=True,\n",
    "                          verbose=args.verbose,\n",
    "                          save_probabilities=args.save_probabilities,\n",
    "                          overwrite=not args.continue_prediction,\n",
    "                          checkpoint_name=args.chk,\n",
    "                          num_processes_preprocessing=args.npp,\n",
    "                          num_processes_segmentation_export=args.nps,\n",
    "                          folder_with_segs_from_prev_stage=args.prev_stage_predictions,\n",
    "                          num_parts=args.num_parts,\n",
    "                          part_id=args.part_id,\n",
    "                          desired_gpu_index = args.desired_gpu_index,\n",
    "                          device=device,\n",
    "                          batch_size=args.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "faa9261b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#######################################################################\n",
      "Please cite the following paper when using nnU-Net:\n",
      "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
      "#######################################################################\n",
      "\n",
      "總共有幾個網路parameters(同時拿幾個網路預測): 1\n",
      "There are 160 cases in the source folder\n",
      "I am process 0 out of 1 (max process ID is 0, we start counting with 0!)\n",
      "There are 160 cases that I would like to predict\n",
      "list_of_lists_or_source_folder example: ['/data/chuan/nnUNet/nnUNet_raw/Dataset121_DeepAneurysm/RSNA_Normalized_Image_Val_0_9925/DeepAneurysm_00001_0000.nii.gz']\n",
      "Mask_list_of_lists_or_Mask_folder: ['/data/chuan/nnUNet/nnUNet_raw/Dataset121_DeepAneurysm/RSNA_Vessel_Val_0_9925_ov0/DeepAneurysm_00001_0000.nii.gz']\n",
      "overwrite was set to False, so I am only working on cases that haven't been predicted yet. That's 160 cases.\n",
      "inference_gaussian.shape: torch.Size([32, 64, 64])\n",
      "using pin_memory on device 0\n",
      "old shape: (188, 512, 512), new_shape: [157 461 461], old_spacing: [0.4999987483024597, 0.3515625, 0.3515625], new_spacing: [0.5999996066093445, 0.3905999958515167, 0.3905999958515167], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7f48ae74d430>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "\n",
      "Predicting DeepAneurysm_00001:\n",
      "perform_everything_on_gpu: True\n",
      "configuration_manager.patch_size: [32, 64, 64]\n",
      "step_size: 0.25\n",
      "mirror_axes: None\n",
      "step_size: 0.25\n",
      "mirror_axes: None\n",
      "data pad後的大小: torch.Size([1, 157, 461, 461])\n",
      "data_vessel pad後的大小: torch.Size([1, 157, 461, 461])\n",
      "n_steps 11492, image size is torch.Size([157, 461, 461]), tile_size [32, 64, 64], tile_step_size 0.25\n",
      "steps:\n",
      "[[0, 8, 16, 23, 31, 39, 47, 55, 62, 70, 78, 86, 94, 102, 109, 117, 125], [0, 16, 32, 48, 64, 79, 95, 111, 127, 143, 159, 175, 191, 206, 222, 238, 254, 270, 286, 302, 318, 333, 349, 365, 381, 397], [0, 16, 32, 48, 64, 79, 95, 111, 127, 143, 159, 175, 191, 206, 222, 238, 254, 270, 286, 302, 318, 333, 349, 365, 381, 397]]\n",
      "[Gaussian模式] 處理 3489 個有血管的 patches，使用 batch_size=112\n",
      "Prediction done, transferring to CPU if needed\n",
      "[Done] spend 15.67 sec\n",
      "before\n",
      "predicted_array_or_file.shape: (2, 157, 461, 461)\n",
      "np.max(predicted_array_or_file): 1.0\n",
      "np.median(predicted_array_or_file): 0.0\n",
      "properties_dict[shape_after_cropping_and_before_resampling]: (188, 512, 512)\n",
      "current_spacing: [0.5999996066093445, 0.3905999958515167, 0.3905999958515167]\n",
      "properties_dict[spacing]: [0.4999987483024597, 0.3515625, 0.3515625]\n",
      "old shape: (201, 768, 696), new_shape: [168 512 464], old_spacing: [0.5000057220458984, 0.2604166567325592, 0.2604166567325592], new_spacing: [0.5999996066093445, 0.3905999958515167, 0.3905999958515167], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7f48ae74d430>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "after\n",
      "predicted_array_or_file.shape: (2, 188, 512, 512)\n",
      "np.max(predicted_array_or_file): 0.99976945\n",
      "np.median(predicted_array_or_file): 0.0\n",
      "revert cropping\n",
      "probs_reverted_cropping.shape: (2, 188, 512, 512)\n",
      "np.max(probs_reverted_cropping): 0.99976945\n",
      "np.median(probs_reverted_cropping): 0.0\n",
      "[Done] spend 22.90 sec\n",
      "\n",
      "Predicting DeepAneurysm_00002:\n",
      "perform_everything_on_gpu: True\n",
      "configuration_manager.patch_size: [32, 64, 64]\n",
      "step_size: 0.25\n",
      "mirror_axes: None\n",
      "step_size: 0.25\n",
      "mirror_axes: None\n",
      "data pad後的大小: torch.Size([1, 168, 512, 464])\n",
      "data_vessel pad後的大小: torch.Size([1, 168, 512, 464])\n",
      "n_steps 13572, image size is torch.Size([168, 512, 464]), tile_size [32, 64, 64], tile_step_size 0.25\n",
      "steps:\n",
      "[[0, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136], [0, 16, 32, 48, 64, 80, 96, 112, 128, 144, 160, 176, 192, 208, 224, 240, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448], [0, 16, 32, 48, 64, 80, 96, 112, 128, 144, 160, 176, 192, 208, 224, 240, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400]]\n",
      "[Gaussian模式] 處理 4248 個有血管的 patches，使用 batch_size=112\n",
      "old shape: (150, 512, 512), new_shape: [175 512 512], old_spacing: [0.699999988079071, 0.390625, 0.390625], new_spacing: [0.5999996066093445, 0.3905999958515167, 0.3905999958515167], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7f48ae74d430>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "Prediction done, transferring to CPU if needed\n",
      "[Done] spend 18.14 sec\n",
      "before\n",
      "predicted_array_or_file.shape: (2, 168, 512, 464)\n",
      "np.max(predicted_array_or_file): 1.0\n",
      "np.median(predicted_array_or_file): 0.0\n",
      "properties_dict[shape_after_cropping_and_before_resampling]: (201, 768, 696)\n",
      "current_spacing: [0.5999996066093445, 0.3905999958515167, 0.3905999958515167]\n",
      "properties_dict[spacing]: [0.5000057220458984, 0.2604166567325592, 0.2604166567325592]\n",
      "old shape: (194, 512, 512), new_shape: [162 461 461], old_spacing: [0.5, 0.3515625, 0.3515625], new_spacing: [0.5999996066093445, 0.3905999958515167, 0.3905999958515167], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7f48ae74d430>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "after\n",
      "predicted_array_or_file.shape: (2, 201, 768, 696)\n",
      "np.max(predicted_array_or_file): 0.9997334\n",
      "np.median(predicted_array_or_file): 0.0\n",
      "revert cropping\n",
      "probs_reverted_cropping.shape: (2, 201, 768, 696)\n",
      "np.max(probs_reverted_cropping): 0.9997334\n",
      "np.median(probs_reverted_cropping): 0.0\n",
      "[Done] spend 33.25 sec\n",
      "\n",
      "Predicting DeepAneurysm_00003:\n",
      "perform_everything_on_gpu: True\n",
      "configuration_manager.patch_size: [32, 64, 64]\n",
      "step_size: 0.25\n",
      "mirror_axes: None\n",
      "step_size: 0.25\n",
      "mirror_axes: None\n",
      "data pad後的大小: torch.Size([1, 175, 512, 512])\n",
      "data_vessel pad後的大小: torch.Size([1, 175, 512, 512])\n",
      "n_steps 15979, image size is torch.Size([175, 512, 512]), tile_size [32, 64, 64], tile_step_size 0.25\n",
      "steps:\n",
      "[[0, 8, 16, 24, 32, 40, 48, 56, 64, 72, 79, 87, 95, 103, 111, 119, 127, 135, 143], [0, 16, 32, 48, 64, 80, 96, 112, 128, 144, 160, 176, 192, 208, 224, 240, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448], [0, 16, 32, 48, 64, 80, 96, 112, 128, 144, 160, 176, 192, 208, 224, 240, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448]]\n",
      "[Gaussian模式] 處理 3916 個有血管的 patches，使用 batch_size=112\n",
      "Prediction done, transferring to CPU if needed\n",
      "[Done] spend 17.90 sec\n",
      "old shape: (140, 352, 352), new_shape: [163 461 461], old_spacing: [0.699999988079071, 0.5113636255264282, 0.5113636255264282], new_spacing: [0.5999996066093445, 0.3905999958515167, 0.3905999958515167], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7f48ae74d430>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "before\n",
      "predicted_array_or_file.shape: (2, 175, 512, 512)\n",
      "np.max(predicted_array_or_file): 1.0\n",
      "np.median(predicted_array_or_file): 0.0\n",
      "properties_dict[shape_after_cropping_and_before_resampling]: (150, 512, 512)\n",
      "current_spacing: [0.5999996066093445, 0.3905999958515167, 0.3905999958515167]\n",
      "properties_dict[spacing]: [0.699999988079071, 0.390625, 0.390625]\n",
      "old shape: (120, 512, 512), new_shape: [160 563 563], old_spacing: [0.7999989986419678, 0.42969998717308044, 0.42969998717308044], new_spacing: [0.5999996066093445, 0.3905999958515167, 0.3905999958515167], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7f48ae74d430>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "after\n",
      "predicted_array_or_file.shape: (2, 150, 512, 512)\n",
      "np.max(predicted_array_or_file): 1.0\n",
      "np.median(predicted_array_or_file): 0.0\n",
      "revert cropping\n",
      "probs_reverted_cropping.shape: (2, 150, 512, 512)\n",
      "np.max(probs_reverted_cropping): 1.0\n",
      "np.median(probs_reverted_cropping): 0.0\n",
      "[Done] spend 23.91 sec\n",
      "\n",
      "Predicting DeepAneurysm_00004:\n",
      "perform_everything_on_gpu: True\n",
      "configuration_manager.patch_size: [32, 64, 64]\n",
      "step_size: 0.25\n",
      "mirror_axes: None\n",
      "step_size: 0.25\n",
      "mirror_axes: None\n",
      "data pad後的大小: torch.Size([1, 162, 461, 461])\n",
      "data_vessel pad後的大小: torch.Size([1, 162, 461, 461])\n",
      "n_steps 12168, image size is torch.Size([162, 461, 461]), tile_size [32, 64, 64], tile_step_size 0.25\n",
      "steps:\n",
      "[[0, 8, 15, 23, 31, 38, 46, 54, 61, 69, 76, 84, 92, 99, 107, 115, 122, 130], [0, 16, 32, 48, 64, 79, 95, 111, 127, 143, 159, 175, 191, 206, 222, 238, 254, 270, 286, 302, 318, 333, 349, 365, 381, 397], [0, 16, 32, 48, 64, 79, 95, 111, 127, 143, 159, 175, 191, 206, 222, 238, 254, 270, 286, 302, 318, 333, 349, 365, 381, 397]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Gaussian模式] 處理 3602 個有血管的 patches，使用 batch_size=112\n",
      "Prediction done, transferring to CPU if needed\n",
      "[Done] spend 15.31 sec\n",
      "before\n",
      "predicted_array_or_file.shape: (2, 162, 461, 461)\n",
      "np.max(predicted_array_or_file): 1.0\n",
      "np.median(predicted_array_or_file): 0.0\n",
      "properties_dict[shape_after_cropping_and_before_resampling]: (194, 512, 512)\n",
      "current_spacing: [0.5999996066093445, 0.3905999958515167, 0.3905999958515167]\n",
      "properties_dict[spacing]: [0.5, 0.3515625, 0.3515625]\n",
      "after\n",
      "predicted_array_or_file.shape: (2, 194, 512, 512)\n",
      "np.max(predicted_array_or_file): 0.99995357\n",
      "np.median(predicted_array_or_file): 0.0\n",
      "revert cropping\n",
      "probs_reverted_cropping.shape: (2, 194, 512, 512)\n",
      "np.max(probs_reverted_cropping): 0.99995357\n",
      "np.median(probs_reverted_cropping): 0.0\n",
      "[Done] spend 22.55 sec\n",
      "\n",
      "Predicting DeepAneurysm_00005:\n",
      "perform_everything_on_gpu: True\n",
      "configuration_manager.patch_size: [32, 64, 64]\n",
      "step_size: 0.25\n",
      "mirror_axes: None\n",
      "step_size: 0.25\n",
      "mirror_axes: None\n",
      "data pad後的大小: torch.Size([1, 160, 563, 563])\n",
      "data_vessel pad後的大小: torch.Size([1, 160, 563, 563])\n",
      "n_steps 18513, image size is torch.Size([160, 563, 563]), tile_size [32, 64, 64], tile_step_size 0.25\n",
      "steps:\n",
      "[[0, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128], [0, 16, 31, 47, 62, 78, 94, 109, 125, 140, 156, 172, 187, 203, 218, 234, 250, 265, 281, 296, 312, 327, 343, 359, 374, 390, 405, 421, 437, 452, 468, 483, 499], [0, 16, 31, 47, 62, 78, 94, 109, 125, 140, 156, 172, 187, 203, 218, 234, 250, 265, 281, 296, 312, 327, 343, 359, 374, 390, 405, 421, 437, 452, 468, 483, 499]]\n",
      "old shape: (191, 384, 348), new_shape: [165 512 464], old_spacing: [0.5198835730552673, 0.5208330154418945, 0.5208330154418945], new_spacing: [0.5999996066093445, 0.3905999958515167, 0.3905999958515167], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7f48ae74d430>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "old shape: (188, 512, 512), new_shape: [157 461 461], old_spacing: [0.4999994933605194, 0.3515625, 0.3515625], new_spacing: [0.5999996066093445, 0.3905999958515167, 0.3905999958515167], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7f48ae74d430>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "[Gaussian模式] 處理 3577 個有血管的 patches，使用 batch_size=112\n",
      "Prediction done, transferring to CPU if needed\n",
      "[Done] spend 18.06 sec\n",
      "before\n",
      "predicted_array_or_file.shape: (2, 160, 563, 563)\n",
      "np.max(predicted_array_or_file): 1.0\n",
      "np.median(predicted_array_or_file): 0.0\n",
      "properties_dict[shape_after_cropping_and_before_resampling]: (120, 512, 512)\n",
      "current_spacing: [0.5999996066093445, 0.3905999958515167, 0.3905999958515167]\n",
      "properties_dict[spacing]: [0.7999989986419678, 0.42969998717308044, 0.42969998717308044]\n",
      "after\n",
      "predicted_array_or_file.shape: (2, 120, 512, 512)\n",
      "np.max(predicted_array_or_file): 0.9996286\n",
      "np.median(predicted_array_or_file): 0.0\n",
      "revert cropping\n",
      "probs_reverted_cropping.shape: (2, 120, 512, 512)\n",
      "np.max(probs_reverted_cropping): 0.9996286\n",
      "np.median(probs_reverted_cropping): 0.0\n",
      "[Done] spend 23.02 sec\n",
      "\n",
      "Predicting DeepAneurysm_00006:\n",
      "perform_everything_on_gpu: True\n",
      "configuration_manager.patch_size: [32, 64, 64]\n",
      "step_size: 0.25\n",
      "mirror_axes: None\n",
      "step_size: 0.25\n",
      "mirror_axes: None\n",
      "data pad後的大小: torch.Size([1, 163, 461, 461])\n",
      "data_vessel pad後的大小: torch.Size([1, 163, 461, 461])\n",
      "n_steps 12168, image size is torch.Size([163, 461, 461]), tile_size [32, 64, 64], tile_step_size 0.25\n",
      "steps:\n",
      "[[0, 8, 15, 23, 31, 39, 46, 54, 62, 69, 77, 85, 92, 100, 108, 116, 123, 131], [0, 16, 32, 48, 64, 79, 95, 111, 127, 143, 159, 175, 191, 206, 222, 238, 254, 270, 286, 302, 318, 333, 349, 365, 381, 397], [0, 16, 32, 48, 64, 79, 95, 111, 127, 143, 159, 175, 191, 206, 222, 238, 254, 270, 286, 302, 318, 333, 349, 365, 381, 397]]\n",
      "[Gaussian模式] 處理 3621 個有血管的 patches，使用 batch_size=112\n",
      "old shape: (160, 512, 512), new_shape: [173 461 461], old_spacing: [0.6500011086463928, 0.3515625, 0.3515625], new_spacing: [0.5999996066093445, 0.3905999958515167, 0.3905999958515167], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7f48ae74d430>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "Prediction done, transferring to CPU if needed\n",
      "[Done] spend 16.17 sec\n",
      "before\n",
      "predicted_array_or_file.shape: (2, 163, 461, 461)\n",
      "np.max(predicted_array_or_file): 1.0\n",
      "np.median(predicted_array_or_file): 0.0\n",
      "properties_dict[shape_after_cropping_and_before_resampling]: (140, 352, 352)\n",
      "current_spacing: [0.5999996066093445, 0.3905999958515167, 0.3905999958515167]\n",
      "properties_dict[spacing]: [0.699999988079071, 0.5113636255264282, 0.5113636255264282]\n",
      "after\n",
      "predicted_array_or_file.shape: (2, 140, 352, 352)\n",
      "np.max(predicted_array_or_file): 0.9997228\n",
      "np.median(predicted_array_or_file): 0.0\n",
      "revert cropping\n",
      "probs_reverted_cropping.shape: (2, 140, 352, 352)\n",
      "np.max(probs_reverted_cropping): 0.9997228\n",
      "np.median(probs_reverted_cropping): 0.0\n",
      "[Done] spend 19.00 sec\n",
      "\n",
      "Predicting DeepAneurysm_00007:\n",
      "perform_everything_on_gpu: True\n",
      "configuration_manager.patch_size: [32, 64, 64]\n",
      "step_size: 0.25\n",
      "mirror_axes: None\n",
      "step_size: 0.25\n",
      "mirror_axes: None\n",
      "data pad後的大小: torch.Size([1, 165, 512, 464])\n",
      "data_vessel pad後的大小: torch.Size([1, 165, 512, 464])\n",
      "n_steps 13572, image size is torch.Size([165, 512, 464]), tile_size [32, 64, 64], tile_step_size 0.25\n",
      "steps:\n",
      "[[0, 8, 16, 23, 31, 39, 47, 55, 63, 70, 78, 86, 94, 102, 110, 117, 125, 133], [0, 16, 32, 48, 64, 80, 96, 112, 128, 144, 160, 176, 192, 208, 224, 240, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448], [0, 16, 32, 48, 64, 80, 96, 112, 128, 144, 160, 176, 192, 208, 224, 240, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400]]\n",
      "[Gaussian模式] 處理 3698 個有血管的 patches，使用 batch_size=112\n",
      "old shape: (242, 640, 580), new_shape: [202 486 441], old_spacing: [0.5, 0.296875, 0.296875], new_spacing: [0.5999996066093445, 0.3905999958515167, 0.3905999958515167], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7f48ae74d430>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "Prediction done, transferring to CPU if needed\n",
      "[Done] spend 16.44 sec\n",
      "before\n",
      "predicted_array_or_file.shape: (2, 165, 512, 464)\n",
      "np.max(predicted_array_or_file): 1.0\n",
      "np.median(predicted_array_or_file): 0.0\n",
      "properties_dict[shape_after_cropping_and_before_resampling]: (191, 384, 348)\n",
      "current_spacing: [0.5999996066093445, 0.3905999958515167, 0.3905999958515167]\n",
      "properties_dict[spacing]: [0.5198835730552673, 0.5208330154418945, 0.5208330154418945]\n",
      "after\n",
      "predicted_array_or_file.shape: (2, 191, 384, 348)\n",
      "np.max(predicted_array_or_file): 0.9998294\n",
      "np.median(predicted_array_or_file): 0.0\n",
      "revert cropping\n",
      "probs_reverted_cropping.shape: (2, 191, 384, 348)\n",
      "np.max(probs_reverted_cropping): 0.9998294\n",
      "np.median(probs_reverted_cropping): 0.0\n",
      "[Done] spend 20.39 sec\n",
      "\n",
      "Predicting DeepAneurysm_00008:\n",
      "perform_everything_on_gpu: True\n",
      "configuration_manager.patch_size: [32, 64, 64]\n",
      "step_size: 0.25\n",
      "mirror_axes: None\n",
      "step_size: 0.25\n",
      "mirror_axes: None\n",
      "data pad後的大小: torch.Size([1, 157, 461, 461])\n",
      "data_vessel pad後的大小: torch.Size([1, 157, 461, 461])\n",
      "n_steps 11492, image size is torch.Size([157, 461, 461]), tile_size [32, 64, 64], tile_step_size 0.25\n",
      "steps:\n",
      "[[0, 8, 16, 23, 31, 39, 47, 55, 62, 70, 78, 86, 94, 102, 109, 117, 125], [0, 16, 32, 48, 64, 79, 95, 111, 127, 143, 159, 175, 191, 206, 222, 238, 254, 270, 286, 302, 318, 333, 349, 365, 381, 397], [0, 16, 32, 48, 64, 79, 95, 111, 127, 143, 159, 175, 191, 206, 222, 238, 254, 270, 286, 302, 318, 333, 349, 365, 381, 397]]\n",
      "[Gaussian模式] 處理 4277 個有血管的 patches，使用 batch_size=112\n",
      "old shape: (132, 384, 318), new_shape: [154 614 509], old_spacing: [0.6999969482421875, 0.625, 0.625], new_spacing: [0.5999996066093445, 0.3905999958515167, 0.3905999958515167], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7f48ae74d430>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "Prediction done, transferring to CPU if needed\n",
      "[Done] spend 16.90 sec\n",
      "before\n",
      "predicted_array_or_file.shape: (2, 157, 461, 461)\n",
      "np.max(predicted_array_or_file): 1.0\n",
      "np.median(predicted_array_or_file): 0.0\n",
      "properties_dict[shape_after_cropping_and_before_resampling]: (188, 512, 512)\n",
      "current_spacing: [0.5999996066093445, 0.3905999958515167, 0.3905999958515167]\n",
      "properties_dict[spacing]: [0.4999994933605194, 0.3515625, 0.3515625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old shape: (186, 512, 464), new_shape: [155 461 418], old_spacing: [0.5, 0.3515619933605194, 0.3515619933605194], new_spacing: [0.5999996066093445, 0.3905999958515167, 0.3905999958515167], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7f48ae74d430>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "after\n",
      "predicted_array_or_file.shape: (2, 188, 512, 512)\n",
      "np.max(predicted_array_or_file): 0.9997701\n",
      "np.median(predicted_array_or_file): 0.0\n",
      "revert cropping\n",
      "probs_reverted_cropping.shape: (2, 188, 512, 512)\n",
      "np.max(probs_reverted_cropping): 0.9997701\n",
      "np.median(probs_reverted_cropping): 0.0\n",
      "[Done] spend 23.78 sec\n",
      "\n",
      "Predicting DeepAneurysm_00009:\n",
      "perform_everything_on_gpu: True\n",
      "configuration_manager.patch_size: [32, 64, 64]\n",
      "step_size: 0.25\n",
      "mirror_axes: None\n",
      "step_size: 0.25\n",
      "mirror_axes: None\n",
      "data pad後的大小: torch.Size([1, 173, 461, 461])\n",
      "data_vessel pad後的大小: torch.Size([1, 173, 461, 461])\n",
      "n_steps 12844, image size is torch.Size([173, 461, 461]), tile_size [32, 64, 64], tile_step_size 0.25\n",
      "steps:\n",
      "[[0, 8, 16, 24, 31, 39, 47, 55, 63, 70, 78, 86, 94, 102, 110, 118, 125, 133, 141], [0, 16, 32, 48, 64, 79, 95, 111, 127, 143, 159, 175, 191, 206, 222, 238, 254, 270, 286, 302, 318, 333, 349, 365, 381, 397], [0, 16, 32, 48, 64, 79, 95, 111, 127, 143, 159, 175, 191, 206, 222, 238, 254, 270, 286, 302, 318, 333, 349, 365, 381, 397]]\n",
      "[Gaussian模式] 處理 2097 個有血管的 patches，使用 batch_size=112\n",
      "Prediction done, transferring to CPU if needed\n",
      "[Done] spend 11.27 sec\n",
      "before\n",
      "predicted_array_or_file.shape: (2, 173, 461, 461)\n",
      "np.max(predicted_array_or_file): 1.0\n",
      "np.median(predicted_array_or_file): 0.0\n",
      "properties_dict[shape_after_cropping_and_before_resampling]: (160, 512, 512)\n",
      "current_spacing: [0.5999996066093445, 0.3905999958515167, 0.3905999958515167]\n",
      "properties_dict[spacing]: [0.6500011086463928, 0.3515625, 0.3515625]\n",
      "after\n",
      "predicted_array_or_file.shape: (2, 160, 512, 512)\n",
      "np.max(predicted_array_or_file): 0.99984103\n",
      "np.median(predicted_array_or_file): 0.0\n",
      "revert cropping\n",
      "probs_reverted_cropping.shape: (2, 160, 512, 512)\n",
      "np.max(probs_reverted_cropping): 0.99984103\n",
      "np.median(probs_reverted_cropping): 0.0\n",
      "[Done] spend 17.37 sec\n",
      "\n",
      "Predicting DeepAneurysm_00010:\n",
      "perform_everything_on_gpu: True\n",
      "configuration_manager.patch_size: [32, 64, 64]\n",
      "step_size: 0.25\n",
      "mirror_axes: None\n",
      "step_size: 0.25\n",
      "mirror_axes: None\n",
      "data pad後的大小: torch.Size([1, 202, 486, 441])\n",
      "data_vessel pad後的大小: torch.Size([1, 202, 486, 441])\n",
      "n_steps 16100, image size is torch.Size([202, 486, 441]), tile_size [32, 64, 64], tile_step_size 0.25\n",
      "steps:\n",
      "[[0, 8, 15, 23, 31, 39, 46, 54, 62, 70, 77, 85, 93, 100, 108, 116, 124, 131, 139, 147, 155, 162, 170], [0, 16, 31, 47, 63, 78, 94, 109, 125, 141, 156, 172, 188, 203, 219, 234, 250, 266, 281, 297, 313, 328, 344, 359, 375, 391, 406, 422], [0, 16, 31, 47, 63, 79, 94, 110, 126, 141, 157, 173, 188, 204, 220, 236, 251, 267, 283, 298, 314, 330, 346, 361, 377]]\n",
      "[Gaussian模式] 處理 4926 個有血管的 patches，使用 batch_size=112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process SpawnPoolWorker-2:\n",
      "Process SpawnPoolWorker-3:\n",
      "Process SpawnPoolWorker-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chuan/anaconda3/envs/nnResUNet-long-BigBatch-cosine-Ane-AdamW-1to1/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/chuan/anaconda3/envs/nnResUNet-long-BigBatch-cosine-Ane-AdamW-1to1/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/chuan/anaconda3/envs/nnResUNet-long-BigBatch-cosine-Ane-AdamW-1to1/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/chuan/anaconda3/envs/nnResUNet-long-BigBatch-cosine-Ane-AdamW-1to1/lib/python3.9/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/chuan/anaconda3/envs/nnResUNet-long-BigBatch-cosine-Ane-AdamW-1to1/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "Traceback (most recent call last):\n",
      "KeyboardInterrupt\n",
      "  File \"/home/chuan/anaconda3/envs/nnResUNet-long-BigBatch-cosine-Ane-AdamW-1to1/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/chuan/anaconda3/envs/nnResUNet-long-BigBatch-cosine-Ane-AdamW-1to1/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/chuan/anaconda3/envs/nnResUNet-long-BigBatch-cosine-Ane-AdamW-1to1/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/chuan/anaconda3/envs/nnResUNet-long-BigBatch-cosine-Ane-AdamW-1to1/lib/python3.9/multiprocessing/queues.py\", line 365, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/chuan/anaconda3/envs/nnResUNet-long-BigBatch-cosine-Ane-AdamW-1to1/lib/python3.9/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/chuan/anaconda3/envs/nnResUNet-long-BigBatch-cosine-Ane-AdamW-1to1/lib/python3.9/multiprocessing/connection.py\", line 414, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/chuan/anaconda3/envs/nnResUNet-long-BigBatch-cosine-Ane-AdamW-1to1/lib/python3.9/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chuan/anaconda3/envs/nnResUNet-long-BigBatch-cosine-Ane-AdamW-1to1/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/chuan/anaconda3/envs/nnResUNet-long-BigBatch-cosine-Ane-AdamW-1to1/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/chuan/anaconda3/envs/nnResUNet-long-BigBatch-cosine-Ane-AdamW-1to1/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/chuan/anaconda3/envs/nnResUNet-long-BigBatch-cosine-Ane-AdamW-1to1/lib/python3.9/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/chuan/anaconda3/envs/nnResUNet-long-BigBatch-cosine-Ane-AdamW-1to1/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmultiprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pool\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# 最快速度模式：關閉 gaussian + 大 batch_size\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mpredict_from_raw_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/data/chuan/nnUNet/nnUNet_raw/Dataset121_DeepAneurysm/RSNA_Normalized_Image_Val_0_9925/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/data/chuan/nnUNet/nnUNet_raw/Dataset121_DeepAneurysm/RSNA_Vessel_Val_0_9925_ov0/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/data/chuan/nnUNet/nnUNet_inference/Dataset127_DeepAneurysm/3d_fullres/nnResUNet-long-BigBatch-64x-5L-1to4-ft/MRA0_0_9925_Val_ov025_TestCode\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/data/chuan/nnUNet/nnUNet_results/Dataset127_DeepAneurysm/nnUNetTrainer__nnUNetPlans__3d_fullres\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                      \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;241;43m0.25\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                      \u001b[49m\u001b[43muse_gaussian\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 關閉 gaussian 以獲得最大速度\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m                      \u001b[49m\u001b[43muse_mirroring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mperform_everything_on_gpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                      \u001b[49m\u001b[43msave_probabilities\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                      \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mcheckpoint_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcheckpoint_best.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mnum_processes_preprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mnum_processes_segmentation_export\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mdesired_gpu_index\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m112\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 可以使用更大的 batch_size，因為跳過了很多空白區域\u001b[39;49;00m\n\u001b[1;32m     21\u001b[0m \u001b[43m                      \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 185\u001b[0m, in \u001b[0;36mpredict_from_raw_data\u001b[0;34m(list_of_lists_or_source_folder, Mask_list_of_lists_or_Mask_folder, output_folder, model_training_output_dir, use_folds, tile_step_size, use_gaussian, use_mirroring, perform_everything_on_gpu, verbose, save_probabilities, overwrite, checkpoint_name, num_processes_preprocessing, num_processes_segmentation_export, folder_with_segs_from_prev_stage, num_parts, part_id, desired_gpu_index, device, batch_size)\u001b[0m\n\u001b[1;32m    183\u001b[0m network\u001b[38;5;241m.\u001b[39mload_state_dict(params)\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prediction \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 185\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_sliding_window_return_logits\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m\u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_vessel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_seg_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m\u001b[49m\u001b[43mconfiguration_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m\u001b[49m\u001b[43mmirror_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minference_allowed_mirroring_axes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43muse_mirroring\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m\u001b[49m\u001b[43mtile_step_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtile_step_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m\u001b[49m\u001b[43muse_gaussian\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_gaussian\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m\u001b[49m\u001b[43mprecomputed_gaussian\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minference_gaussian\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m\u001b[49m\u001b[43mperform_everything_on_gpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mperform_everything_on_gpu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    197\u001b[0m     prediction \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m predict_sliding_window_return_logits(\n\u001b[1;32m    198\u001b[0m         network, data, data_vessel, num_seg_heads,\n\u001b[1;32m    199\u001b[0m         configuration_manager\u001b[38;5;241m.\u001b[39mpatch_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    206\u001b[0m         device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[1;32m    207\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n",
      "Cell \u001b[0;32mIn[10], line 135\u001b[0m, in \u001b[0;36mpredict_sliding_window_return_logits\u001b[0;34m(network, input_image, vessel_image, num_segmentation_heads, tile_size, mirror_axes, tile_step_size, use_gaussian, precomputed_gaussian, perform_everything_on_gpu, verbose, device, batch_size)\u001b[0m\n\u001b[1;32m    132\u001b[0m batch_slicers \u001b[38;5;241m=\u001b[39m slicers_to_process[i:batch_end]\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m# 將 batch 中的 patches 組合成一個 tensor\u001b[39;00m\n\u001b[0;32m--> 135\u001b[0m batch_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_patches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;66;03m# 批次預測\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m#start_time_batch = time.time()\u001b[39;00m\n\u001b[1;32m    139\u001b[0m batch_predictions \u001b[38;5;241m=\u001b[39m maybe_mirror_and_predict(network, batch_tensor, mirror_axes)\u001b[38;5;241m.\u001b[39mto(results_device)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    from multiprocessing import Pool\n",
    "    # 最快速度模式：關閉 gaussian + 大 batch_size\n",
    "    predict_from_raw_data('/data/chuan/nnUNet/nnUNet_raw/Dataset121_DeepAneurysm/RSNA_Normalized_Image_Val_0_9925/',\n",
    "                          '/data/chuan/nnUNet/nnUNet_raw/Dataset121_DeepAneurysm/RSNA_Vessel_Val_0_9925_ov0/',\n",
    "                          '/data/chuan/nnUNet/nnUNet_inference/Dataset127_DeepAneurysm/3d_fullres/nnResUNet-long-BigBatch-64x-5L-1to4-ft/MRA0_0_9925_Val_ov025_TestCode',\n",
    "                          '/data/chuan/nnUNet/nnUNet_results/Dataset127_DeepAneurysm/nnUNetTrainer__nnUNetPlans__3d_fullres',\n",
    "                          (0,),\n",
    "                          0.25,\n",
    "                          use_gaussian=True,  # 關閉 gaussian 以獲得最大速度\n",
    "                          use_mirroring=False,\n",
    "                          perform_everything_on_gpu=True,\n",
    "                          verbose=True,\n",
    "                          save_probabilities=False,\n",
    "                          overwrite=False,\n",
    "                          checkpoint_name='checkpoint_best.pth',\n",
    "                          num_processes_preprocessing=2,\n",
    "                          num_processes_segmentation_export=3,\n",
    "                          desired_gpu_index = 0,\n",
    "                          batch_size=112  # 可以使用更大的 batch_size，因為跳過了很多空白區域\n",
    "                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6189eb",
   "metadata": {},
   "source": [
    "## 如何使用優化後的 batch 功能（已修正 NaN 問題）\n",
    "\n",
    "# 現在您可以設定 batch_size 和 gaussian 開關來加速推論：\n",
    "\n",
    "### Batch Size 設定：\n",
    "# - batch_size=1: 原始的逐個處理方式（預設值）\n",
    "# - batch_size=4: 一次處理 4 個 patches（建議值，適合大多數 GPU）\n",
    "# - batch_size=8: 一次處理 8 個 patches（需要更多 GPU 記憶體）\n",
    "# - batch_size=16: 一次處理 16 個 patches（需要大量 GPU 記憶體）\n",
    "\n",
    "### Gaussian 開關優化：\n",
    "# - use_gaussian=True: 使用高斯權重，品質較好但速度較慢\n",
    "# - use_gaussian=False: 不使用高斯權重，速度最快（推薦用於快速推論）\n",
    "\n",
    "### 速度優化組合建議：\n",
    "# 1. 最高品質模式：use_gaussian=True, batch_size=4\n",
    "# 2. 平衡模式：use_gaussian=True, batch_size=8\n",
    "# 3. 最快速度模式：use_gaussian=False, batch_size=8-16\n",
    "\n",
    "# 使用範例：\n",
    "# predict_from_raw_data(..., use_gaussian=False, batch_size=8)  # 最快速度\n",
    "\n",
    "### 優化效果：\n",
    "# 1. 關閉 gaussian 後，完全跳過沒有血管的空白區域，大幅減少計算量\n",
    "# 2. 批次處理減少 GPU 調用次數，提高效率\n",
    "# 3. 記憶體使用更優化，可以使用更大的 batch_size\n",
    "# 4. 修正了 NaN 問題：安全除法避免除以零，沒有血管的區域自動設為背景類別\n",
    "\n",
    "### 修正的問題：\n",
    "# 1. **NaN 問題修正**：當不使用 gaussian 且某些區域沒有血管時，避免除以零產生 NaN\n",
    "# 2. **背景預測**：沒有血管的區域自動設置為背景類別（機率 [1.0, 0.0]）\n",
    "# 3. **安全除法**：使用 torch.where 進行條件除法，確保數值穩定性\n",
    "\n",
    "# 注意事項：\n",
    "# 1. 較大的 batch_size 可以加速推論，但需要更多 GPU 記憶體\n",
    "# 2. 如果出現 GPU 記憶體不足錯誤，請降低 batch_size\n",
    "# 3. 關閉 gaussian 後可以使用更大的 batch_size，因為跳過了很多空白區域\n",
    "# 4. 對於大部分應用，關閉 gaussian 的品質損失很小，但速度提升顯著\n",
    "# 5. 現在不會再出現 NaN 值，所有區域都會有合理的預測結果\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
