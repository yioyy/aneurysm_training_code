{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1f1020e",
   "metadata": {},
   "source": [
    "## 測試nnUNet training code \n",
    "想要看出經過augmentation後，train的input長什麼樣子，總共放5張圖: \n",
    "1. 原圖 \n",
    "2. Resample \n",
    "3. Resample + augmentation \n",
    "4. Resample + SimulateLowResolutionTransform \n",
    "5. Resample + augmentation + SimulateLowResolutionTransform "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b30b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import socket\n",
    "from typing import Union, Optional\n",
    "\n",
    "import nnunetv2\n",
    "import torch.cuda\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from batchgenerators.utilities.file_and_folder_operations import join, isfile, load_json\n",
    "from nnunetv2.paths import nnUNet_preprocessed\n",
    "from nnunetv2.run.load_pretrained_weights import load_pretrained_weights\n",
    "from nnunetv2.training.nnUNetTrainer.nnUNetTrainer import nnUNetTrainer\n",
    "from nnunetv2.utilities.dataset_name_id_conversion import maybe_convert_to_dataset_name\n",
    "from nnunetv2.utilities.find_class_by_name import recursive_find_python_class\n",
    "from torch.backends import cudnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6751de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import multiprocessing\n",
    "import os\n",
    "import shutil\n",
    "import traceback\n",
    "from asyncio import sleep\n",
    "from copy import deepcopy\n",
    "from typing import Tuple, Union, List\n",
    "\n",
    "import nnunetv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from batchgenerators.dataloading.data_loader import DataLoader\n",
    "from batchgenerators.dataloading.single_threaded_augmenter import SingleThreadedAugmenter\n",
    "from batchgenerators.dataloading.multi_threaded_augmenter import MultiThreadedAugmenter\n",
    "from batchgenerators.transforms.utility_transforms import NumpyToTensor\n",
    "from batchgenerators.utilities.file_and_folder_operations import load_json, join, isfile, maybe_mkdir_p, isdir, subdirs, \\\n",
    "    save_json\n",
    "from nnunetv2.configuration import default_num_processes\n",
    "from nnunetv2.inference.export_prediction import export_prediction_from_softmax\n",
    "#from nnunetv2.inference.sliding_window_prediction import predict_sliding_window_return_logits, compute_gaussian\n",
    "from nnunetv2.preprocessing.preprocessors.default_preprocessor import DefaultPreprocessor\n",
    "from nnunetv2.utilities.file_path_utilities import get_output_folder, should_i_save_to_file, check_workers_busy\n",
    "from nnunetv2.utilities.find_class_by_name import recursive_find_python_class\n",
    "from nnunetv2.utilities.json_export import recursive_fix_for_json_export\n",
    "from nnunetv2.utilities.label_handling.label_handling import determine_num_input_channels, convert_labelmap_to_one_hot\n",
    "from nnunetv2.utilities.plans_handling.plans_handler import PlansManager, ConfigurationManager\n",
    "from nnunetv2.utilities.utils import create_lists_from_splitted_dataset_folder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.filters import threshold_multiotsu, gaussian, threshold_otsu, frangi\n",
    "from skimage.measure import label, regionprops, regionprops_table\n",
    "import time\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "from scipy.ndimage import binary_dilation\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage  # pip install scipy\n",
    "import scipy.stats\n",
    "from skimage.morphology import skeletonize\n",
    "from sklearn.model_selection import train_test_split  # pip install scikit-learn\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report, f1_score, cohen_kappa_score, matthews_corrcoef\n",
    "from itertools import cycle, product\n",
    "import random\n",
    "import cv2\n",
    "import matplotlib\n",
    "#%matplotlib notebook\n",
    "%matplotlib inline\n",
    "#matplotlib.use('Agg') \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2444061",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessAdapter(DataLoader):\n",
    "    def __init__(self, list_of_lists: List[List[str]], list_of_segs_from_prev_stage_files: Union[List[None], List[str]],\n",
    "                 preprocessor: DefaultPreprocessor, output_filenames_truncated: List[str],\n",
    "                 plans_manager: PlansManager, dataset_json: dict, configuration_manager: ConfigurationManager,\n",
    "                 num_threads_in_multithreaded: int = 1):\n",
    "        self.preprocessor, self.plans_manager, self.configuration_manager, self.dataset_json = \\\n",
    "            preprocessor, plans_manager, configuration_manager, dataset_json\n",
    "\n",
    "        self.label_manager = plans_manager.get_label_manager(dataset_json)\n",
    "\n",
    "        super().__init__(list(zip(list_of_lists, list_of_segs_from_prev_stage_files, output_filenames_truncated)),\n",
    "                         1, num_threads_in_multithreaded,\n",
    "                         seed_for_shuffle=1, return_incomplete=True,\n",
    "                         shuffle=False, infinite=False, sampling_probabilities=None)\n",
    "\n",
    "        self.indices = list(range(len(list_of_lists)))\n",
    "\n",
    "    def generate_train_batch(self):\n",
    "        idx = self.get_indices()[0]\n",
    "        files = self._data[idx][0]\n",
    "        seg_prev_stage = self._data[idx][1]\n",
    "        ofile = self._data[idx][2]\n",
    "        # if we have a segmentation from the previous stage we have to process it together with the images so that we\n",
    "        # can crop it appropriately (if needed). Otherwise it would just be resized to the shape of the data after\n",
    "        # preprocessing and then there might be misalignments\n",
    "        data, seg, data_properites = self.preprocessor.run_case(files, seg_prev_stage, self.plans_manager,\n",
    "                                                                self.configuration_manager,\n",
    "                                                                self.dataset_json)\n",
    "        if seg_prev_stage is not None:\n",
    "            seg_onehot = convert_labelmap_to_one_hot(seg[0], self.label_manager.foreground_labels, data.dtype)\n",
    "            data = np.vstack((data, seg_onehot))\n",
    "\n",
    "        if np.prod(data.shape) > (2e9 / 4 * 0.85):\n",
    "            # we need to temporarily save the preprocessed image due to process-process communication restrictions\n",
    "            np.save(ofile + '.npy', data)\n",
    "            data = ofile + '.npy'\n",
    "\n",
    "        return {'data': data, 'data_properites': data_properites, 'ofile': ofile}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c6b3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_what_we_need(model_training_output_dir, use_folds, checkpoint_name):\n",
    "    # we could also load plans and dataset_json from the init arguments in the checkpoint. Not quite sure what is the\n",
    "    # best method so we leave things as they are for the moment.\n",
    "    dataset_json = load_json(join(model_training_output_dir, 'dataset.json'))\n",
    "    plans = load_json(join(model_training_output_dir, 'plans.json'))\n",
    "    plans_manager = PlansManager(plans)\n",
    "\n",
    "    if isinstance(use_folds, str):\n",
    "        use_folds = [use_folds]\n",
    "\n",
    "    parameters = []\n",
    "    for i, f in enumerate(use_folds):\n",
    "        f = int(f) if f != 'all' else f\n",
    "        checkpoint = torch.load(join(model_training_output_dir, f'fold_{f}', checkpoint_name),\n",
    "                                map_location=torch.device('cpu'))\n",
    "        if i == 0:\n",
    "            trainer_name = checkpoint['trainer_name']\n",
    "            configuration_name = checkpoint['init_args']['configuration']\n",
    "            inference_allowed_mirroring_axes = checkpoint['inference_allowed_mirroring_axes'] if \\\n",
    "                'inference_allowed_mirroring_axes' in checkpoint.keys() else None\n",
    "\n",
    "        parameters.append(checkpoint['network_weights'])\n",
    "\n",
    "    configuration_manager = plans_manager.get_configuration(configuration_name)\n",
    "    # restore network\n",
    "    num_input_channels = determine_num_input_channels(plans_manager, configuration_manager, dataset_json)\n",
    "    trainer_class = recursive_find_python_class(join(nnunetv2.__path__[0], \"training\", \"nnUNetTrainer\"),\n",
    "                                                trainer_name, 'nnunetv2.training.nnUNetTrainer')\n",
    "    network = trainer_class.build_network_architecture(plans_manager, dataset_json, configuration_manager,\n",
    "                                                       num_input_channels, enable_deep_supervision=False)\n",
    "    return parameters, configuration_manager, inference_allowed_mirroring_axes, plans_manager, dataset_json, network, trainer_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79186af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_detect_available_folds(model_training_output_dir, checkpoint_name):\n",
    "    print('use_folds is None, attempting to auto detect available folds')\n",
    "    fold_folders = subdirs(model_training_output_dir, prefix='fold_', join=False)\n",
    "    fold_folders = [i for i in fold_folders if i != 'fold_all']\n",
    "    fold_folders = [i for i in fold_folders if isfile(join(model_training_output_dir, i, checkpoint_name))]\n",
    "    use_folds = [int(i.split('_')[-1]) for i in fold_folders]\n",
    "    print(f'found the following folds: {use_folds}')\n",
    "    return use_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e209e36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from typing import Union, Tuple, List\n",
    "from acvl_utils.cropping_and_padding.padding import pad_nd_image\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from torch import nn\n",
    "\n",
    "from nnunetv2.utilities.helpers import empty_cache, dummy_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bc4049",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_translate(img, nii):\n",
    "    img = np.swapaxes(img,0,1)\n",
    "    img = np.flip(img,0)\n",
    "    img = np.flip(img, -1)\n",
    "    header = nii.header.copy() #抓出nii header 去算體積 \n",
    "    pixdim = header['pixdim']  #可以借此從nii的header抓出voxel size\n",
    "    if pixdim[0] > 0:\n",
    "        img = np.flip(img, 1)  \n",
    "    # img = np.expand_dims(np.expand_dims(img, axis=0), axis=4)\n",
    "    return img\n",
    "\n",
    "#會使用到的一些predict技巧\n",
    "def data_translate_back(img, nii):\n",
    "    header = nii.header.copy() #抓出nii header 去算體積 \n",
    "    pixdim = header['pixdim']  #可以借此從nii的header抓出voxel size\n",
    "    if pixdim[0] > 0:\n",
    "        img = np.flip(img, 1)  \n",
    "    img = np.flip(img, -1)\n",
    "    img = np.flip(img,0)\n",
    "    img = np.swapaxes(img,1,0)\n",
    "    # img = np.expand_dims(np.expand_dims(img, axis=0), axis=4)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1113a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling in aneurysm_labels\n",
    "# 同時5種不同成像切片\n",
    "# 因為resample可能會比較小顆，所以random label的選取使用他\n",
    "# 連brain mask 跟 augmentation 都不需要了\n",
    "def rand_crop_sampling(image_arr, label_arr, \n",
    "                       img_resample, label_resample,\n",
    "                       img_aug, label_aug,\n",
    "                       img_low, label_low,\n",
    "                       img_auglow, label_auglow,\n",
    "                       nag_sample_mask=None,\n",
    "                       size=(32,32,16), sample_num=1, pos_rate=0.2, lesion_lb=3):\n",
    "    lesion_mask = np.zeros_like(label_resample, dtype=bool)\n",
    "    \n",
    "    ## get sample centers\n",
    "    center_list = []\n",
    "    \n",
    "    # positive sampling\n",
    "    if (label_resample.max() > 0)and(label_resample.max() >= lesion_lb):  # on lesion\n",
    "        lesion_mask = label_resample==lesion_lb\n",
    "        centers = np.stack(np.where(lesion_mask), axis=1)\n",
    "        centers = [xyz for xyz in centers.tolist()]\n",
    "        random.shuffle(centers)\n",
    "        center_list.extend(centers[:int(sample_num*pos_rate)])\n",
    "        \n",
    "    # other sampling\n",
    "    if np.any(nag_sample_mask):  # on custom area\n",
    "        mask = nag_sample_mask\n",
    "    else:\n",
    "        mask = image_arr > 0\n",
    "    if np.any(lesion_mask):\n",
    "        mask = mask & (label_arr==0)\n",
    "    centers = np.stack(np.where(mask), axis=1)\n",
    "    centers = [xyz for xyz in centers.tolist()]\n",
    "    random.shuffle(centers)\n",
    "    center_list.extend(centers[:sample_num])\n",
    "    center_list = center_list[:sample_num]\n",
    "    del mask, centers\n",
    "    \n",
    "    ## pad image and label\n",
    "    bigger_size = np.ceil(np.array(size) / np.cos(45 * np.pi / 180)).astype('uint16')\n",
    "    p0, p1, p2 = np.int32(bigger_size // 2)\n",
    "    \n",
    "    #以下為了符合旋轉，先做padding的影像\n",
    "    pad_image_arr = np.pad(image_arr, ((p0,p0),(p1,p1),(p2,p2)), 'constant')\n",
    "    pad_label_arr = np.pad(np.uint8(label_arr>0), ((p0,p0),(p1,p1),(p2,p2)), 'constant')  # <-label_arr\n",
    "    \n",
    "    pad_image_resample = np.pad(img_resample, ((p0,p0),(p1,p1),(p2,p2)), 'constant')\n",
    "    pad_label_resample = np.pad(np.uint8(label_resample>0), ((p0,p0),(p1,p1),(p2,p2)), 'constant')  # <-label_arr\n",
    "    \n",
    "    pad_image_aug = np.pad(img_aug, ((p0,p0),(p1,p1),(p2,p2)), 'constant')\n",
    "    pad_label_aug = np.pad(np.uint8(label_aug>0), ((p0,p0),(p1,p1),(p2,p2)), 'constant')  # <-label_arr    \n",
    "\n",
    "    pad_image_low = np.pad(img_low, ((p0,p0),(p1,p1),(p2,p2)), 'constant')\n",
    "    pad_label_low = np.pad(np.uint8(label_low>0), ((p0,p0),(p1,p1),(p2,p2)), 'constant')  # <-label_arr   \n",
    "\n",
    "    pad_image_auglow = np.pad(img_auglow, ((p0,p0),(p1,p1),(p2,p2)), 'constant')\n",
    "    pad_label_auglow = np.pad(np.uint8(label_auglow>0), ((p0,p0),(p1,p1),(p2,p2)), 'constant')  # <-label_arr  \n",
    "    \n",
    "    ## random crop sampling\n",
    "    image_crop_stack = np.zeros((sample_num, *size), dtype=image_arr.dtype)\n",
    "    label_crop_stack = np.zeros((sample_num, *size), dtype=label_arr.dtype)\n",
    "    \n",
    "    image_crop_resample = np.zeros((sample_num, *size), dtype=image_arr.dtype)\n",
    "    label_crop_resample = np.zeros((sample_num, *size), dtype=label_arr.dtype)\n",
    "    \n",
    "    image_crop_aug = np.zeros((sample_num, *size), dtype=image_arr.dtype)\n",
    "    label_crop_aug = np.zeros((sample_num, *size), dtype=label_arr.dtype)\n",
    "    \n",
    "    image_crop_low = np.zeros((sample_num, *size), dtype=image_arr.dtype)\n",
    "    label_crop_low = np.zeros((sample_num, *size), dtype=label_arr.dtype)\n",
    "    \n",
    "    image_crop_auglow = np.zeros((sample_num, *size), dtype=image_arr.dtype)\n",
    "    label_crop_auglow = np.zeros((sample_num, *size), dtype=label_arr.dtype)\n",
    "        \n",
    "    for i, idx in enumerate(np.random.randint(0, len(center_list), sample_num)):\n",
    "        center = center_list[idx]\n",
    "        #原圖\n",
    "        bigger_image_crop = pad_image_arr[center[0]:center[0]+bigger_size[0], \n",
    "                                          center[1]:center[1]+bigger_size[1], \n",
    "                                          center[2]:center[2]+bigger_size[2]]\n",
    "        bigger_label_crop = pad_label_arr[center[0]:center[0]+bigger_size[0], \n",
    "                                          center[1]:center[1]+bigger_size[1], \n",
    "                                          center[2]:center[2]+bigger_size[2]]\n",
    "\n",
    "        # center crop to target size\n",
    "        image_crop_stack[i] = bigger_image_crop[p0-(size[0]//2) : p0-(size[0]//2)+size[0], \n",
    "                                                p1-(size[1]//2) : p1-(size[1]//2)+size[1], \n",
    "                                                p2-(size[2]//2) : p2-(size[2]//2)+size[2]]\n",
    "        label_crop_stack[i] = bigger_label_crop[p0-(size[0]//2) : p0-(size[0]//2)+size[0], \n",
    "                                                p1-(size[1]//2) : p1-(size[1]//2)+size[1], \n",
    "                                                p2-(size[2]//2) : p2-(size[2]//2)+size[2]]\n",
    "        #resample\n",
    "        bigger_image_crop = pad_image_resample[center[0]:center[0]+bigger_size[0], \n",
    "                                               center[1]:center[1]+bigger_size[1], \n",
    "                                               center[2]:center[2]+bigger_size[2]]\n",
    "        bigger_label_crop = pad_label_resample[center[0]:center[0]+bigger_size[0], \n",
    "                                               center[1]:center[1]+bigger_size[1], \n",
    "                                               center[2]:center[2]+bigger_size[2]]\n",
    "\n",
    "        image_crop_resample[i] = bigger_image_crop[p0-(size[0]//2) : p0-(size[0]//2)+size[0], \n",
    "                                                   p1-(size[1]//2) : p1-(size[1]//2)+size[1], \n",
    "                                                   p2-(size[2]//2) : p2-(size[2]//2)+size[2]]\n",
    "        label_crop_resample[i] = bigger_label_crop[p0-(size[0]//2) : p0-(size[0]//2)+size[0], \n",
    "                                                   p1-(size[1]//2) : p1-(size[1]//2)+size[1], \n",
    "                                                   p2-(size[2]//2) : p2-(size[2]//2)+size[2]]\n",
    "        #aug\n",
    "        bigger_image_crop = pad_image_aug[center[0]:center[0]+bigger_size[0], \n",
    "                                          center[1]:center[1]+bigger_size[1], \n",
    "                                          center[2]:center[2]+bigger_size[2]]\n",
    "        bigger_label_crop = pad_label_aug[center[0]:center[0]+bigger_size[0], \n",
    "                                          center[1]:center[1]+bigger_size[1], \n",
    "                                          center[2]:center[2]+bigger_size[2]]\n",
    "\n",
    "        image_crop_aug[i] = bigger_image_crop[p0-(size[0]//2) : p0-(size[0]//2)+size[0], \n",
    "                                              p1-(size[1]//2) : p1-(size[1]//2)+size[1], \n",
    "                                              p2-(size[2]//2) : p2-(size[2]//2)+size[2]]\n",
    "        label_crop_aug[i] = bigger_label_crop[p0-(size[0]//2) : p0-(size[0]//2)+size[0], \n",
    "                                              p1-(size[1]//2) : p1-(size[1]//2)+size[1], \n",
    "                                              p2-(size[2]//2) : p2-(size[2]//2)+size[2]]\n",
    "        #low\n",
    "        bigger_image_crop = pad_image_low[center[0]:center[0]+bigger_size[0], \n",
    "                                          center[1]:center[1]+bigger_size[1], \n",
    "                                          center[2]:center[2]+bigger_size[2]]\n",
    "        bigger_label_crop = pad_label_low[center[0]:center[0]+bigger_size[0], \n",
    "                                          center[1]:center[1]+bigger_size[1], \n",
    "                                          center[2]:center[2]+bigger_size[2]]\n",
    "\n",
    "        image_crop_low[i] = bigger_image_crop[p0-(size[0]//2) : p0-(size[0]//2)+size[0], \n",
    "                                              p1-(size[1]//2) : p1-(size[1]//2)+size[1], \n",
    "                                              p2-(size[2]//2) : p2-(size[2]//2)+size[2]]\n",
    "        label_crop_low[i] = bigger_label_crop[p0-(size[0]//2) : p0-(size[0]//2)+size[0], \n",
    "                                              p1-(size[1]//2) : p1-(size[1]//2)+size[1], \n",
    "                                              p2-(size[2]//2) : p2-(size[2]//2)+size[2]]        \n",
    "        \n",
    "        #auglow\n",
    "        bigger_image_crop = pad_image_auglow[center[0]:center[0]+bigger_size[0], \n",
    "                                             center[1]:center[1]+bigger_size[1], \n",
    "                                             center[2]:center[2]+bigger_size[2]]\n",
    "        bigger_label_crop = pad_label_auglow[center[0]:center[0]+bigger_size[0], \n",
    "                                             center[1]:center[1]+bigger_size[1], \n",
    "                                             center[2]:center[2]+bigger_size[2]]\n",
    "\n",
    "        image_crop_auglow[i] = bigger_image_crop[p0-(size[0]//2) : p0-(size[0]//2)+size[0], \n",
    "                                                 p1-(size[1]//2) : p1-(size[1]//2)+size[1], \n",
    "                                                 p2-(size[2]//2) : p2-(size[2]//2)+size[2]]\n",
    "        label_crop_auglow[i] = bigger_label_crop[p0-(size[0]//2) : p0-(size[0]//2)+size[0], \n",
    "                                                 p1-(size[1]//2) : p1-(size[1]//2)+size[1], \n",
    "                                                 p2-(size[2]//2) : p2-(size[2]//2)+size[2]] \n",
    "        \n",
    "    return image_crop_stack, label_crop_stack, image_crop_resample, label_crop_resample, image_crop_aug, label_crop_aug, image_crop_low, label_crop_low, image_crop_auglow, label_crop_auglow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116d4173",
   "metadata": {},
   "outputs": [],
   "source": [
    "def easy_nor(sample):\n",
    "    sample = (((sample - np.min(sample))/(np.max(sample) - np.min(sample)))*255).copy()\n",
    "    sample[sample<0] = 0\n",
    "    sample[sample>255] = 255\n",
    "    return sample\n",
    "\n",
    "def easy_show(sample, idx):\n",
    "    show = np.expand_dims(sample[:,:,idx], axis=-1).copy()\n",
    "    y_i, x_i, z_i = show.shape\n",
    "    show_one = show.copy()\n",
    "    show = np.concatenate([show, show_one],2)\n",
    "    show = np.concatenate([show, show_one],2)\n",
    "    show = show.astype('uint8')\n",
    "    return show\n",
    "\n",
    "def esay_canny(targe, idx):\n",
    "    y_nor1 = targe[:,:,idx]    \n",
    "    y_color = (y_nor1*255).astype('uint8')\n",
    "    y_th = cv2.Canny(y_color, 128, 256).copy()\n",
    "    y_th = y_th.astype('uint8')\n",
    "    return y_th\n",
    "\n",
    "def plot_multi_view(img1, label1, img2, label2, img3, label3, img4, label4, img5, label5):\n",
    "    #先決定影像是否為正規化後，是的話就不用再做正規化, 先決定影像是否為4d，畫三張，原圖,label,疊圖\n",
    "    #dim=3為標註123放在一起，dim=4為一標註一層，統一把標註轉為1層1個吧\n",
    "    # 生成 1 到 100 之間的隨機正整數（包括 1 和 100）\n",
    "    random_integer = random.randint(0, img1.shape[0]-1)\n",
    "    sample1 = img1[random_integer,:,:,:]\n",
    "    targe1 = label1[random_integer,:,:,:]\n",
    "    sample2 = img2[random_integer,:,:,:]\n",
    "    targe2 = label2[random_integer,:,:,:]\n",
    "    sample3 = img3[random_integer,:,:,:]\n",
    "    targe3 = label3[random_integer,:,:,:]\n",
    "    sample4 = img4[random_integer,:,:,:]\n",
    "    targe4 = label4[random_integer,:,:,:]\n",
    "    sample5 = img5[random_integer,:,:,:]\n",
    "    targe5 = label5[random_integer,:,:,:]\n",
    "    #為了展示正規化\n",
    "    sample1 = easy_nor(sample1)\n",
    "    sample2 = easy_nor(sample2)\n",
    "    sample3 = easy_nor(sample3)\n",
    "    sample4 = easy_nor(sample4)\n",
    "    sample5 = easy_nor(sample5)\n",
    "    \n",
    "    for idx in range(sample1.shape[-1]):\n",
    "        show1 = easy_show(sample1, idx)\n",
    "        show_IL1 = show1.copy()\n",
    "        show2 = easy_show(sample2, idx)\n",
    "        show_IL2 = show2.copy()\n",
    "        show3 = easy_show(sample3, idx)\n",
    "        show4 = easy_show(sample4, idx)\n",
    "        show5 = easy_show(sample5, idx)\n",
    "        \n",
    "        y_th1 = esay_canny(targe1, idx)\n",
    "        y_th2 = esay_canny(targe2, idx)\n",
    "        y_th3 = esay_canny(targe3, idx)\n",
    "        y_th4 = esay_canny(targe4, idx)\n",
    "        y_th5 = esay_canny(targe5, idx)\n",
    "\n",
    "        y_c, x_c = np.where(y_th1>0)\n",
    "        if len(y_c) > 0:    \n",
    "            show_IL1[y_c,x_c,0] = 255\n",
    "            show_IL1[y_c,x_c,1] = 0\n",
    "            show_IL1[y_c,x_c,2] = 0\n",
    "            \n",
    "        y_c, x_c = np.where(y_th2>0)\n",
    "        if len(y_c) > 0:    \n",
    "            show_IL2[y_c,x_c,0] = 255\n",
    "            show_IL2[y_c,x_c,1] = 0\n",
    "            show_IL2[y_c,x_c,2] = 0\n",
    "\n",
    "#         y_c, x_c = np.where(y_th3>0)\n",
    "#         if len(y_c) > 0:    \n",
    "#             show3[y_c,x_c,0] = 255\n",
    "#             show3[y_c,x_c,1] = 0\n",
    "#             show3[y_c,x_c,2] = 0\n",
    "            \n",
    "#         y_c, x_c = np.where(y_th4>0)\n",
    "#         if len(y_c) > 0:    \n",
    "#             show4[y_c,x_c,0] = 255\n",
    "#             show4[y_c,x_c,1] = 0\n",
    "#             show4[y_c,x_c,2] = 0\n",
    "            \n",
    "#         y_c, x_c = np.where(y_th5>0)\n",
    "#         if len(y_c) > 0:    \n",
    "#             show5[y_c,x_c,0] = 255\n",
    "#             show5[y_c,x_c,1] = 0\n",
    "#             show5[y_c,x_c,2] = 0\n",
    "                \n",
    "        plt.style.use('default') #使用背景色，繪圖風格\n",
    "        plt.figure(figsize=(15, 15)) #show 2view\n",
    "        plt.subplot(1,7,1)\n",
    "        plt.imshow(show1)\n",
    "        plt.title('Image', fontsize=15)\n",
    "        plt.axis('off')\n",
    "        plt.subplot(1,7,2)\n",
    "        plt.imshow(show_IL1)\n",
    "        plt.title('o_Label', fontsize=15)\n",
    "        plt.axis('off') \n",
    "        plt.subplot(1,7,3)\n",
    "        plt.imshow(show2)\n",
    "        plt.title('resample', fontsize=15)\n",
    "        plt.axis('off') \n",
    "        plt.subplot(1,7,4)\n",
    "        plt.imshow(show_IL2)\n",
    "        plt.title('resample_Label', fontsize=15)\n",
    "        plt.axis('off')\n",
    "        plt.subplot(1,7,5)\n",
    "        plt.imshow(show3)\n",
    "        plt.title('aug', fontsize=15)\n",
    "        plt.axis('off')     \n",
    "        plt.subplot(1,7,6)\n",
    "        plt.imshow(show4)\n",
    "        plt.title('low', fontsize=15)\n",
    "        plt.axis('off') \n",
    "        plt.subplot(1,7,7)\n",
    "        plt.imshow(show5)\n",
    "        plt.title('auglow', fontsize=15)\n",
    "        plt.axis('off') \n",
    "        plt.show()\n",
    "        \n",
    "def plot_multi_view2(img1, label1, img2, label2, img3, label3, img4, label4, img5, label5):\n",
    "    #先決定影像是否為正規化後，是的話就不用再做正規化, 先決定影像是否為4d，畫三張，原圖,label,疊圖\n",
    "    #dim=3為標註123放在一起，dim=4為一標註一層，統一把標註轉為1層1個吧\n",
    "    # 生成 1 到 100 之間的隨機正整數（包括 1 和 100）\n",
    "    random_integer = random.randint(0, img1.shape[0]-1)\n",
    "    sample1 = img1[random_integer,:,:,:]\n",
    "    targe1 = label1[random_integer,:,:,:]\n",
    "    sample2 = img2[random_integer,:,:,:]\n",
    "    targe2 = label2[random_integer,:,:,:]\n",
    "    sample3 = img3[random_integer,:,:,:]\n",
    "    targe3 = label3[random_integer,:,:,:]\n",
    "    sample4 = img4[random_integer,:,:,:]\n",
    "    targe4 = label4[random_integer,:,:,:]\n",
    "    sample5 = img5[random_integer,:,:,:]\n",
    "    targe5 = label5[random_integer,:,:,:]\n",
    "    #為了展示正規化\n",
    "    sample1 = easy_nor(sample1)\n",
    "    sample2 = easy_nor(sample2)\n",
    "    sample3 = easy_nor(sample3)\n",
    "    sample4 = easy_nor(sample4)\n",
    "    sample5 = easy_nor(sample5)\n",
    "    \n",
    "    for idx in range(sample1.shape[-1]):\n",
    "        show1 = easy_show(sample1, idx)\n",
    "        show_IL1 = show1.copy()\n",
    "        show2 = easy_show(sample2, idx)\n",
    "        show_IL2 = show2.copy()\n",
    "        show3 = easy_show(sample3, idx)\n",
    "        show4 = easy_show(sample4, idx)\n",
    "        show5 = easy_show(sample5, idx)\n",
    "        \n",
    "        y_th1 = esay_canny(targe1, idx)\n",
    "        y_th2 = esay_canny(targe2, idx)\n",
    "        y_th3 = esay_canny(targe3, idx)\n",
    "        y_th4 = esay_canny(targe4, idx)\n",
    "        y_th5 = esay_canny(targe5, idx)\n",
    "\n",
    "        y_c, x_c = np.where(y_th1>0)\n",
    "        if len(y_c) > 0:    \n",
    "            show_IL1[y_c,x_c,0] = 255\n",
    "            show_IL1[y_c,x_c,1] = 0\n",
    "            show_IL1[y_c,x_c,2] = 0\n",
    "            \n",
    "        y_c, x_c = np.where(y_th2>0)\n",
    "        if len(y_c) > 0:    \n",
    "            show_IL2[y_c,x_c,0] = 255\n",
    "            show_IL2[y_c,x_c,1] = 0\n",
    "            show_IL2[y_c,x_c,2] = 0\n",
    "\n",
    "#         y_c, x_c = np.where(y_th3>0)\n",
    "#         if len(y_c) > 0:    \n",
    "#             show3[y_c,x_c,0] = 255\n",
    "#             show3[y_c,x_c,1] = 0\n",
    "#             show3[y_c,x_c,2] = 0\n",
    "            \n",
    "#         y_c, x_c = np.where(y_th4>0)\n",
    "#         if len(y_c) > 0:    \n",
    "#             show4[y_c,x_c,0] = 255\n",
    "#             show4[y_c,x_c,1] = 0\n",
    "#             show4[y_c,x_c,2] = 0\n",
    "            \n",
    "#         y_c, x_c = np.where(y_th5>0)\n",
    "#         if len(y_c) > 0:    \n",
    "#             show5[y_c,x_c,0] = 255\n",
    "#             show5[y_c,x_c,1] = 0\n",
    "#             show5[y_c,x_c,2] = 0\n",
    "                \n",
    "        plt.style.use('default') #使用背景色，繪圖風格\n",
    "        plt.figure(figsize=(15, 15)) #show 2view\n",
    "        plt.subplot(1,4,1)\n",
    "        plt.imshow(show1)\n",
    "        plt.title('Image', fontsize=15)\n",
    "        plt.axis('off')\n",
    "        plt.subplot(1,4,2)\n",
    "        plt.imshow(show_IL1)\n",
    "        plt.title('o_Label', fontsize=15)\n",
    "        plt.axis('off') \n",
    "        plt.subplot(1,4,3)\n",
    "        plt.imshow(show2)\n",
    "        plt.title('resample', fontsize=15)\n",
    "        plt.axis('off') \n",
    "        plt.subplot(1,4,4)\n",
    "        plt.imshow(show_IL2)\n",
    "        plt.title('resample_Label', fontsize=15)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45ce231",
   "metadata": {},
   "outputs": [],
   "source": [
    "#透過 SingleThreadedAugmenter ，這裡融入各種augmentation\n",
    "import inspect\n",
    "import multiprocessing\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "from datetime import datetime\n",
    "from time import time, sleep\n",
    "from typing import Union, Tuple, List\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from batchgenerators.dataloading.single_threaded_augmenter import SingleThreadedAugmenter\n",
    "from batchgenerators.transforms.abstract_transforms import AbstractTransform, Compose\n",
    "from batchgenerators.transforms.color_transforms import BrightnessMultiplicativeTransform, \\\n",
    "    ContrastAugmentationTransform, GammaTransform\n",
    "from batchgenerators.transforms.noise_transforms import GaussianNoiseTransform, GaussianBlurTransform\n",
    "from batchgenerators.transforms.resample_transforms import SimulateLowResolutionTransform\n",
    "from batchgenerators.transforms.spatial_transforms import SpatialTransform, MirrorTransform\n",
    "from batchgenerators.transforms.utility_transforms import RemoveLabelTransform, RenameTransform, NumpyToTensor\n",
    "from batchgenerators.utilities.file_and_folder_operations import join, load_json, isfile, save_json, maybe_mkdir_p\n",
    "from nnunetv2.configuration import ANISO_THRESHOLD, default_num_processes\n",
    "from nnunetv2.evaluation.evaluate_predictions import compute_metrics_on_folder\n",
    "from nnunetv2.inference.export_prediction import export_prediction_from_softmax, resample_and_save\n",
    "from nnunetv2.inference.sliding_window_prediction import compute_gaussian, predict_sliding_window_return_logits\n",
    "from nnunetv2.paths import nnUNet_preprocessed, nnUNet_results\n",
    "from nnunetv2.training.data_augmentation.compute_initial_patch_size import get_patch_size\n",
    "from nnunetv2.training.data_augmentation.custom_transforms.cascade_transforms import MoveSegAsOneHotToData, \\\n",
    "    ApplyRandomBinaryOperatorTransform, RemoveRandomConnectedComponentFromOneHotEncodingTransform\n",
    "from nnunetv2.training.data_augmentation.custom_transforms.deep_supervision_donwsampling import \\\n",
    "    DownsampleSegForDSTransform2\n",
    "from nnunetv2.training.data_augmentation.custom_transforms.limited_length_multithreaded_augmenter import \\\n",
    "    LimitedLenWrapper\n",
    "from nnunetv2.training.data_augmentation.custom_transforms.masking import MaskTransform\n",
    "from nnunetv2.training.data_augmentation.custom_transforms.region_based_training import \\\n",
    "    ConvertSegmentationToRegionsTransform\n",
    "from nnunetv2.training.data_augmentation.custom_transforms.transforms_for_dummy_2d import Convert2DTo3DTransform, \\\n",
    "    Convert3DTo2DTransform\n",
    "from nnunetv2.training.dataloading.data_loader_2d import nnUNetDataLoader2D\n",
    "from nnunetv2.training.dataloading.data_loader_3d import nnUNetDataLoader3D\n",
    "from nnunetv2.training.dataloading.nnunet_dataset import nnUNetDataset\n",
    "from nnunetv2.training.dataloading.utils import get_case_identifiers, unpack_dataset\n",
    "from nnunetv2.training.logging.nnunet_logger import nnUNetLogger\n",
    "from nnunetv2.training.loss.deep_supervision import DeepSupervisionWrapper\n",
    "from nnunetv2.training.lr_scheduler.polylr import PolyLRScheduler\n",
    "from nnunetv2.utilities.collate_outputs import collate_outputs\n",
    "from nnunetv2.utilities.default_n_proc_DA import get_allowed_n_proc_DA\n",
    "from nnunetv2.utilities.file_path_utilities import should_i_save_to_file, check_workers_busy\n",
    "from nnunetv2.utilities.get_network_from_plans import get_network_from_plans\n",
    "from nnunetv2.utilities.helpers import empty_cache, dummy_context\n",
    "from nnunetv2.utilities.label_handling.label_handling import convert_labelmap_to_one_hot, determine_num_input_channels\n",
    "from nnunetv2.utilities.plans_handling.plans_handler import PlansManager, ConfigurationManager\n",
    "from sklearn.model_selection import KFold\n",
    "from torch import autocast, nn\n",
    "from torch import distributed as dist\n",
    "from torch.cuda import device_count\n",
    "from torch.cuda.amp import GradScaler\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12df62ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_rotation_dummyDA_mirroring_and_inital_patch_size(patch_size):\n",
    "    \"\"\"\n",
    "    This function is stupid and certainly one of the weakest spots of this implementation. Not entirely sure how we can fix it.\n",
    "    \"\"\"\n",
    "    dim = len(patch_size)\n",
    "    # todo rotation should be defined dynamically based on patch size (more isotropic patch sizes = more rotation)\n",
    "    if dim == 2:\n",
    "        do_dummy_2d_data_aug = False\n",
    "        # todo revisit this parametrization\n",
    "        if max(patch_size) / min(patch_size) > 1.5:\n",
    "            rotation_for_DA = {\n",
    "                'x': (-15. / 360 * 2. * np.pi, 15. / 360 * 2. * np.pi),\n",
    "                'y': (0, 0),\n",
    "                'z': (0, 0)\n",
    "            }\n",
    "        else:\n",
    "            rotation_for_DA = {\n",
    "                'x': (-180. / 360 * 2. * np.pi, 180. / 360 * 2. * np.pi),\n",
    "                'y': (0, 0),\n",
    "                'z': (0, 0)\n",
    "            }\n",
    "        mirror_axes = (0, 1)\n",
    "    elif dim == 3:\n",
    "        # todo this is not ideal. We could also have patch_size (64, 16, 128) in which case a full 180deg 2d rot would be bad\n",
    "        # order of the axes is determined by spacing, not image size\n",
    "        do_dummy_2d_data_aug = (max(patch_size) / patch_size[0]) > ANISO_THRESHOLD\n",
    "        if do_dummy_2d_data_aug:\n",
    "            # why do we rotate 180 deg here all the time? We should also restrict it\n",
    "            rotation_for_DA = {\n",
    "                'x': (-180. / 360 * 2. * np.pi, 180. / 360 * 2. * np.pi),\n",
    "                'y': (0, 0),\n",
    "                'z': (0, 0)\n",
    "            }\n",
    "        else:\n",
    "            rotation_for_DA = {\n",
    "                'x': (-30. / 360 * 2. * np.pi, 30. / 360 * 2. * np.pi),\n",
    "                'y': (-30. / 360 * 2. * np.pi, 30. / 360 * 2. * np.pi),\n",
    "                'z': (-30. / 360 * 2. * np.pi, 30. / 360 * 2. * np.pi),\n",
    "            }\n",
    "        mirror_axes = (0, 1, 2)\n",
    "    else:\n",
    "        raise RuntimeError()\n",
    "\n",
    "    # todo this function is stupid. It doesn't even use the correct scale range (we keep things as they were in the\n",
    "    #  old nnunet for now)\n",
    "    initial_patch_size = get_patch_size(patch_size[-dim:],\n",
    "                                        *rotation_for_DA.values(),\n",
    "                                        (0.85, 1.25))\n",
    "    if do_dummy_2d_data_aug:\n",
    "        initial_patch_size[0] = patch_size[0]\n",
    "\n",
    "    return rotation_for_DA, do_dummy_2d_data_aug, initial_patch_size, mirror_axes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64fe239",
   "metadata": {},
   "source": [
    "configure_rotation_dummyDA_mirroring_and_inital_patch_size((16,32,32)) \n",
    "\n",
    "({'x': (-0.5235987755982988, 0.5235987755982988),\n",
    "  'y': (-0.5235987755982988, 0.5235987755982988),\n",
    "  'z': (-0.5235987755982988, 0.5235987755982988)},  \n",
    "  \n",
    " False,\n",
    " array([35, 51, 42]),\n",
    " (0, 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4040d4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_transforms(patch_size: Union[np.ndarray, Tuple[int]],\n",
    "                            rotation_for_DA: dict,\n",
    "                            mirror_axes: Tuple[int, ...],\n",
    "                            do_dummy_2d_data_aug: bool,\n",
    "                            order_resampling_data: int = 3,\n",
    "                            order_resampling_seg: int = 1,\n",
    "                            border_val_seg: int = -1,\n",
    "                            use_mask_for_norm: List[bool] = None,\n",
    "                            is_cascaded: bool = False,\n",
    "                            foreground_labels: Union[Tuple[int, ...], List[int]] = None,\n",
    "                            regions: List[Union[List[int], Tuple[int, ...], int]] = None,\n",
    "                            ignore_label: int = None) -> AbstractTransform:\n",
    "    tr_transforms = []\n",
    "    if do_dummy_2d_data_aug:\n",
    "        ignore_axes = (0,)\n",
    "        tr_transforms.append(Convert3DTo2DTransform())\n",
    "        patch_size_spatial = patch_size[1:]\n",
    "    else:\n",
    "        patch_size_spatial = patch_size\n",
    "        ignore_axes = None\n",
    "\n",
    "    tr_transforms.append(SpatialTransform(\n",
    "        patch_size_spatial, patch_center_dist_from_border=None,\n",
    "        do_elastic_deform=False, alpha=(0, 0), sigma=(0, 0),\n",
    "        do_rotation=True, angle_x=rotation_for_DA['x'], angle_y=rotation_for_DA['y'], angle_z=rotation_for_DA['z'],\n",
    "        p_rot_per_axis=1,  # todo experiment with this\n",
    "        do_scale=True, scale=(0.7, 1.4),\n",
    "        border_mode_data=\"constant\", border_cval_data=0, order_data=order_resampling_data,\n",
    "        border_mode_seg=\"constant\", border_cval_seg=border_val_seg, order_seg=order_resampling_seg,\n",
    "        random_crop=False,  # random cropping is part of our dataloaders\n",
    "        p_el_per_sample=0, p_scale_per_sample=0.2, p_rot_per_sample=0.2,\n",
    "        independent_scale_for_each_axis=False  # todo experiment with this\n",
    "    ))\n",
    "\n",
    "    if do_dummy_2d_data_aug:\n",
    "        tr_transforms.append(Convert2DTo3DTransform())\n",
    "\n",
    "    tr_transforms.append(GaussianNoiseTransform(p_per_sample=0.1))\n",
    "    tr_transforms.append(GaussianBlurTransform((0.5, 1.), different_sigma_per_channel=True, p_per_sample=0.2,\n",
    "                                               p_per_channel=0.5))\n",
    "    tr_transforms.append(BrightnessMultiplicativeTransform(multiplier_range=(0.75, 1.25), p_per_sample=0.15))\n",
    "    tr_transforms.append(ContrastAugmentationTransform(p_per_sample=0.15))\n",
    "    # tr_transforms.append(SimulateLowResolutionTransform(zoom_range=(0.5, 1), per_channel=True,\n",
    "    #                                                     p_per_channel=0.5,\n",
    "    #                                                     order_downsample=0, order_upsample=3, p_per_sample=0.25,\n",
    "    #                                                     ignore_axes=ignore_axes))\n",
    "    tr_transforms.append(GammaTransform((0.7, 1.5), True, True, retain_stats=True, p_per_sample=0.1))\n",
    "    tr_transforms.append(GammaTransform((0.7, 1.5), False, True, retain_stats=True, p_per_sample=0.3))\n",
    "\n",
    "    if mirror_axes is not None and len(mirror_axes) > 0:\n",
    "        tr_transforms.append(MirrorTransform(mirror_axes))\n",
    "\n",
    "    if use_mask_for_norm is not None and any(use_mask_for_norm):\n",
    "        tr_transforms.append(MaskTransform([i for i in range(len(use_mask_for_norm)) if use_mask_for_norm[i]],\n",
    "                                           mask_idx_in_seg=0, set_outside_to=0))\n",
    "\n",
    "    tr_transforms.append(RemoveLabelTransform(-1, 0))\n",
    "\n",
    "    if is_cascaded:\n",
    "        assert foreground_labels is not None, 'We need foreground_labels for cascade augmentations'\n",
    "        tr_transforms.append(MoveSegAsOneHotToData(1, foreground_labels, 'seg', 'data'))\n",
    "        tr_transforms.append(ApplyRandomBinaryOperatorTransform(\n",
    "            channel_idx=list(range(-len(foreground_labels), 0)),\n",
    "            p_per_sample=0.4,\n",
    "            key=\"data\",\n",
    "            strel_size=(1, 8),\n",
    "            p_per_label=1))\n",
    "        tr_transforms.append(\n",
    "            RemoveRandomConnectedComponentFromOneHotEncodingTransform(\n",
    "                channel_idx=list(range(-len(foreground_labels), 0)),\n",
    "                key=\"data\",\n",
    "                p_per_sample=0.2,\n",
    "                fill_with_other_class_p=0,\n",
    "                dont_do_if_covers_more_than_x_percent=0.15))\n",
    "\n",
    "    tr_transforms.append(RenameTransform('seg', 'target', True))\n",
    "\n",
    "    if regions is not None:\n",
    "        # the ignore label must also be converted\n",
    "        tr_transforms.append(ConvertSegmentationToRegionsTransform(list(regions) + [ignore_label]\n",
    "                                                                   if ignore_label is not None else regions,\n",
    "                                                                   'target', 'target'))\n",
    "\n",
    "    tr_transforms.append(NumpyToTensor(['data', 'target'], 'float'))\n",
    "    tr_transforms = Compose(tr_transforms)\n",
    "    return tr_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953b48dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_right(img):\n",
    "    img = np.transpose(img, (1, 2, 0))\n",
    "    img = np.flip(img,0)\n",
    "    img = np.flip(img,1)\n",
    "    img = np.flip(img,-1)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1287e475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_from_raw_data(ID,\n",
    "                          list_of_lists_or_source_folder: Union[str, List[List[str]]],\n",
    "                          Mask_list_of_lists_or_Mask_folder: Union[str, List[List[str]]],\n",
    "                          output_folder: str,\n",
    "                          model_training_output_dir: str,\n",
    "                          use_folds: Union[Tuple[int, ...], str] = None,\n",
    "                          tile_step_size: float = 0.5,\n",
    "                          use_gaussian: bool = True,\n",
    "                          use_mirroring: bool = True,\n",
    "                          perform_everything_on_gpu: bool = True,\n",
    "                          verbose: bool = True,\n",
    "                          save_probabilities: bool = False,\n",
    "                          overwrite: bool = True,\n",
    "                          checkpoint_name: str = 'checkpoint_best.pth',\n",
    "                          num_processes_preprocessing: int = default_num_processes,\n",
    "                          num_processes_segmentation_export: int = default_num_processes,\n",
    "                          folder_with_segs_from_prev_stage: str = None,\n",
    "                          num_parts: int = 1,\n",
    "                          part_id: int = 0,\n",
    "                          desired_gpu_index : int = 2,\n",
    "                          device: torch.device = torch.device('cuda')):\n",
    "    print(\"\\n#######################################################################\\nPlease cite the following paper \"\n",
    "          \"when using nnU-Net:\\n\"\n",
    "          \"Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). \"\n",
    "          \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. \"\n",
    "          \"Nature methods, 18(2), 203-211.\\n#######################################################################\\n\")\n",
    "\n",
    "    # 假設你想要在某個特定 GPU 上執行（例如GPU 1，編號從0開始）\n",
    "    #desired_gpu_index = 0  # 修改此處來指定你希望使用的 GPU 編號\n",
    "\n",
    "    # 檢查是否為 CUDA 設備，並指定 GPU 編號\n",
    "    if device.type == 'cuda':\n",
    "        device = torch.device(type='cuda', index=desired_gpu_index)  # 根據 desired_gpu_index 設定具體的 GPU\n",
    "\n",
    "    if device.type != 'cuda':\n",
    "        perform_everything_on_gpu = False\n",
    "    \n",
    "    print('device:', device, ' desired_gpu_index:', desired_gpu_index)\n",
    "\n",
    "    # let's store the input arguments so that its clear what was used to generate the prediction\n",
    "    my_init_kwargs = {}\n",
    "    for k in inspect.signature(predict_from_raw_data).parameters.keys():\n",
    "        my_init_kwargs[k] = locals()[k]\n",
    "    my_init_kwargs = deepcopy(my_init_kwargs)  # let's not unintentionally change anything in-place. Take this as a\n",
    "    # safety precaution.\n",
    "    recursive_fix_for_json_export(my_init_kwargs)\n",
    "    maybe_mkdir_p(output_folder)\n",
    "    save_json(my_init_kwargs, join(output_folder, 'predict_from_raw_data_args.json'))\n",
    "\n",
    "    if use_folds is None:\n",
    "        use_folds = auto_detect_available_folds(model_training_output_dir, checkpoint_name)\n",
    "\n",
    "    # load all the stuff we need from the model_training_output_dir\n",
    "    # 這邊獲得都是模型的參數\n",
    "    parameters, configuration_manager, inference_allowed_mirroring_axes, \\\n",
    "    plans_manager, dataset_json, network, trainer_name = \\\n",
    "        load_what_we_need(model_training_output_dir, use_folds, checkpoint_name)\n",
    "    \n",
    "    #這邊先不用到\n",
    "    \"\"\"\n",
    "    # check if we need a prediction from the previous stage\n",
    "    if configuration_manager.previous_stage_name is not None:\n",
    "        if folder_with_segs_from_prev_stage is None:\n",
    "            print(f'WARNING: The requested configuration is a cascaded model and requires predctions from the '\n",
    "                  f'previous stage! folder_with_segs_from_prev_stage was not provided. Trying to run the '\n",
    "                  f'inference of the previous stage...')\n",
    "            folder_with_segs_from_prev_stage = join(output_folder,\n",
    "                                                    f'prediction_{configuration_manager.previous_stage_name}')\n",
    "            predict_from_raw_data(list_of_lists_or_source_folder,\n",
    "                                  folder_with_segs_from_prev_stage,\n",
    "                                  get_output_folder(plans_manager.dataset_name,\n",
    "                                                    trainer_name,\n",
    "                                                    plans_manager.plans_name,\n",
    "                                                    configuration_manager.previous_stage_name),\n",
    "                                  use_folds, tile_step_size, use_gaussian, use_mirroring, perform_everything_on_gpu,\n",
    "                                  verbose, False, overwrite, checkpoint_name,\n",
    "                                  num_processes_preprocessing, num_processes_segmentation_export, None,\n",
    "                                  num_parts=num_parts, part_id=part_id, device=device)\n",
    "    \"\"\"\n",
    "\n",
    "    # sort out input and output filenames\n",
    "    if isinstance(list_of_lists_or_source_folder, str):\n",
    "        list_of_lists_or_source_folder = create_lists_from_splitted_dataset_folder(list_of_lists_or_source_folder,\n",
    "                                                                                   dataset_json['file_ending'])\n",
    "        Mask_list_of_lists_or_Mask_folder = create_lists_from_splitted_dataset_folder(Mask_list_of_lists_or_Mask_folder,\n",
    "                                                                                   dataset_json['file_ending'])\n",
    "    \n",
    "    print(f'There are {len(list_of_lists_or_source_folder)} cases in the source folder')\n",
    "    list_of_lists_or_source_folder = list_of_lists_or_source_folder[part_id::num_parts]\n",
    "    caseids = [os.path.basename(i[0])[:-(len(dataset_json['file_ending']) + 5)] for i in list_of_lists_or_source_folder]\n",
    "    print(f'I am process {part_id} out of {num_parts} (max process ID is {num_parts - 1}, we start counting with 0!)')\n",
    "    print(f'There are {len(caseids)} cases that I would like to predict')\n",
    "    print('選中的case為:', str(ID))\n",
    "    print('list_of_lists_or_source_folder example:', list_of_lists_or_source_folder[ID-1])\n",
    "    print('Mask_list_of_lists_or_Mask_folder:', type(Mask_list_of_lists_or_Mask_folder), Mask_list_of_lists_or_Mask_folder[ID-1])\n",
    "    \n",
    "    #這裡只留下選定的case\n",
    "    list_of_lists_or_source_folder = [list_of_lists_or_source_folder[ID-1]]\n",
    "    Mask_list_of_lists_or_Mask_folder = [Mask_list_of_lists_or_Mask_folder[ID-1]]\n",
    "    print('Mask_list_of_lists_or_Mask_folder:', type(Mask_list_of_lists_or_Mask_folder), Mask_list_of_lists_or_Mask_folder)\n",
    "    caseids = [caseids[ID-1]]\n",
    "    \n",
    "    output_filename_truncated = [join(output_folder, i) for i in caseids]\n",
    "    seg_from_prev_stage_files = [join(folder_with_segs_from_prev_stage, i + dataset_json['file_ending']) if\n",
    "                                 folder_with_segs_from_prev_stage is not None else None for i in caseids]\n",
    "    # remove already predicted files form the lists\n",
    "    if not overwrite:\n",
    "        tmp = [isfile(i + dataset_json['file_ending']) for i in output_filename_truncated]\n",
    "        not_existing_indices = [i for i, j in enumerate(tmp) if not j]\n",
    "\n",
    "        output_filename_truncated = [output_filename_truncated[i] for i in not_existing_indices]\n",
    "        list_of_lists_or_source_folder = [list_of_lists_or_source_folder[i] for i in not_existing_indices]\n",
    "        seg_from_prev_stage_files = [seg_from_prev_stage_files[i] for i in not_existing_indices]\n",
    "        print(f'overwrite was set to {overwrite}, so I am only working on cases that haven\\'t been predicted yet. '\n",
    "              f'That\\'s {len(not_existing_indices)} cases.')\n",
    "        # caseids = [caseids[i] for i in not_existing_indices]\n",
    "    print('list_of_lists_or_source_folder:', list_of_lists_or_source_folder)\n",
    "    print('seg_from_prev_stage_files:', seg_from_prev_stage_files)\n",
    "    # placing this into a separate function doesnt make sense because it needs so many input variables...\n",
    "    preprocessor = configuration_manager.preprocessor_class(verbose=verbose)\n",
    "    # hijack batchgenerators, yo\n",
    "    # we use the multiprocessing of the batchgenerators dataloader to handle all the background worker stuff. This\n",
    "    # way we don't have to reinvent the wheel here.\n",
    "    \n",
    "    print('開始前處裡!!!')\n",
    "    num_processes = max(1, min(num_processes_preprocessing, len(list_of_lists_or_source_folder)))\n",
    "    print('num_processes:', num_processes)\n",
    "    #Mask_list_of_lists_or_Mask_folder就是原本的label資料夾\n",
    "    ppa = PreprocessAdapter(list_of_lists_or_source_folder, Mask_list_of_lists_or_Mask_folder, preprocessor,\n",
    "                            output_filename_truncated, plans_manager, dataset_json,\n",
    "                            configuration_manager, num_processes)\n",
    "\n",
    "    #進到這裡的生成器基本上等於做augmentation，因為MultiThreadedAugmenter會調用gpu，這邊用SingleThreadedAugmenter就好\n",
    "    #mta = MultiThreadedAugmenter(ppa, NumpyToTensor(), num_processes, 1, None, pin_memory=device.type == 'cuda')\n",
    "    mta = SingleThreadedAugmenter(ppa, NumpyToTensor())\n",
    "    \n",
    "    #以下增加augmentation使用的增強器\n",
    "    patch_size = (160 , 512, 512)\n",
    "\n",
    "    rotation_for_DA, do_dummy_2d_data_aug, initial_patch_size, mirror_axes = \\\n",
    "        configure_rotation_dummyDA_mirroring_and_inital_patch_size(patch_size)\n",
    "    \n",
    "    print('rotation_for_DA, do_dummy_2d_data_aug, initial_patch_size, mirror_axes:', rotation_for_DA, do_dummy_2d_data_aug, initial_patch_size, mirror_axes)\n",
    "\n",
    "    # training pipeline\n",
    "    tr_transforms = get_training_transforms(\n",
    "        (1, 1, initial_patch_size[-1], initial_patch_size[1], initial_patch_size[0]), rotation_for_DA, mirror_axes, do_dummy_2d_data_aug=False,\n",
    "        order_resampling_data=3, order_resampling_seg=1)\n",
    "\n",
    "    mta_tr = SingleThreadedAugmenter(ppa, tr_transforms)\n",
    "    #mta_tr = SingleThreadedAugmenter(ppa, NumpyToTensor())\n",
    "    \n",
    "    # precompute gaussian\n",
    "#     inference_gaussian = torch.from_numpy(\n",
    "#         compute_gaussian(configuration_manager.patch_size)).half()\n",
    "#     if perform_everything_on_gpu:\n",
    "#         inference_gaussian = inference_gaussian.to(device)\n",
    "#     print('inference_gaussian.shape:', inference_gaussian.shape)\n",
    "\n",
    "    # num seg heads is needed because we need to preallocate the results in predict_sliding_window_return_logits\n",
    "    label_manager = plans_manager.get_label_manager(dataset_json)\n",
    "    num_seg_heads = label_manager.num_segmentation_heads\n",
    "    #num_seg_heads 這邊為 0背景 1.動脈瘤，所以為2\n",
    "    #print('num_seg_heads:', num_seg_heads)\n",
    "\n",
    "    # go go go\n",
    "    # spawn allows the use of GPU in the background process in case somebody wants to do this. Not recommended. Trust me.\n",
    "    # export_pool = multiprocessing.get_context('spawn').Pool(num_processes_segmentation_export)\n",
    "    # export_pool = multiprocessing.Pool(num_processes_segmentation_export)\n",
    "    print('go go go!!!')\n",
    "    with multiprocessing.get_context(\"spawn\").Pool(num_processes_segmentation_export) as export_pool:\n",
    "        #network = network.to(device)\n",
    "        #network = network\n",
    "\n",
    "        r = []\n",
    "        with torch.no_grad():\n",
    "            for preprocessed, nii_path, label_path in zip(mta, list_of_lists_or_source_folder, Mask_list_of_lists_or_Mask_folder):\n",
    "                start_time = time.time()\n",
    "                #print('preprocessed:', preprocessed)\n",
    "                data = preprocessed['data']\n",
    "                print('data.shape:', data.shape) #data.shape: torch.Size([2, 136, 490, 490]))\n",
    "                img_resample = data[0,:,:,:].numpy().copy()\n",
    "                label_resample = data[1,:,:,:].numpy().copy()\n",
    "                transposed_img_resample = set_right(img_resample)\n",
    "                transposed_label_resample = set_right(label_resample)\n",
    "                \n",
    "                data_aug = preprocessed['data']\n",
    "                img_aug = data_aug[0,:,:,:].numpy().copy()\n",
    "                label_aug = data_aug[1,:,:,:].numpy().copy()\n",
    "                transposed_img_aug = set_right(img_aug)\n",
    "                transposed_label_aug = set_right(label_aug)\n",
    "                \n",
    "                #這邊切出image跟label\n",
    "                #讀取nifti\n",
    "                img_nii = nib.load(str(nii_path[0]))\n",
    "                img_o = np.array(img_nii.dataobj) #讀出label的array矩陣      #256*256*22   \n",
    "                img_o = data_translate(img_o, img_nii)\n",
    "                \n",
    "                label_nii = nib.load(str(label_path[0]))\n",
    "                label_o = np.array(label_nii.dataobj) #讀出label的array矩陣      #256*256*22   \n",
    "                label_o = data_translate(label_o, label_nii)\n",
    "                \n",
    "                #看出resample完成後影像的shape跟原始的sample\n",
    "                print('original size:', img_o.shape, ' resample size:', transposed_img_resample.shape)\n",
    "                \n",
    "                #原始比resample大，resample補0\n",
    "                if img_o.shape[0] > transposed_img_resample.shape[0] or img_o.shape[2] > transposed_img_resample.shape[2]:\n",
    "                    # 計算需要補齊的大小:tensorA = torch.randn(1, 127, 512, 512)  # 假設是 tensorA\n",
    "                    pad_height = (img_o.shape[0] - transposed_img_resample.shape[0])  # 需要補齊的高度 (上和下)\n",
    "                    pad_width = (img_o.shape[1] - transposed_img_resample.shape[1])  # 需要補齊的寬度 (左和右)\n",
    "                    pad_depth = (img_o.shape[2] - transposed_img_resample.shape[2])  # 需要補齊的深度 (前和後)\n",
    "\n",
    "                    # 計算每一維的補齊值\n",
    "                    # pad順序為 (左, 右, 上, 下, 前, 後)\n",
    "                    padding = ((pad_height // 2, pad_height - pad_height // 2),  # 高度（上下）\n",
    "                               (pad_width // 2, pad_width - pad_width // 2),  # 深度（前後）\n",
    "                               (pad_depth // 2, pad_depth - pad_depth // 2))  # 寬度（左右）\n",
    "\n",
    "                    # 使用 F.pad 進行補齊\n",
    "                    transposed_img_resample = np.pad(transposed_img_resample, pad_width=padding, mode='constant', constant_values=0)\n",
    "                    transposed_label_resample = np.pad(transposed_label_resample, pad_width=padding, mode='constant', constant_values=0)\n",
    "                    \n",
    "                    transposed_img_aug = np.pad(transposed_img_aug, pad_width=padding, mode='constant', constant_values=0)\n",
    "                    transposed_label_aug = np.pad(transposed_label_aug, pad_width=padding, mode='constant', constant_values=0)                    \n",
    "                else:\n",
    "                    pad_height = (transposed_img_resample.shape[0] - img_o.shape[0])  # 需要補齊的高度 (上和下)\n",
    "                    pad_width = (transposed_img_resample.shape[1] - img_o.shape[1])  # 需要補齊的寬度 (左和右)\n",
    "                    pad_depth = (transposed_img_resample.shape[2] - img_o.shape[2])  # 需要補齊的深度 (前和後)\n",
    "\n",
    "                    # 計算每一維的補齊值\n",
    "                    # pad順序為 (左, 右, 上, 下, 前, 後)\n",
    "                    padding = ((pad_height // 2, pad_height - pad_height // 2),  # 高度（上下）\n",
    "                               (pad_width // 2, pad_width - pad_width // 2),  # 深度（前後）\n",
    "                               (pad_depth // 2, pad_depth - pad_depth // 2))  # 寬度（左右）\n",
    "\n",
    "                    # 使用 F.pad 進行補齊\n",
    "                    img_o = np.pad(img_o, pad_width=padding, mode='constant', constant_values=0)\n",
    "                    label_o = np.pad(label_o, pad_width=padding, mode='constant', constant_values=0)\n",
    "                    \n",
    "                print('original size:', img_o.shape, ' after padding size:', transposed_img_resample.shape)\n",
    "\n",
    "                ofile = preprocessed['ofile']\n",
    "                print(f'\\nPredicting {os.path.basename(ofile)}:')\n",
    "                print(f'perform_everything_on_gpu: {perform_everything_on_gpu}')\n",
    "                print('configuration_manager.patch_size:', configuration_manager.patch_size)\n",
    "                \n",
    "                properties = preprocessed['data_properites'] #組回nifti的參數\n",
    "                \n",
    "                #以下使用依照label取框的程式來畫圖\n",
    "                # function test:\n",
    "                image_crop_stack, label_crop_stack, image_crop_resample, label_crop_resample, image_crop_aug, label_crop_aug, image_crop_low, label_crop_low, image_crop_auglow, label_crop_auglow = rand_crop_sampling(img_o, label_o,\n",
    "                                                                                                                                                                                                                        transposed_img_resample, transposed_label_resample, \n",
    "                                                                                                                                                                                                                        transposed_img_aug, transposed_label_aug,\n",
    "                                                                                                                                                                                                                        transposed_img_resample, transposed_label_resample,\n",
    "                                                                                                                                                                                                                        transposed_img_resample, transposed_label_resample,\n",
    "                                                                                                                                                                                                                        lesion_lb=1, \n",
    "                                                                                                                                                                                                                        nag_sample_mask=transposed_label_resample>0, \n",
    "                                                                                                                                                                                                                        size=(32,32,16), sample_num=1, pos_rate=1)\n",
    "                \n",
    "                print(\"image_crop_stack shape =\", image_crop_stack.shape)\n",
    "                print(\"label_crop_stack shape =\", label_crop_stack.shape, label_crop_stack.min(), label_crop_stack.max())\n",
    "                \n",
    "                plot_multi_view2(image_crop_stack, label_crop_stack, \n",
    "                                 image_crop_resample, label_crop_resample, \n",
    "                                 image_crop_aug, label_crop_aug, \n",
    "                                 image_crop_low, label_crop_low, \n",
    "                                 image_crop_auglow, label_crop_auglow\n",
    "                                 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41730e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_entry_point():\n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser(description='Use this to run inference with nnU-Net. This function is used when '\n",
    "                                                 'you want to manually specify a folder containing a trained nnU-Net '\n",
    "                                                 'model. This is useful when the nnunet environment variables '\n",
    "                                                 '(nnUNet_results) are not set.')\n",
    "    parser.add_argument('-i', type=str, required=True,\n",
    "                        help='input folder. Remember to use the correct channel numberings for your files (_0000 etc). '\n",
    "                             'File endings must be the same as the training dataset!')\n",
    "    parser.add_argument('-v', type=str, required=True,\n",
    "                        help='input vessel folder. Remember to use the correct channel numberings for your files (_0000 etc). '\n",
    "                             'File endings must be the same as the training dataset!')\n",
    "    parser.add_argument('-o', type=str, required=True,\n",
    "                        help='Output folder. If it does not exist it will be created. Predicted segmentations will '\n",
    "                             'have the same name as their source images.')\n",
    "    parser.add_argument('-d', type=str, required=True,\n",
    "                        help='Dataset with which you would like to predict. You can specify either dataset name or id')\n",
    "    parser.add_argument('-p', type=str, required=False, default='nnUNetPlans',\n",
    "                        help='Plans identifier. Specify the plans in which the desired configuration is located. '\n",
    "                             'Default: nnUNetPlans')\n",
    "    parser.add_argument('-tr', type=str, required=False, default='nnUNetTrainer',\n",
    "                        help='What nnU-Net trainer class was used for training? Default: nnUNetTrainer')\n",
    "    parser.add_argument('-c', type=str, required=True,\n",
    "                        help='nnU-Net configuration that should be used for prediction. Config must be located '\n",
    "                             'in the plans specified with -p')\n",
    "    parser.add_argument('-f', nargs='+', type=str, required=False, default=(0, 1, 2, 3, 4),\n",
    "                        help='Specify the folds of the trained model that should be used for prediction. '\n",
    "                             'Default: (0, 1, 2, 3, 4)')\n",
    "    parser.add_argument('-step_size', type=float, required=False, default=0.5,\n",
    "                        help='Step size for sliding window prediction. The larger it is the faster but less accurate '\n",
    "                             'the prediction. Default: 0.5. Cannot be larger than 1. We recommend the default.')\n",
    "    parser.add_argument('--disable_tta', action='store_true', required=False, default=False,\n",
    "                        help='Set this flag to disable test time data augmentation in the form of mirroring. Faster, '\n",
    "                             'but less accurate inference. Not recommended.')\n",
    "    parser.add_argument('--verbose', action='store_true', help=\"Set this if you like being talked to. You will have \"\n",
    "                                                               \"to be a good listener/reader.\")\n",
    "    parser.add_argument('--save_probabilities', action='store_true',\n",
    "                        help='Set this to export predicted class \"probabilities\". Required if you want to ensemble '\n",
    "                             'multiple configurations.')\n",
    "    parser.add_argument('--continue_prediction', action='store_true',\n",
    "                        help='Continue an aborted previous prediction (will not overwrite existing files)')\n",
    "    parser.add_argument('-chk', type=str, required=False, default='checkpoint_final.pth',\n",
    "                        help='Name of the checkpoint you want to use. Default: checkpoint_final.pth')\n",
    "    parser.add_argument('-npp', type=int, required=False, default=3,\n",
    "                        help='Number of processes used for preprocessing. More is not always better. Beware of '\n",
    "                             'out-of-RAM issues. Default: 3')\n",
    "    parser.add_argument('-nps', type=int, required=False, default=3,\n",
    "                        help='Number of processes used for segmentation export. More is not always better. Beware of '\n",
    "                             'out-of-RAM issues. Default: 3')\n",
    "    parser.add_argument('-prev_stage_predictions', type=str, required=False, default=None,\n",
    "                        help='Folder containing the predictions of the previous stage. Required for cascaded models.')\n",
    "    parser.add_argument('-num_parts', type=int, required=False, default=1,\n",
    "                        help='Number of separate nnUNetv2_predict call that you will be making. Default: 1 (= this one '\n",
    "                             'call predicts everything)')\n",
    "    parser.add_argument('-part_id', type=int, required=False, default=0,\n",
    "                        help='If multiple nnUNetv2_predict exist, which one is this? IDs start with 0 can end with '\n",
    "                             'num_parts - 1. So when you submit 5 nnUNetv2_predict calls you need to set -num_parts '\n",
    "                             '5 and use -part_id 0, 1, 2, 3 and 4. Simple, right? Note: You are yourself responsible '\n",
    "                             'to make these run on separate GPUs! Use CUDA_VISIBLE_DEVICES (google, yo!)')\n",
    "    parser.add_argument('-desired_gpu_index', type=int, default=2, required=False, \n",
    "                        help=\"This to set which GPU ID!\")\n",
    "    parser.add_argument('-device', type=str, default='cuda', required=False,\n",
    "                        help=\"Use this to set the device the inference should run with. Available options are 'cuda' \"\n",
    "                             \"(GPU), 'cpu' (CPU) and 'mps' (Apple M1/M2). Do NOT use this to set which GPU ID! \"\n",
    "                             \"Use CUDA_VISIBLE_DEVICES=X nnUNetv2_predict [...] instead!\")   \n",
    "\n",
    "    args = parser.parse_args()\n",
    "    args.f = [i if i == 'all' else int(i) for i in args.f]\n",
    "\n",
    "    model_folder = get_output_folder(args.d, args.tr, args.p, args.c)\n",
    "\n",
    "    if not isdir(args.o):\n",
    "        maybe_mkdir_p(args.o)\n",
    "\n",
    "    # slightly passive agressive haha\n",
    "    assert args.part_id < args.num_parts, 'Do you even read the documentation? See nnUNetv2_predict -h.'\n",
    "\n",
    "    assert args.device in ['cpu', 'cuda',\n",
    "                           'mps'], f'-device must be either cpu, mps or cuda. Other devices are not tested/supported. Got: {args.device}.'\n",
    "    if args.device == 'cpu':\n",
    "        # let's allow torch to use hella threads\n",
    "        import multiprocessing\n",
    "        torch.set_num_threads(multiprocessing.cpu_count())\n",
    "        device = torch.device('cpu')\n",
    "    elif args.device == 'cuda':\n",
    "        # multithreading in torch doesn't help nnU-Net if run on GPU\n",
    "        torch.set_num_threads(1)\n",
    "        torch.set_num_interop_threads(1)\n",
    "        device = torch.device('cuda')\n",
    "    else:\n",
    "        device = torch.device('mps')\n",
    "\n",
    "    predict_from_raw_data(1,\n",
    "                          args.i,\n",
    "                          args.v,\n",
    "                          args.o,\n",
    "                          model_folder,\n",
    "                          args.f,\n",
    "                          args.step_size,\n",
    "                          use_gaussian=True,\n",
    "                          use_mirroring=not args.disable_tta,\n",
    "                          perform_everything_on_gpu=True,\n",
    "                          verbose=args.verbose,\n",
    "                          save_probabilities=args.save_probabilities,\n",
    "                          overwrite=not args.continue_prediction,\n",
    "                          checkpoint_name=args.chk,\n",
    "                          num_processes_preprocessing=args.npp,\n",
    "                          num_processes_segmentation_export=args.nps,\n",
    "                          folder_with_segs_from_prev_stage=args.prev_stage_predictions,\n",
    "                          num_parts=args.num_parts,\n",
    "                          part_id=args.part_id,\n",
    "                          desired_gpu_index = args.desired_gpu_index,\n",
    "                          device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb12dab4",
   "metadata": {},
   "source": [
    "這邊vessel改成label，去展示疊label的情況"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1843fe8e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    from multiprocessing import Pool\n",
    "    #最前面數字可以指定先在要看哪個case，至少1以上\n",
    "    predict_from_raw_data(3,\n",
    "                          '/data/chuan/nnUNet/nnUNet_raw/Dataset058_DeepAneurysm/Normalized_Image_External_Test',\n",
    "                          '/data/chuan/nnUNet/nnUNet_raw/Dataset058_DeepAneurysm/Label_External_Test/',\n",
    "                          '/data/chuan/nnUNet/nnUNet_inference/Dataset058_DeepAneurysm/3d_fullres/nnResUNet/External_Test_tsetshow',\n",
    "                          '/data/chuan/nnUNet/nnUNet_results/Dataset058_DeepAneurysm/nnUNetTrainer__nnUNetPlans__3d_fullres',\n",
    "                          (1,),\n",
    "                          0.25,\n",
    "                          use_gaussian=True,\n",
    "                          use_mirroring=False,\n",
    "                          perform_everything_on_gpu=True,\n",
    "                          verbose=True,\n",
    "                          save_probabilities=False,\n",
    "                          overwrite=False,\n",
    "                          checkpoint_name='checkpoint_best.pth',\n",
    "                          num_processes_preprocessing=3,\n",
    "                          num_processes_segmentation_export=3,\n",
    "                          desired_gpu_index = 0,\n",
    "                          )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
