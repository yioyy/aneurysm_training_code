{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85f3f59e",
   "metadata": {},
   "source": [
    "## 測試nnUNet training code\n",
    "想要看出經過augmentation後，train的input長什麼樣子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de031122",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import socket\n",
    "from typing import Union, Optional\n",
    "\n",
    "import nnunetv2\n",
    "import torch.cuda\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from batchgenerators.utilities.file_and_folder_operations import join, isfile, load_json\n",
    "from nnunetv2.paths import nnUNet_preprocessed\n",
    "from nnunetv2.run.load_pretrained_weights import load_pretrained_weights\n",
    "from nnunetv2.training.nnUNetTrainer.nnUNetTrainer import nnUNetTrainer\n",
    "from nnunetv2.utilities.dataset_name_id_conversion import maybe_convert_to_dataset_name\n",
    "from nnunetv2.utilities.find_class_by_name import recursive_find_python_class\n",
    "from torch.backends import cudnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cad8f969",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_free_network_port() -> int:\n",
    "    \"\"\"Finds a free port on localhost.\n",
    "\n",
    "    It is useful in single-node training when we don't want to connect to a real main node but have to set the\n",
    "    `MASTER_PORT` environment variable.\n",
    "    \"\"\"\n",
    "    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    s.bind((\"\", 0))\n",
    "    port = s.getsockname()[1]\n",
    "    s.close()\n",
    "    return port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45c8b5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trainer_from_args(dataset_name_or_id: Union[int, str],\n",
    "                          configuration: str,\n",
    "                          fold: int,\n",
    "                          trainer_name: str = 'nnUNetTrainer',\n",
    "                          plans_identifier: str = 'nnUNetPlans',\n",
    "                          use_compressed: bool = False,\n",
    "                          device: torch.device = torch.device('cuda')):\n",
    "    # load nnunet class and do sanity checks\n",
    "    nnunet_trainer = recursive_find_python_class(join(nnunetv2.__path__[0], \"training\", \"nnUNetTrainer\"),\n",
    "                                                trainer_name, 'nnunetv2.training.nnUNetTrainer')\n",
    "    if nnunet_trainer is None:\n",
    "        raise RuntimeError(f'Could not find requested nnunet trainer {trainer_name} in '\n",
    "                           f'nnunetv2.training.nnUNetTrainer ('\n",
    "                           f'{join(nnunetv2.__path__[0], \"training\", \"nnUNetTrainer\")}). If it is located somewhere '\n",
    "                           f'else, please move it there.')\n",
    "    assert issubclass(nnunet_trainer, nnUNetTrainer), 'The requested nnunet trainer class must inherit from ' \\\n",
    "                                                    'nnUNetTrainer'\n",
    "\n",
    "    # handle dataset input. If it's an ID we need to convert to int from string\n",
    "    if dataset_name_or_id.startswith('Dataset'):\n",
    "        pass\n",
    "    else:\n",
    "        try:\n",
    "            dataset_name_or_id = int(dataset_name_or_id)\n",
    "        except ValueError:\n",
    "            raise ValueError(f'dataset_name_or_id must either be an integer or a valid dataset name with the pattern '\n",
    "                             f'DatasetXXX_YYY where XXX are the three(!) task ID digits. Your '\n",
    "                             f'input: {dataset_name_or_id}')\n",
    "\n",
    "    # initialize nnunet trainer\n",
    "    preprocessed_dataset_folder_base = join(nnUNet_preprocessed, maybe_convert_to_dataset_name(dataset_name_or_id))\n",
    "    plans_file = join(preprocessed_dataset_folder_base, plans_identifier + '.json')\n",
    "    plans = load_json(plans_file)\n",
    "    dataset_json = load_json(join(preprocessed_dataset_folder_base, 'dataset.json'))\n",
    "    nnunet_trainer = nnunet_trainer(plans=plans, configuration=configuration, fold=fold,\n",
    "                                    dataset_json=dataset_json, unpack_dataset=not use_compressed, device=device)\n",
    "    return nnunet_trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f077858",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maybe_load_checkpoint(nnunet_trainer: nnUNetTrainer, continue_training: bool, validation_only: bool,\n",
    "                          pretrained_weights_file: str = None):\n",
    "    if continue_training:\n",
    "        expected_checkpoint_file = join(nnunet_trainer.output_folder, 'checkpoint_final.pth')\n",
    "        if not isfile(expected_checkpoint_file):\n",
    "            expected_checkpoint_file = join(nnunet_trainer.output_folder, 'checkpoint_latest.pth')\n",
    "        # special case where --c is used to run a previously aborted validation\n",
    "        if not isfile(expected_checkpoint_file):\n",
    "            expected_checkpoint_file = join(nnunet_trainer.output_folder, 'checkpoint_best.pth')\n",
    "        if not isfile(expected_checkpoint_file):\n",
    "            print(f\"WARNING: Cannot continue training because there seems to be no checkpoint available to \"\n",
    "                               f\"continue from. Starting a new training...\")\n",
    "    elif validation_only:\n",
    "        expected_checkpoint_file = join(nnunet_trainer.output_folder, 'checkpoint_final.pth')\n",
    "        if not isfile(expected_checkpoint_file):\n",
    "            raise RuntimeError(f\"Cannot run validation because the training is not finished yet!\")\n",
    "    else:\n",
    "        if pretrained_weights_file is not None:\n",
    "            load_pretrained_weights(nnunet_trainer.network, pretrained_weights_file, verbose=True)\n",
    "        expected_checkpoint_file = None\n",
    "\n",
    "    if expected_checkpoint_file is not None:\n",
    "        nnunet_trainer.load_checkpoint(expected_checkpoint_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25225a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_ddp(rank, world_size):\n",
    "    # initialize the process group\n",
    "    dist.init_process_group(\"nccl\", rank=rank, world_size=world_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f98dcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_ddp():\n",
    "    dist.destroy_process_group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "616f1b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ddp(rank, dataset_name_or_id, configuration, fold, tr, p, use_compressed, disable_checkpointing, c, val, pretrained_weights, npz, world_size):\n",
    "    setup_ddp(rank, world_size)\n",
    "    torch.cuda.set_device(torch.device('cuda', dist.get_rank()))\n",
    "\n",
    "    nnunet_trainer = get_trainer_from_args(dataset_name_or_id, configuration, fold, tr, p,\n",
    "                                           use_compressed)\n",
    "\n",
    "    if disable_checkpointing:\n",
    "        nnunet_trainer.disable_checkpointing = disable_checkpointing\n",
    "\n",
    "    assert not (c and val), f'Cannot set --c and --val flag at the same time. Dummy.'\n",
    "\n",
    "    maybe_load_checkpoint(nnunet_trainer, c, val, pretrained_weights)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        cudnn.deterministic = False\n",
    "        cudnn.benchmark = True\n",
    "\n",
    "    if not val:\n",
    "        nnunet_trainer.run_training()\n",
    "\n",
    "    nnunet_trainer.perform_actual_validation(npz)\n",
    "    cleanup_ddp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7379729e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(dataset_name_or_id: Union[str, int],\n",
    "                 configuration: str, fold: Union[int, str],\n",
    "                 trainer_class_name: str = 'nnUNetTrainer',\n",
    "                 plans_identifier: str = 'nnUNetPlans',\n",
    "                 pretrained_weights: Optional[str] = None,\n",
    "                 num_gpus: int = 1,\n",
    "                 use_compressed_data: bool = False,\n",
    "                 export_validation_probabilities: bool = False,\n",
    "                 continue_training: bool = False,\n",
    "                 only_run_validation: bool = False,\n",
    "                 disable_checkpointing: bool = False,\n",
    "                 device: torch.device = torch.device('cuda')):\n",
    "    if isinstance(fold, str):\n",
    "        if fold != 'all':\n",
    "            try:\n",
    "                fold = int(fold)\n",
    "            except ValueError as e:\n",
    "                print(f'Unable to convert given value for fold to int: {fold}. fold must bei either \"all\" or an integer!')\n",
    "                raise e\n",
    "\n",
    "    if num_gpus > 1:\n",
    "        assert device.type == 'cuda', f\"DDP training (triggered by num_gpus > 1) is only implemented for cuda devices. Your device: {device}\"\n",
    "\n",
    "        os.environ['MASTER_ADDR'] = 'localhost'\n",
    "        if 'MASTER_PORT' not in os.environ.keys():\n",
    "            port = str(find_free_network_port())\n",
    "            print(f\"using port {port}\")\n",
    "            os.environ['MASTER_PORT'] = port  # str(port)\n",
    "\n",
    "        mp.spawn(run_ddp,\n",
    "                 args=(\n",
    "                     dataset_name_or_id,\n",
    "                     configuration,\n",
    "                     fold,\n",
    "                     trainer_class_name,\n",
    "                     plans_identifier,\n",
    "                     use_compressed_data,\n",
    "                     disable_checkpointing,\n",
    "                     continue_training,\n",
    "                     only_run_validation,\n",
    "                     pretrained_weights,\n",
    "                     export_validation_probabilities,\n",
    "                     num_gpus),\n",
    "                 nprocs=num_gpus,\n",
    "                 join=True)\n",
    "    else:\n",
    "        nnunet_trainer = get_trainer_from_args(dataset_name_or_id, configuration, fold, trainer_class_name,\n",
    "                                               plans_identifier, use_compressed_data, device=device)\n",
    "\n",
    "        #已經確認load pretrain weights，所以先初始化一次\n",
    "        if pretrained_weights is not None:\n",
    "            nnunet_trainer.initialize()\n",
    "            #因為已經做過初始化，所以\n",
    "\n",
    "        if disable_checkpointing:\n",
    "            nnunet_trainer.disable_checkpointing = disable_checkpointing\n",
    "\n",
    "        if nnunet_trainer.network is None:\n",
    "            print(\"Network is not initialized correctly!\")\n",
    "        else:\n",
    "            print(\"Network is initialized successfully.\")\n",
    "\n",
    "        assert not (continue_training and only_run_validation), f'Cannot set --c and --val flag at the same time. Dummy.'\n",
    "\n",
    "        maybe_load_checkpoint(nnunet_trainer, continue_training, only_run_validation, pretrained_weights)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            cudnn.deterministic = False\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        if not only_run_validation:\n",
    "            nnunet_trainer.run_training()\n",
    "\n",
    "        nnunet_trainer.perform_actual_validation(export_validation_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c63b2e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training_entry():\n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('dataset_name_or_id', type=str,\n",
    "                        help=\"Dataset name or ID to train with\")\n",
    "    parser.add_argument('configuration', type=str,\n",
    "                        help=\"Configuration that should be trained\")\n",
    "    parser.add_argument('fold', type=str,\n",
    "                        help='Fold of the 5-fold cross-validation. Should be an int between 0 and 4.')\n",
    "    parser.add_argument('-tr', type=str, required=False, default='nnUNetTrainer',\n",
    "                        help='[OPTIONAL] Use this flag to specify a custom trainer. Default: nnUNetTrainer')\n",
    "    parser.add_argument('-p', type=str, required=False, default='nnUNetPlans',\n",
    "                        help='[OPTIONAL] Use this flag to specify a custom plans identifier. Default: nnUNetPlans')\n",
    "    parser.add_argument('-pretrained_weights', type=str, required=False, default=None,\n",
    "                        help='[OPTIONAL] path to nnU-Net checkpoint file to be used as pretrained model. Will only '\n",
    "                             'be used when actually training. Beta. Use with caution.')\n",
    "    parser.add_argument('-num_gpus', type=int, default=1, required=False,\n",
    "                        help='Specify the number of GPUs to use for training')\n",
    "    parser.add_argument(\"--use_compressed\", default=False, action=\"store_true\", required=False,\n",
    "                        help=\"[OPTIONAL] If you set this flag the training cases will not be decompressed. Reading compressed \"\n",
    "                             \"data is much more CPU and (potentially) RAM intensive and should only be used if you \"\n",
    "                             \"know what you are doing\")\n",
    "    parser.add_argument('--npz', action='store_true', required=False,\n",
    "                        help='[OPTIONAL] Save softmax predictions from final validation as npz files (in addition to predicted '\n",
    "                             'segmentations). Needed for finding the best ensemble.')\n",
    "    parser.add_argument('--c', action='store_true', required=False,\n",
    "                        help='[OPTIONAL] Continue training from latest checkpoint')\n",
    "    parser.add_argument('--val', action='store_true', required=False,\n",
    "                        help='[OPTIONAL] Set this flag to only run the validation. Requires training to have finished.')\n",
    "    parser.add_argument('--disable_checkpointing', action='store_true', required=False,\n",
    "                        help='[OPTIONAL] Set this flag to disable checkpointing. Ideal for testing things out and '\n",
    "                             'you dont want to flood your hard drive with checkpoints.')\n",
    "    parser.add_argument('-device', type=str, default='cuda', required=False,\n",
    "                    help=\"Use this to set the device the training should run with. Available options are 'cuda' \"\n",
    "                         \"(GPU), 'cpu' (CPU) and 'mps' (Apple M1/M2). Do NOT use this to set which GPU ID! \"\n",
    "                         \"Use CUDA_VISIBLE_DEVICES=X nnUNetv2_train [...] instead!\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    assert args.device in ['cpu', 'cuda', 'mps'], f'-device must be either cpu, mps or cuda. Other devices are not tested/supported. Got: {args.device}.'\n",
    "    if args.device == 'cpu':\n",
    "        # let's allow torch to use hella threads\n",
    "        import multiprocessing\n",
    "        torch.set_num_threads(multiprocessing.cpu_count())\n",
    "        device = torch.device('cpu')\n",
    "    elif args.device == 'cuda':\n",
    "        # multithreading in torch doesn't help nnU-Net if run on GPU\n",
    "        torch.set_num_threads(1)\n",
    "        torch.set_num_interop_threads(1)\n",
    "        device = torch.device('cuda')\n",
    "    else:\n",
    "        device = torch.device('mps')\n",
    "\n",
    "    run_training(args.dataset_name_or_id, args.configuration, args.fold, args.tr, args.p, args.pretrained_weights,\n",
    "                 args.num_gpus, args.use_compressed, args.npz, args.c, args.val, args.disable_checkpointing,\n",
    "                 device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d16c9861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "\n",
      "#######################################################################\n",
      "Please cite the following paper when using nnU-Net:\n",
      "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
      "#######################################################################\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'aa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 46\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;66;03m#因為已經做過初始化，所以\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     45\u001b[0m     plans_manager_i, dataset_json_i, configuration_manager_i, num_input_channels_i, network_i \u001b[38;5;241m=\u001b[39m nnunet_trainer\u001b[38;5;241m.\u001b[39minitialize_network_look()\n\u001b[0;32m---> 46\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[43maa\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[1;32m     49\u001b[0m     cudnn\u001b[38;5;241m.\u001b[39mdeterministic \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'aa' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    dataset_name_or_id = '74'\n",
    "    configuration = '3d_fullres'\n",
    "    fold = '0'\n",
    "    num_gpus = 1\n",
    "    trainer_class_name = 'nnUNetTrainer'\n",
    "    plans_identifier = 'nnUNetPlans'\n",
    "    use_compressed_data = False\n",
    "    device = torch.device('cuda')\n",
    "    pretrained_weights = None\n",
    "    \n",
    "    #run_training(dataset_name_or_id, configuration, fold, args.tr, args.p, args.pretrained_weights,\n",
    "    #             args.num_gpus, args.use_compressed, args.npz, args.c, args.val, args.disable_checkpointing,\n",
    "    #             device=device)\n",
    "\n",
    "    #run_training(dataset_name_or_id, configuration, fold)\n",
    "    \n",
    "    #下面把run_training完全展開來看\n",
    "    if isinstance(fold, str):\n",
    "        if fold != 'all':\n",
    "            try:\n",
    "                fold = int(fold)\n",
    "            except ValueError as e:\n",
    "                print(f'Unable to convert given value for fold to int: {fold}. fold must bei either \"all\" or an integer!')\n",
    "                raise e\n",
    "    \n",
    "    if num_gpus > 1:\n",
    "        assert device.type == 'cuda', f\"DDP training (triggered by num_gpus > 1) is only implemented for cuda devices. Your device: {device}\"\n",
    "\n",
    "        os.environ['MASTER_ADDR'] = 'localhost'\n",
    "        if 'MASTER_PORT' not in os.environ.keys():\n",
    "            port = str(find_free_network_port())\n",
    "            print(f\"using port {port}\")\n",
    "            os.environ['MASTER_PORT'] = port  # str(port)\n",
    "            \n",
    "    else:\n",
    "        nnunet_trainer = get_trainer_from_args(dataset_name_or_id, configuration, fold, trainer_class_name,\n",
    "                                               plans_identifier, use_compressed_data, device=device)\n",
    "\n",
    "        #已經確認load pretrain weights，所以先初始化一次\n",
    "        if pretrained_weights is not None:\n",
    "            nnunet_trainer.initialize()\n",
    "            #因為已經做過初始化，所以\n",
    "        else:\n",
    "            plans_manager_i, dataset_json_i, configuration_manager_i, num_input_channels_i, network_i = nnunet_trainer.initialize_network_look()\n",
    "        a = aa\n",
    "           \n",
    "        if torch.cuda.is_available():\n",
    "            cudnn.deterministic = False\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        #if not only_run_validation:\n",
    "        #    nnunet_trainer.run_training()\n",
    "\n",
    "        #nnunet_trainer.perform_actual_validation(export_validation_probabilities)\n",
    "        #這邊之後就用data, target來畫圖吧!!!\n",
    "        data_noaug, target_noaug, data_aug, target_aug = nnunet_trainer.run_training_ShowTraingData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c05648f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset_name': 'Dataset074_DeepAneurysm', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [0.6999997496604919, 0.44920000433921814, 0.44920000433921814], 'original_median_shape_after_transp': [133, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'configurations': {'2d': {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 14, 'patch_size': [384, 384], 'median_image_size_in_voxels': [434.0, 402.0], 'spacing': [0.44920000433921814, 0.44920000433921814], 'normalization_schemes': ['NoNormalization'], 'use_mask_for_norm': [False], 'UNet_class_name': 'ResidualEncoderUNet', 'UNet_base_num_features': 32, 'n_conv_per_stage_encoder': [2, 2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2, 2], 'num_pool_per_axis': [6, 6], 'pool_op_kernel_sizes': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'unet_max_num_features': 512, 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'batch_dice': True}, '3d_lowres': {'data_identifier': 'nnUNetPlans_3d_lowres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [48, 192, 160], 'median_image_size_in_voxels': [81, 279, 258], 'spacing': [1.0905768015997388, 0.6998389702974243, 0.6998389702974243], 'normalization_schemes': ['NoNormalization'], 'use_mask_for_norm': [False], 'UNet_class_name': 'ResidualEncoderUNet', 'UNet_base_num_features': 32, 'n_conv_per_stage_encoder': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'num_pool_per_axis': [3, 5, 5], 'pool_op_kernel_sizes': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2], [1, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'unet_max_num_features': 320, 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'batch_dice': False, 'next_stage': '3d_cascade_fullres'}, '3d_fullres': {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [16, 32, 32], 'median_image_size_in_voxels': [16.0, 32.0, 32.0], 'spacing': [0.6999997496604919, 0.44920000433921814, 0.44920000433921814], 'normalization_schemes': ['NoNormalization'], 'use_mask_for_norm': [False], 'UNet_class_name': 'ResidualEncoderUNetClassifier', 'UNet_base_num_features': 32, 'n_conv_per_stage_encoder': [2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2], 'num_pool_per_axis': [2, 3, 3], 'pool_op_kernel_sizes': [[1, 1, 1], [1, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'conv_kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'unet_max_num_features': 512, 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'batch_dice': False}, '3d_cascade_fullres': {'inherits_from': '3d_fullres', 'previous_stage': '3d_lowres'}}, 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3.198979616165161, 'mean': 0.7234269437441456, 'median': 0.666655421257019, 'min': -0.02173912525177002, 'percentile_00_5': 0.09472443908452988, 'percentile_99_5': 1.9170658588409424, 'std': 0.3698049739851904}}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plans_manager_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10368cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TASK': 'DeepAneurysm',\n",
       " 'No.': '074',\n",
       " 'channel_names': {'0': 'MRA_BRAIN'},\n",
       " 'labels': {'background': 0, 'Aneurysm': 1},\n",
       " 'numTraining': 3116,\n",
       " 'file_ending': '.nii.gz',\n",
       " 'val_as_test': 'n'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_json_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31ef07f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [16, 32, 32], 'median_image_size_in_voxels': [16.0, 32.0, 32.0], 'spacing': [0.6999997496604919, 0.44920000433921814, 0.44920000433921814], 'normalization_schemes': ['NoNormalization'], 'use_mask_for_norm': [False], 'UNet_class_name': 'ResidualEncoderUNetClassifier', 'UNet_base_num_features': 32, 'n_conv_per_stage_encoder': [2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2], 'num_pool_per_axis': [2, 3, 3], 'pool_op_kernel_sizes': [[1, 1, 1], [1, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'conv_kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'unet_max_num_features': 512, 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'batch_dice': False}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configuration_manager_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfe8b3b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_input_channels_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f3c51660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=============================================================================================================================\n",
       "Layer (type:depth-idx)                                                      Output Shape              Param #\n",
       "=============================================================================================================================\n",
       "ResidualEncoderUNetClassifier                                               [1200, 2, 16, 32, 32]     --\n",
       "├─UNetDecoder: 1-1                                                          --                        (recursive)\n",
       "│    └─ResidualEncoder: 2-1                                                 [1200, 32, 16, 32, 32]    --\n",
       "│    │    └─StackedConvBlocks: 3-1                                          [1200, 32, 16, 32, 32]    384\n",
       "│    │    └─Sequential: 3-2                                                 --                        33,125,888\n",
       "├─UNetDecoder: 1-2                                                          [1200, 2, 16, 32, 32]     33,126,272\n",
       "│    └─ModuleList: 2-11                                                     --                        (recursive)\n",
       "│    │    └─ConvTranspose3d: 3-3                                            [1200, 256, 4, 4, 4]      524,544\n",
       "│    └─ModuleList: 2-12                                                     --                        (recursive)\n",
       "│    │    └─StackedConvBlocks: 3-4                                          [1200, 256, 4, 4, 4]      5,309,952\n",
       "│    └─ModuleList: 2-13                                                     --                        (recursive)\n",
       "│    │    └─Conv3d: 3-5                                                     [1200, 2, 4, 4, 4]        514\n",
       "│    └─ModuleList: 2-11                                                     --                        (recursive)\n",
       "│    │    └─ConvTranspose3d: 3-6                                            [1200, 128, 8, 8, 8]      262,272\n",
       "│    └─ModuleList: 2-12                                                     --                        (recursive)\n",
       "│    │    └─StackedConvBlocks: 3-7                                          [1200, 128, 8, 8, 8]      1,327,872\n",
       "│    └─ModuleList: 2-13                                                     --                        (recursive)\n",
       "│    │    └─Conv3d: 3-8                                                     [1200, 2, 8, 8, 8]        258\n",
       "│    └─ModuleList: 2-11                                                     --                        (recursive)\n",
       "│    │    └─ConvTranspose3d: 3-9                                            [1200, 64, 16, 16, 16]    65,600\n",
       "│    └─ModuleList: 2-12                                                     --                        (recursive)\n",
       "│    │    └─StackedConvBlocks: 3-10                                         [1200, 64, 16, 16, 16]    332,160\n",
       "│    └─ModuleList: 2-13                                                     --                        (recursive)\n",
       "│    │    └─Conv3d: 3-11                                                    [1200, 2, 16, 16, 16]     130\n",
       "│    └─ModuleList: 2-11                                                     --                        (recursive)\n",
       "│    │    └─ConvTranspose3d: 3-12                                           [1200, 32, 16, 32, 32]    8,224\n",
       "│    └─ModuleList: 2-12                                                     --                        (recursive)\n",
       "│    │    └─StackedConvBlocks: 3-13                                         [1200, 32, 16, 32, 32]    27,840\n",
       "│    └─ModuleList: 2-13                                                     --                        (recursive)\n",
       "│    │    └─Conv3d: 3-14                                                    [1200, 2, 16, 32, 32]     66\n",
       "├─Classifier: 1-3                                                           [1200, 2]                 --\n",
       "│    └─Sequential: 2-14                                                     [1200, 512, 4, 2, 2]      --\n",
       "│    │    └─EasyResidualBlock: 3-15                                         [1200, 512, 4, 2, 2]      574,976\n",
       "│    │    └─EasyResidualBlock: 3-16                                         [1200, 512, 4, 2, 2]      574,976\n",
       "│    └─Sequential: 2-15                                                     [1200, 2]                 --\n",
       "│    │    └─AdaptiveAvgPool3d: 3-17                                         [1200, 512, 1, 1, 1]      --\n",
       "│    │    └─Flatten: 3-18                                                   [1200, 512]               --\n",
       "│    │    └─Linear: 3-19                                                    [1200, 256]               131,328\n",
       "│    │    └─LeakyReLU: 3-20                                                 [1200, 256]               --\n",
       "│    │    └─Dropout: 3-21                                                   [1200, 256]               --\n",
       "│    │    └─Linear: 3-22                                                    [1200, 128]               32,896\n",
       "│    │    └─LeakyReLU: 3-23                                                 [1200, 128]               --\n",
       "│    │    └─Dropout: 3-24                                                   [1200, 128]               --\n",
       "│    │    └─Linear: 3-25                                                    [1200, 64]                8,256\n",
       "│    │    └─LeakyReLU: 3-26                                                 [1200, 64]                --\n",
       "│    │    └─Dropout: 3-27                                                   [1200, 64]                --\n",
       "│    │    └─Linear: 3-28                                                    [1200, 2]                 130\n",
       "=============================================================================================================================\n",
       "Total params: 75,434,538\n",
       "Trainable params: 75,434,538\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (T): 8.67\n",
       "=============================================================================================================================\n",
       "Input size (MB): 78.64\n",
       "Forward/backward pass size (MB): 126709.57\n",
       "Params size (MB): 169.23\n",
       "Estimated Total Size (MB): 126957.45\n",
       "============================================================================================================================="
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "summary(network_i, (1200, 1, 16, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbe3f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data是訓練的資料，data: torch.Size([600, 1, 16, 32, 32])\n",
    "#target因為deep supervision，所以為一個list有4層，這邊取第一層與label對在一起看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeffb46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage, interp  # pip install scipy\n",
    "import scipy.stats\n",
    "from sklearn.model_selection import train_test_split  # pip install scikit-learn\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report, f1_score, cohen_kappa_score\n",
    "from skimage.util import montage  # pip install scikit-image\n",
    "import skimage\n",
    "import pickle\n",
    "import cv2\n",
    "import csv\n",
    "import math\n",
    "import datetime\n",
    "from itertools import zip_longest\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "#%matplotlib notebook\n",
    "%matplotlib inline\n",
    "#matplotlib.use('Agg') \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b7c979",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_multi_view(img, label):\n",
    "    #先決定影像是否為正規化後，是的話就不用再做正規化, 先決定影像是否為4d，畫三張，原圖,label,疊圖\n",
    "    #dim=3為標註123放在一起，dim=4為一標註一層，統一把標註轉為1層1個吧\n",
    "    # 生成 1 到 100 之間的隨機正整數（包括 1 和 100）\n",
    "    random_integer = random.randint(0, img.shape[0]-1)\n",
    "    sample = img[random_integer,0,:,:,:]\n",
    "    targe = label[random_integer,0,:,:,:]\n",
    "    \n",
    "    #為了展示正規化\n",
    "    sample = (((sample - np.min(sample))/(np.max(sample) - np.min(sample)))*255).copy()\n",
    "    sample[sample<0] = 0\n",
    "    sample[sample>255] = 255\n",
    "    #rands = np.random.randint(0, img.shape[-1], num) #multi view\n",
    "    for idx in range(sample.shape[0]):\n",
    "        show = np.expand_dims(sample[idx,:,:], axis=-1).copy()\n",
    "        y_i, x_i, z_i = show.shape\n",
    "        show_one = show.copy()\n",
    "        show = np.concatenate([show, show_one],2)\n",
    "        show = np.concatenate([show, show_one],2)\n",
    "        show = show.astype('uint8')\n",
    "        show_label = np.zeros((y_i, x_i)).astype('uint8')\n",
    "        show_IL = show.copy()\n",
    "\n",
    "        y_nor1 = targe[idx,:,:]    \n",
    "        y_color = (y_nor1*255).astype('uint8')\n",
    "        y_th = cv2.Canny(y_color, 128, 256).copy()\n",
    "        y_th = y_th.astype('uint8')\n",
    "\n",
    "        y_c, x_c = np.where(y_nor1>0)\n",
    "        if len(y_c) > 0:    \n",
    "            show_label[y_c,x_c] = 1\n",
    "        y_c, x_c = np.where(y_th>0)\n",
    "        if len(y_c) > 0:    \n",
    "            show_IL[y_c,x_c,0] = 255\n",
    "            show_IL[y_c,x_c,1] = 0\n",
    "            show_IL[y_c,x_c,2] = 0\n",
    "                \n",
    "        plt.style.use('default') #使用背景色，繪圖風格\n",
    "        plt.figure(figsize=(20, 20)) #show 2view\n",
    "        plt.subplot(1,3,1)\n",
    "        plt.imshow(show)\n",
    "        plt.title('Image', fontsize=20)\n",
    "        plt.axis('off')\n",
    "        plt.subplot(1,3,2)\n",
    "        plt.imshow(show_label, cmap='bone')\n",
    "        plt.title('Label', fontsize=20)\n",
    "        plt.axis('off')\n",
    "        plt.subplot(1,3,3)\n",
    "        plt.imshow(show_IL)\n",
    "        plt.title('ImgLabel', fontsize=20)\n",
    "        plt.axis('off')        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4c68ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_right(img):\n",
    "    img = np.transpose(img, (1, 2, 0))\n",
    "    img = np.flip(img,0)\n",
    "    img = np.flip(img,1)\n",
    "    img = np.flip(img,-1)\n",
    "    return img\n",
    "\n",
    "def easy_nor(sample):\n",
    "    sample = (((sample - np.min(sample))/(np.max(sample) - np.min(sample)))*255).copy()\n",
    "    sample[sample<0] = 0\n",
    "    sample[sample>255] = 255\n",
    "    return sample\n",
    "\n",
    "def easy_show(sample, idx):\n",
    "    show = np.expand_dims(sample[:,:,idx], axis=-1).copy()\n",
    "    #print(show.shape)\n",
    "    y_i, x_i, z_i = show.shape\n",
    "    show_one = show.copy()\n",
    "    show = np.concatenate([show, show_one],2)\n",
    "    show = np.concatenate([show, show_one],2)\n",
    "    show = show.astype('uint8')\n",
    "    return show\n",
    "\n",
    "def esay_canny(targe, idx):\n",
    "    y_nor1 = targe[:,:,idx]    \n",
    "    y_color = (y_nor1*255).astype('uint8')\n",
    "    y_th = cv2.Canny(y_color, 128, 256).copy()\n",
    "    y_th = y_th.astype('uint8')\n",
    "    return y_th\n",
    "\n",
    "def plot_multi_view2(img1, label1, img2, label2, random_integer):\n",
    "    #先決定影像是否為正規化後，是的話就不用再做正規化, 先決定影像是否為4d，畫三張，原圖,label,疊圖\n",
    "    #dim=3為標註123放在一起，dim=4為一標註一層，統一把標註轉為1層1個吧\n",
    "    # 生成 1 到 100 之間的隨機正整數（包括 1 和 100） => 改成指定\n",
    "    #random_integer = random.randint(0, img1.shape[0]-1)\n",
    "    sample1 = img1[random_integer,0,:,:,:]\n",
    "    targe1 = label1[random_integer,0,:,:,:]\n",
    "    sample2 = img2[random_integer,0,:,:,:]\n",
    "    targe2 = label2[random_integer,0,:,:,:]\n",
    "    \n",
    "    sample1 = set_right(sample1)\n",
    "    targe1 = set_right(targe1)\n",
    "    sample2 = set_right(sample2)\n",
    "    targe2 = set_right(targe2)\n",
    "\n",
    "    #為了展示正規化\n",
    "    sample1 = easy_nor(sample1)\n",
    "    sample2 = easy_nor(sample2)\n",
    "    \n",
    "    for idx in range(sample1.shape[-1]):\n",
    "        show1 = easy_show(sample1, idx)\n",
    "        show_IL1 = show1.copy()\n",
    "        show2 = easy_show(sample2, idx)\n",
    "        show_IL2 = show2.copy()\n",
    "        \n",
    "        y_th1 = esay_canny(targe1, idx)\n",
    "        y_th2 = esay_canny(targe2, idx)\n",
    "\n",
    "        y_c, x_c = np.where(y_th1>0)\n",
    "        if len(y_c) > 0:    \n",
    "            show_IL1[y_c,x_c,0] = 255\n",
    "            show_IL1[y_c,x_c,1] = 0\n",
    "            show_IL1[y_c,x_c,2] = 0\n",
    "            \n",
    "        y_c, x_c = np.where(y_th2>0)\n",
    "        if len(y_c) > 0:    \n",
    "            show_IL2[y_c,x_c,0] = 255\n",
    "            show_IL2[y_c,x_c,1] = 0\n",
    "            show_IL2[y_c,x_c,2] = 0\n",
    "                \n",
    "        plt.style.use('default') #使用背景色，繪圖風格\n",
    "        plt.figure(figsize=(15, 15)) #show 2view\n",
    "        plt.subplot(1,4,1)\n",
    "        plt.imshow(show1)\n",
    "        plt.title('Image', fontsize=15)\n",
    "        plt.axis('off')\n",
    "        plt.subplot(1,4,2)\n",
    "        plt.imshow(show_IL1)\n",
    "        plt.title('o_Label', fontsize=15)\n",
    "        plt.axis('off') \n",
    "        plt.subplot(1,4,3)\n",
    "        plt.imshow(show2)\n",
    "        plt.title('aug', fontsize=15)\n",
    "        plt.axis('off') \n",
    "        plt.subplot(1,4,4)\n",
    "        plt.imshow(show_IL2)\n",
    "        plt.title('aug_Label', fontsize=15)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bef3ba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#先只保留有動脈瘤的case\n",
    "img_noaug = data_noaug.numpy()\n",
    "label_noaug = target_noaug[0].numpy()\n",
    "img_aug = data_aug.numpy()\n",
    "label_aug = target_aug[0].numpy()\n",
    "\n",
    "# 1. 過濾標註全為 0 的張量\n",
    "non_zero_indices = [i for i in range(label_noaug.shape[0]) if not np.all(label_noaug[i] == 0)]\n",
    "filtered_label_noaug = label_noaug[non_zero_indices]\n",
    "filtered_img_noaug = img_noaug[non_zero_indices]\n",
    "filtered_label_aug = label_aug[non_zero_indices]\n",
    "filtered_img_aug = img_aug[non_zero_indices]\n",
    "\n",
    "# 2. 按標註值的總和排序\n",
    "# 計算每張標註的總和，並按總和降序排序\n",
    "sums = filtered_label_noaug.sum(axis=(1, 2, 3, 4))  # 計算每張的標註總和\n",
    "sorted_indices = np.argsort(-sums)         # 按總和降序排序\n",
    "\n",
    "sorted_label_noaug = filtered_label_noaug[sorted_indices]\n",
    "sorted_img_noaug = filtered_img_noaug[sorted_indices]\n",
    "sorted_label_aug = filtered_label_aug[sorted_indices]\n",
    "sorted_img_aug = filtered_img_aug[sorted_indices]\n",
    "\n",
    "\n",
    "# 輸出的目標尺寸\n",
    "output_shape = (24, 42, 42)\n",
    "\n",
    "# 計算輸入的中心點\n",
    "input_shape = sorted_img_noaug.shape[2:]  # (35, 55, 42)\n",
    "center = [dim // 2 for dim in input_shape]  # 中心點索引\n",
    "\n",
    "# 計算裁剪範圍\n",
    "crop_ranges = [(center[i] - output_shape[i] // 2, center[i] + output_shape[i] // 2) for i in range(3)]\n",
    "\n",
    "# 使用切片進行裁剪\n",
    "sorted_label_noaug = sorted_label_noaug[\n",
    "    :,  # 保留 batch\n",
    "    :,  # 保留 channel\n",
    "    crop_ranges[0][0]:crop_ranges[0][1],  # 第三維\n",
    "    crop_ranges[1][0]:crop_ranges[1][1],  # 第四維\n",
    "    crop_ranges[2][0]:crop_ranges[2][1]   # 第五維\n",
    "]\n",
    "\n",
    "\n",
    "sorted_img_noaug = sorted_img_noaug[\n",
    "    :,  # 保留 batch\n",
    "    :,  # 保留 channel\n",
    "    crop_ranges[0][0]:crop_ranges[0][1],  # 第三維\n",
    "    crop_ranges[1][0]:crop_ranges[1][1],  # 第四維\n",
    "    crop_ranges[2][0]:crop_ranges[2][1]   # 第五維\n",
    "]\n",
    "\n",
    "\n",
    "# 目標大小\n",
    "target_shape = (24, 42, 42)\n",
    "\n",
    "# 計算填充量\n",
    "z_pad = (target_shape[0] - sorted_img_aug.shape[2]) // 2\n",
    "y_pad = (target_shape[1] - sorted_img_aug.shape[3]) // 2\n",
    "x_pad = (target_shape[2] - sorted_img_aug.shape[4]) // 2\n",
    "\n",
    "# 如果目標大小與輸入大小不是偶數差，保證填充後大小正確\n",
    "z_extra = (target_shape[0] - sorted_img_aug.shape[2]) % 2\n",
    "y_extra = (target_shape[1] - sorted_img_aug.shape[3]) % 2\n",
    "x_extra = (target_shape[2] - sorted_img_aug.shape[4]) % 2\n",
    "\n",
    "# 使用 np.pad 對每張數據進行填充\n",
    "sorted_label_aug = np.pad(\n",
    "    sorted_label_aug,\n",
    "    pad_width=((0, 0),  # 不填充 batch 維度\n",
    "               (0, 0),  # 不填充通道維度\n",
    "               (z_pad, z_pad + z_extra),  # z 軸填充\n",
    "               (y_pad, y_pad + y_extra),  # y 軸填充\n",
    "               (x_pad, x_pad + x_extra)),  # x 軸填充\n",
    "    mode='constant',  # 填充模式為常數（默認填充 0）\n",
    "    constant_values=0  # 填充值為 0\n",
    ")\n",
    "\n",
    "\n",
    "# 使用 np.pad 對每張數據進行填充\n",
    "sorted_img_aug = np.pad(\n",
    "    sorted_img_aug,\n",
    "    pad_width=((0, 0),  # 不填充 batch 維度\n",
    "               (0, 0),  # 不填充通道維度\n",
    "               (z_pad, z_pad + z_extra),  # z 軸填充\n",
    "               (y_pad, y_pad + y_extra),  # y 軸填充\n",
    "               (x_pad, x_pad + x_extra)),  # x 軸填充\n",
    "    mode='constant',  # 填充模式為常數（默認填充 0）\n",
    "    constant_values=0  # 填充值為 0\n",
    ")\n",
    "\n",
    "\n",
    "# 處理後的結果\n",
    "print(\"處理後的標註大小:\", sorted_label_noaug.shape)\n",
    "print(\"處理後的影像大小:\", sorted_img_aug.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b37e96d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_multi_view2(sorted_img_noaug, sorted_label_noaug, sorted_img_aug, sorted_label_aug, 298)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
